{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419e150-198e-4e58-817f-99a0529513b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/duckduckgo_search/ddg.py\n",
    "import logging\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from urllib.parse import unquote\n",
    "\n",
    "from click import progressbar\n",
    "\n",
    "from .utils import SESSION, _do_output, _download_file, _get_vqd, _normalize\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def ddg(\n",
    "    keywords,\n",
    "    region=\"wt-wt\",\n",
    "    safesearch=\"moderate\",\n",
    "    time=None,\n",
    "    max_results=None,\n",
    "    page=1,\n",
    "    output=None,\n",
    "    download=False,\n",
    "):\n",
    "    \"\"\"DuckDuckGo text search. Query params: https://duckduckgo.com/params\n",
    "\n",
    "    Args:\n",
    "        keywords (str): keywords for query.\n",
    "        region (str, optional): wt-wt, us-en, uk-en, ru-ru, etc. Defaults to \"wt-wt\".\n",
    "        safesearch (str, optional): on, moderate, off. Defaults to \"moderate\".\n",
    "        time (Optional[str], optional): d, w, m, y. Defaults to None.\n",
    "        max_results (Optional[int], optional): maximum number of results, max=200. Defaults to None.\n",
    "            if max_results is set, then the parameter page is not taken into account.\n",
    "        page (int, optional): page for pagination. Defaults to 1.\n",
    "        output (Optional[str], optional): csv, json. Defaults to None.\n",
    "        download (bool, optional): if True, download and save dociments to 'keywords' folder.\n",
    "            Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Optional[List[dict]]: DuckDuckGo text search results.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_ddg_page(page):\n",
    "        payload[\"s\"] = max(PAGINATION_STEP * (page - 1), 0)\n",
    "        page_data = None\n",
    "        try:\n",
    "            resp = SESSION.get(\"https://links.duckduckgo.com/d.js\", params=payload)\n",
    "            resp.raise_for_status()\n",
    "            page_data = resp.json().get(\"results\", None)\n",
    "        except Exception:\n",
    "            logger.exception(\"\")\n",
    "            if not max_results:\n",
    "                return None\n",
    "        page_results = []\n",
    "        if page_data:\n",
    "            for row in page_data:\n",
    "                if \"n\" not in row and row[\"u\"] not in cache:\n",
    "                    cache.add(row[\"u\"])\n",
    "                    body = _normalize(row[\"a\"])\n",
    "                    if body:\n",
    "                        page_results.append(\n",
    "                            {\n",
    "                                \"title\": _normalize(row[\"t\"]),\n",
    "                                \"href\": row[\"u\"],\n",
    "                                \"body\": body,\n",
    "                            }\n",
    "                        )\n",
    "        return page_results\n",
    "\n",
    "    if not keywords:\n",
    "        return None\n",
    "\n",
    "    # get vqd\n",
    "    vqd = _get_vqd(keywords)\n",
    "    if not vqd:\n",
    "        return None\n",
    "\n",
    "    PAGINATION_STEP, MAX_API_RESULTS = 25, 200\n",
    "\n",
    "    # prepare payload\n",
    "    safesearch_base = {\"On\": 1, \"Moderate\": -1, \"Off\": -2}\n",
    "    payload = {\n",
    "        \"q\": keywords,\n",
    "        \"l\": region,\n",
    "        \"p\": safesearch_base[safesearch.capitalize()],\n",
    "        \"s\": 0,\n",
    "        \"df\": time,\n",
    "        \"o\": \"json\",\n",
    "        \"vqd\": vqd,\n",
    "    }\n",
    "\n",
    "    # get results\n",
    "    cache = set()\n",
    "    if max_results:\n",
    "        results, page = [], 1\n",
    "        max_results = min(abs(max_results), MAX_API_RESULTS)\n",
    "        iterations = (max_results - 1) // PAGINATION_STEP + 1  # == math.ceil()\n",
    "        with ThreadPoolExecutor(min(iterations, 4)) as executor:\n",
    "            fs = []\n",
    "            for page in range(1, iterations + 1):\n",
    "                fs.append(executor.submit(get_ddg_page, page))\n",
    "                sleep(min(iterations / 17, 0.3))  # sleep to prevent blocking\n",
    "            for r in as_completed(fs):\n",
    "                if r.result():\n",
    "                    results.extend(r.result())\n",
    "        results = results[:max_results]\n",
    "    else:\n",
    "        results = get_ddg_page(page=page)\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "    keywords = keywords.replace(\" filetype:\", \"_\")\n",
    "\n",
    "    # save to csv or json file\n",
    "    if output:\n",
    "        _do_output(\"ddg\", keywords, output, results)\n",
    "\n",
    "    # download documents\n",
    "    if download:\n",
    "        keywords = (\n",
    "            keywords.replace('\"', \"'\")\n",
    "            .replace(\"site:\", \"\")\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"/\", \"_\")\n",
    "        )\n",
    "        path = f\"ddg_{keywords}_{datetime.now():%Y%m%d_%H%M%S}\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor(10) as executor:\n",
    "            for i, res in enumerate(results, start=1):\n",
    "                filename = unquote(res[\"href\"].split(\"/\")[-1].split(\"?\")[0])\n",
    "                future = executor.submit(\n",
    "                    _download_file, res[\"href\"], path, f\"{i}_{filename}\"\n",
    "                )\n",
    "                futures.append(future)\n",
    "            with progressbar(\n",
    "                as_completed(futures),\n",
    "                label=\"Downloading documents\",\n",
    "                length=len(futures),\n",
    "                show_percent=True,\n",
    "                show_pos=True,\n",
    "                width=0,\n",
    "            ) as as_completed_futures:\n",
    "                for i, future in enumerate(as_completed_futures, start=1):\n",
    "                    logger.info(\"%s/%s\", i, len(results))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\"\"\" using html method\n",
    "    payload = {\n",
    "        'q': keywords,\n",
    "        'l': region,\n",
    "        'p': safesearch_base[safesearch],\n",
    "        'df': time\n",
    "        }\n",
    "    results = []\n",
    "    while True:\n",
    "        res = SESSION.post('https://html.duckduckgo.com/html', data=payload, **kwargs)\n",
    "        tree = html.fromstring(res.text)\n",
    "        if tree.xpath('//div[@class=\"no-results\"]/text()'):\n",
    "            return results\n",
    "        for element in tree.xpath('//div[contains(@class, \"results_links\")]'):\n",
    "            results.append({\n",
    "                'title': element.xpath('.//a[contains(@class, \"result__a\")]/text()')[0],\n",
    "                'href': element.xpath('.//a[contains(@class, \"result__a\")]/@href')[0],\n",
    "                'body': ''.join(element.xpath('.//a[contains(@class, \"result__snippet\")]//text()')),\n",
    "            })\n",
    "        if len(results) >= max_results:\n",
    "            return results\n",
    "        next_page = tree.xpath('.//div[@class=\"nav-link\"]')[-1]\n",
    "        names = next_page.xpath('.//input[@type=\"hidden\"]/@name')\n",
    "        values = next_page.xpath('.//input[@type=\"hidden\"]/@value')\n",
    "        payload = {n: v for n, v in zip(names, values)}\n",
    "        sleep(2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a319081-31b1-4159-b9ea-756f9a829a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import ddg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ee18a-2619-495d-8506-1c019c392b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipymock.agi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033691f-7ab3-4c74-bce8-465690bfe098",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipymock.agi.DuckDuckGoSearchAPIWrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
