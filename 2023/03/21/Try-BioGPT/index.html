<!DOCTYPE HTML>
<html>

<head>

  <meta charset="utf-8">
  
  <title>Try BioGPT | Andrew&#39;s Blog</title>
  <meta name="author" content="Andrew">
  
  <meta name="description" content="https://github.com/microsoft/BioGPT






In&amp;nbsp;[&amp;nbsp;]:

    
%%bash
pip install torch torchvision torchaudio


    









    



Collecting t">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Try BioGPT"/>
  <meta property="og:site_name" content="Andrew&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/notebook.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/tabs.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  <script src="/js/tabs.js"></script>

  <!-- analytics -->
  



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration -->

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Andrew&#39;s Blog</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> Try BioGPT</h1>
		</div>		
	



<div class="row post">
	<!-- cols -->
	
	<div class="col-md-9">
	

			

	<!-- content -->
	<div class="mypage">
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://github.com/microsoft/BioGPT">https://github.com/microsoft/BioGPT</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting torch
  Using cached torch-2.0.0-cp310-none-macosx_10_9_x86_64.whl (139.8 MB)
Collecting torchvision
  Downloading torchvision-0.15.1-cp310-cp310-macosx_10_9_x86_64.whl (1.5 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">1.5/1.5 MB</span> <span class="ansi-red-fg">2.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Collecting torchaudio
  Downloading torchaudio-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl (3.9 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">3.9/3.9 MB</span> <span class="ansi-red-fg">3.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Collecting networkx
  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">2.0/2.0 MB</span> <span class="ansi-red-fg">3.2 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Collecting sympy
  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">6.5/6.5 MB</span> <span class="ansi-red-fg">3.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Requirement already satisfied: jinja2 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torch) (3.1.2)
Requirement already satisfied: filelock in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torch) (3.9.0)
Requirement already satisfied: typing-extensions in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torch) (4.4.0)
Requirement already satisfied: numpy in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torchvision) (1.24.2)
Collecting pillow!=8.3.*,&gt;=5.3.0
  Downloading Pillow-9.4.0-2-cp310-cp310-macosx_10_10_x86_64.whl (3.3 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">3.3/3.3 MB</span> <span class="ansi-red-fg">3.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Requirement already satisfied: requests in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torchvision) (2.28.1)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from jinja2-&gt;torch) (2.1.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;torchvision) (3.4)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;torchvision) (2.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;torchvision) (2022.12.7)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;torchvision) (1.26.14)
Collecting mpmath&gt;=0.19
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">536.2/536.2 kB</span> <span class="ansi-red-fg">3.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>a <span class="ansi-cyan-fg">0:00:01</span>
Installing collected packages: mpmath, sympy, pillow, networkx, torch, torchvision, torchaudio
Successfully installed mpmath-1.3.0 networkx-3.0 pillow-9.4.0 sympy-1.11.1 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>transformers
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting transformers
  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">6.8/6.8 MB</span> <span class="ansi-red-fg">3.9 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Requirement already satisfied: requests in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (2.28.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (2022.10.31)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (22.0)
Requirement already satisfied: filelock in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (3.9.0)
Collecting tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1
  Downloading tokenizers-0.13.2-cp310-cp310-macosx_10_11_x86_64.whl (3.8 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">3.8/3.8 MB</span> <span class="ansi-red-fg">3.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
Collecting huggingface-hub&lt;1.0,&gt;=0.11.0
  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">199.8/199.8 kB</span> <span class="ansi-red-fg">3.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>a <span class="ansi-cyan-fg">0:00:01</span>
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (4.65.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (6.0)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (1.24.2)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.11.0-&gt;transformers) (4.4.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;transformers) (1.26.14)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;transformers) (2.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests-&gt;transformers) (2022.12.7)
Installing collected packages: tokenizers, huggingface-hub, transformers
Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.2
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">BioGptTokenizer</span><span class="p">,</span> <span class="n">BioGptForCausalLM</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 加载模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BioGptForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;microsoft/biogpt-large&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading (…)lve/main/config.json:   0%|          | 0.00/658 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading pytorch_model.bin:   0%|          | 0.00/6.29G [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">markdown</span>
<span class="kn">import</span> <span class="nn">IPython</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">revChatGPT.V1</span> <span class="kn">import</span> <span class="n">Chatbot</span><span class="p">,</span> <span class="n">configure</span>


<span class="n">bot</span> <span class="o">=</span> <span class="n">Chatbot</span><span class="p">(</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">configure</span><span class="p">(),</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="s1">&#39;a2a0e9d8-b880-4873-95b4-59ac6efdbb23&#39;</span><span class="p">,</span>
    <span class="n">lazy_loading</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">用 Hugging Face 下载的模型一般存储在哪里？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">):</span>
    <span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]))</span>
    <span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_markdown rendered_html output_subarea ">
<p>使用 Hugging Face 下载的模型一般存储在本地的 <code>~/.cache/huggingface/</code> 目录下。该目录下会按照模型名称和版本号的组合来创建相应的子目录，存储着相应的模型文件和元数据文件。可以通过指定 <code>cache_dir</code> 参数来修改默认的存储路径。</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--microsoft--biogpt-large/
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/huggingface/hub/models--microsoft--biogpt-large/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>5.9G	/Users/saintway/.cache/huggingface/hub/models--microsoft--biogpt-large/
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>sacremoses
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting sacremoses
  Downloading sacremoses-0.0.53.tar.gz (880 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">880.6/880.6 kB</span> <span class="ansi-red-fg">3.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status &#39;done&#39;
Requirement already satisfied: regex in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (2022.10.31)
Requirement already satisfied: six in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (1.16.0)
Requirement already satisfied: click in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (8.1.3)
Collecting joblib
  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">298.0/298.0 kB</span> <span class="ansi-red-fg">3.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>a <span class="ansi-cyan-fg">0:00:01</span>
Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (4.65.0)
Building wheels for collected packages: sacremoses
  Building wheel for sacremoses (setup.py): started
  Building wheel for sacremoses (setup.py): finished with status &#39;done&#39;
  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=ef1e1d98064b22881c14de405dff663a3972fb9f39a92195a28612459e1de7f9
  Stored in directory: /Users/saintway/Library/Caches/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb
Successfully built sacremoses
Installing collected packages: joblib, sacremoses
Successfully installed joblib-1.2.0 sacremoses-0.0.53
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 加载分词器</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BioGptTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;microsoft/biogpt-large&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.24M [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading (…)olve/main/merges.txt:   0%|          | 0.00/566k [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading (…)cial_tokens_map.json:   0%|          | 0.00/119 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading (…)okenizer_config.json:   0%|          | 0.00/256 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">用 Hugging Face 下载的 tokenizer 一般存储在哪里？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">):</span>
    <span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]))</span>
    <span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_markdown rendered_html output_subarea ">
<p>使用 Hugging Face 下载的 tokenizer 存储位置取决于所选择的 tokenizer。一些 tokenizer 会默认存储在缓存目录中，例如 <code>$HOME/.cache/huggingface/tokenizers</code>，而其他 tokenizer 可能需要手动指定保存位置。在使用 tokenizer 时，可以使用 <code>from_pretrained</code> 方法指定 tokenizer 的名称和路径来加载已下载的 tokenizer。例如：</p>
<pre><code>from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-uncased&quot;, cache_dir=&quot;/path/to/tokenizer&quot;)
</code></pre>
<p>这里 <code>cache_dir</code> 参数指定了 tokenizer 存储的路径。如果未指定该参数，则默认使用缓存目录。</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--microsoft--biogpt-large/snapshots/c6a5136a91c5e3150d9f05ab9d33927a3210a22e
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 0
drwxr-xr-x  9 saintway  staff   288B Mar 21 23:18 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x  3 saintway  staff    96B Mar 21 22:31 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
lrwxr-xr-x  1 saintway  staff    52B Mar 21 22:31 <span class="ansi-magenta-fg">config.json</span> -&gt; ../../blobs/6781cfc676cb2384020b1b5fdd04817536c723fb
lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 <span class="ansi-magenta-fg">generation_config.json</span> -&gt; ../../blobs/9475ded3180a2d64c6903ebcf2aeb0705703c12a
lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 <span class="ansi-magenta-fg">merges.txt</span> -&gt; ../../blobs/01e121aa8483873879577612f38761f2fd9ce5ae
lrwxr-xr-x  1 saintway  staff    76B Mar 21 23:17 <span class="ansi-magenta-fg">pytorch_model.bin</span> -&gt; ../../blobs/d1753ea5af6449aaf63a105a59a619632b78cbfc2c294ba78f3164156af8c8bf
lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 <span class="ansi-magenta-fg">special_tokens_map.json</span> -&gt; ../../blobs/e66da1703089a0329ca9eaf51638805d8ce1b322
lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 <span class="ansi-magenta-fg">tokenizer_config.json</span> -&gt; ../../blobs/e044f8771c083e25f9accfecb9c8f1408cb3c42f
lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 <span class="ansi-magenta-fg">vocab.json</span> -&gt; ../../blobs/66ddce4fab432cd017c0db812211c30d25acce1e
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 设置随机数种子</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">2023</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 设置 pipeline</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
    <span class="s1">&#39;text-generation&#39;</span><span class="p">,</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 生成文本</span>
<span class="c1"># max new tokens：生成的最多 token 数量</span>
<span class="c1"># num_return_sequences：生成的序列个数</span>
<span class="n">generator</span><span class="p">(</span><span class="s1">&#39;COVID 19 is&#39;</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;generated_text&#39;: &#39;COVID 19 is a novel coronavirus that emerged in 2 0 1 9 and caused a global pandemic. The virus is a positive-&#39;}]</pre>
</div>

</div>

</div>
</div>

</div>
 




	</div>

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
		
          <li class="prev disabled"><a><i class="fa fa-arrow-circle-o-left"></i>上一页</a></li>
        

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2023/03/14/ChatGPT-Robot-for-WhatsApp/" class="alignright next">下一页<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">留言</h2>

  <script data-isso="https://jhub.name/isso/" src="https://jhub.name/isso/js/embed.min.js"></script>
  <section id="isso-thread"></section>
  
</section>

	
	</div> <!-- col-md-9/col-md-12 -->
	
	
		<div class="col-md-3"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2023-03-21 
	</div>
	

	<!-- categories -->
    

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/Notebooks/">Notebooks<span>15</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	

</div><!-- row -->

	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2023 Andrew
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>

</html>
