<!DOCTYPE HTML>
<html>

<head>

  <meta charset="utf-8">
  
  <title>Text2Vec | Andrew&#39;s Blog</title>
  <meta name="author" content="Andrew">
  
  <meta name="description" content="Text2Vec&amp;#182;
Sentence Transformer
CoSENT hfl/chinese-macbert-base
CoSENT hfl/chinese-lert-large
GanymedeNil/text2vec-large-chinese









In&amp;nbsp;">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Text2Vec"/>
  <meta property="og:site_name" content="Andrew&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/notebook.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/tabs.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  <script src="/js/tabs.js"></script>

  <!-- analytics -->
  



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration -->

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Andrew&#39;s Blog</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> Text2Vec</h1>
		</div>		
	



<div class="row post">
	<!-- cols -->
	
	<div class="col-md-9">
	

			

	<!-- content -->
	<div class="mypage">
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Text2Vec"><a target="_blank" rel="noopener" href="https://github.com/shibing624/text2vec">Text2Vec</a><a class="anchor-link" href="#Text2Vec">&#182;</a></h2><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers">Sentence Transformer</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/shibing624/text2vec-base-chinese">CoSENT hfl/chinese-macbert-base</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/GanymedeNil/text2vec-large-chinese">CoSENT hfl/chinese-lert-large</a><ul>
<li>GanymedeNil/text2vec-large-chinese</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>all-mpnet-base-v2</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;sentence-transformers/all-mpnet-base-v2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 384, &#39;do_lower_case&#39;: False}) with Transformer model: MPNetModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 768, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
  (2): Normalize()
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
total 857056
drwxr-xr-x  16 saintway  staff   512B Apr 12 14:31 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   5 saintway  staff   160B Apr 19 17:23 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 12 14:28 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 12 14:28 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff    10K Apr 12 14:28 README.md
-rw-r--r--   1 saintway  staff   571B Apr 12 14:28 config.json
-rw-r--r--   1 saintway  staff   116B Apr 12 14:28 config_sentence_transformers.json
-rw-r--r--   1 saintway  staff    38K Apr 12 14:28 data_config.json
-rw-r--r--   1 saintway  staff   349B Apr 12 14:31 modules.json
-rw-r--r--   1 saintway  staff   418M Apr 12 14:31 pytorch_model.bin
-rw-r--r--   1 saintway  staff    53B Apr 12 14:31 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   239B Apr 12 14:31 special_tokens_map.json
-rw-r--r--   1 saintway  staff   455K Apr 12 14:31 tokenizer.json
-rw-r--r--   1 saintway  staff   363B Apr 12 14:31 tokenizer_config.json
-rw-r--r--   1 saintway  staff    13K Apr 12 14:31 train_script.py
-rw-r--r--   1 saintway  staff   226K Apr 12 14:31 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
cat<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/modules.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[
  {
    &#34;idx&#34;: 0,
    &#34;name&#34;: &#34;0&#34;,
    &#34;path&#34;: &#34;&#34;,
    &#34;type&#34;: &#34;sentence_transformers.models.Transformer&#34;
  },
  {
    &#34;idx&#34;: 1,
    &#34;name&#34;: &#34;1&#34;,
    &#34;path&#34;: &#34;1_Pooling&#34;,
    &#34;type&#34;: &#34;sentence_transformers.models.Pooling&#34;
  },
  {
    &#34;idx&#34;: 2,
    &#34;name&#34;: &#34;2&#34;,
    &#34;path&#34;: &#34;2_Normalize&#34;,
    &#34;type&#34;: &#34;sentence_transformers.models.Normalize&#34;
  }
]</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
cat<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/sentence_bert_config.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{
  &#34;max_seq_length&#34;: 384,
  &#34;do_lower_case&#34;: false
}</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
cat<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/1_Pooling/config.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{
  &#34;word_embedding_dimension&#34;: 768,
  &#34;pooling_mode_cls_token&#34;: false,
  &#34;pooling_mode_mean_tokens&#34;: true,
  &#34;pooling_mode_max_tokens&#34;: false,
  &#34;pooling_mode_mean_sqrt_len_tokens&#34;: false
}</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/data_config.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> 40K	/Users/saintway/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/data_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>all-MiniLM-L6-v2</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 256, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 384, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
  (2): Normalize()
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
total 210456
drwxr-xr-x  16 saintway  staff   512B Apr 19 17:38 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   6 saintway  staff   192B Apr 19 17:38 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 19 17:37 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 19 17:38 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff    10K Apr 19 17:38 README.md
-rw-r--r--   1 saintway  staff   612B Apr 19 17:38 config.json
-rw-r--r--   1 saintway  staff   116B Apr 19 17:38 config_sentence_transformers.json
-rw-r--r--   1 saintway  staff    38K Apr 19 17:38 data_config.json
-rw-r--r--   1 saintway  staff   349B Apr 19 17:38 modules.json
-rw-r--r--   1 saintway  staff    87M Apr 19 17:38 pytorch_model.bin
-rw-r--r--   1 saintway  staff    53B Apr 19 17:38 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   112B Apr 19 17:38 special_tokens_map.json
-rw-r--r--   1 saintway  staff   455K Apr 19 17:38 tokenizer.json
-rw-r--r--   1 saintway  staff   350B Apr 19 17:38 tokenizer_config.json
-rw-r--r--   1 saintway  staff    13K Apr 19 17:38 train_script.py
-rw-r--r--   1 saintway  staff   226K Apr 19 17:38 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>CoSENT hfl/chinese-macbert-base</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Full Model Architecture:</p>
<pre><code>CoSENT(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_mean_tokens': True})
)
</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;shibing624/text2vec-base-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 128, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 768, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/modules.json
<span class="p">[</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Transformer&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;1_Pooling&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Pooling&quot;</span>
  <span class="p">}</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Overwriting /Users/saintway/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/modules.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/sentence_bert_config.json
<span class="p">{</span>
  <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
  <span class="s2">&quot;do_lower_case&quot;</span><span class="p">:</span> <span class="n">false</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /Users/saintway/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/sentence_bert_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
mkdir<span class="w"> </span>-p<span class="w"> </span>~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/1_Pooling
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/1_Pooling/config.json
<span class="p">{</span>
  <span class="s2">&quot;word_embedding_dimension&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>
  <span class="s2">&quot;pooling_mode_mean_tokens&quot;</span><span class="p">:</span> <span class="n">true</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /Users/saintway/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/1_Pooling/config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 831776
drwxr-xr-x  13 saintway  staff   416B Apr 19 19:22 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   7 saintway  staff   224B Apr 19 17:43 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 19 17:42 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 19 19:22 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff   4.0K Apr 19 17:43 README.md
-rw-r--r--   1 saintway  staff   856B Apr 19 17:43 config.json
-rw-r--r--   1 saintway  staff   546B Apr 19 17:43 logs.txt
-rw-r--r--   1 saintway  staff   230B Apr 19 19:17 modules.json
-rw-r--r--   1 saintway  staff   390M Apr 19 17:43 pytorch_model.bin
-rw-r--r--   1 saintway  staff    54B Apr 19 19:11 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   112B Apr 19 17:43 special_tokens_map.json
-rw-r--r--   1 saintway  staff   319B Apr 19 17:43 tokenizer_config.json
-rw-r--r--   1 saintway  staff   107K Apr 19 17:43 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>CoSENT hfl/chinese-lert-large</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;GanymedeNil/text2vec-large-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 128, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 1024, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/modules.json
<span class="p">[</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Transformer&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;1_Pooling&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Pooling&quot;</span>
  <span class="p">}</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /home/jupyter-saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/modules.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/sentence_bert_config.json
<span class="p">{</span>
  <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
  <span class="s2">&quot;do_lower_case&quot;</span><span class="p">:</span> <span class="n">false</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /home/jupyter-saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/sentence_bert_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
mkdir<span class="w"> </span>-p<span class="w"> </span>~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/1_Pooling
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/1_Pooling/config.json
<span class="p">{</span>
  <span class="s2">&quot;word_embedding_dimension&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
  <span class="s2">&quot;pooling_mode_mean_tokens&quot;</span><span class="p">:</span> <span class="n">true</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /home/jupyter-saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/1_Pooling/config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 2569336
drwxr-xr-x  14 saintway  staff   448B Apr 19 19:28 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   7 saintway  staff   224B Apr 19 17:43 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.4K Apr 19 17:16 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 19 19:28 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff   317B Apr 19 17:16 README.md
-rw-r--r--   1 saintway  staff   821B Apr 19 17:16 config.json
-rw-r--r--   1 saintway  staff    69B Apr 19 17:16 eval_results.txt
-rw-r--r--   1 saintway  staff   230B Apr 19 19:28 modules.json
-rw-r--r--   1 saintway  staff   1.2G Apr 19 17:23 pytorch_model.bin
-rw-r--r--   1 saintway  staff    54B Apr 19 19:28 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   125B Apr 19 17:23 special_tokens_map.json
-rw-r--r--   1 saintway  staff   429K Apr 19 17:23 tokenizer.json
-rw-r--r--   1 saintway  staff   514B Apr 19 17:23 tokenizer_config.json
-rw-r--r--   1 saintway  staff   107K Apr 19 17:23 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.2G	/Users/saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Transformer and Indexer</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;GanymedeNil/text2vec-large-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">faiss</span>
<span class="n">indexer</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Preparing Text</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">BSHTMLLoader</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s1">&#39;_morning/htm&#39;</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">BSHTMLLoader</span><span class="p">)</span>
<span class="n">raw_documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="k">for</span> <span class="n">raw_document</span> <span class="ow">in</span> <span class="n">raw_documents</span><span class="p">:</span>
    <span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="s1">&#39;。</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Embedding</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">embed</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">sentences</span>

    <span class="c1"># words = extra_text.split(&#39; &#39;)</span>
    <span class="c1"># sentences = [words[i: i+num_words] for i in range(0, len(words), num_words)]</span>
    <span class="c1"># sentences = [&#39; &#39;.join(word_list) for word_list in sentences]</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="s1">&#39;。</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))):</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">sentence</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Number of Sentences:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
    <span class="c1"># print(sentences)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Embedding the sentences...&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">raw_document</span> <span class="ow">in</span> <span class="n">raw_documents</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">embeddings</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1024</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Loading Faiss Indexer from Disk</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">pickle</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="c1"># load vectorstore</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">indexer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Indexing</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Building the index...&#39;</span><span class="p">)</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">index.ntotal:&#39;</span><span class="p">,</span> <span class="n">indexer</span><span class="o">.</span><span class="n">ntotal</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Saving Faiss Indexer to Disk</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="c1"># save vectorstore</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">indexer</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/lert_indexing_morning.pkl
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
-rw-r--r--  1 saintway  staff    55M Apr 19 21:42 /Users/saintway/lert_indexing_morning.pkl
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Searching</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">retrieve</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Searching for:&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">xq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
    <span class="n">D</span><span class="p">,</span> <span class="n">I</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">xq</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distance:&#39;</span><span class="p">,</span> <span class="n">D</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Index:&#39;</span><span class="p">,</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Retrieving related information...&#39;</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">result:&#39;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;你知道什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;第八周讲了什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;七倍加强的灵是什么？&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Retrieving extra information...
[656.14075 686.03516 686.03516 701.83813 708.9243  709.8529  711.5835
 729.1748  740.6108  756.9905  759.0303  759.19086 760.30756 762.8627
 763.7213  764.0825  770.2078  770.9846  771.6991  776.6118 ]
[ 5330  6025  8696  4925  1817   292  3119  6404  2026  5745  2730  9065
   509 12541 12823  1832 12689   263 10313  2867]

result: 你会明白主的心思，你也会知道什么是主的意愿。
你知道每一个十字路口都是一个十字架么？有的是大十字架，有的是小十字架，但它们都是十字架。
你知道每一个十字路口都是一个十字架么？有的是大十字架，有的是小十字架，但它们都是十字架。
你晓得误会是从哪里来的么？它的根源常常是不纯净。
我和你们交通这事，是要让你们晓得我们的书撰写的方式。
当我们愿意对祂说，“主啊，我不知道自己的光景如何，也不知道自己需要什么；但是你知道。
……“我从前风闻有你，现在亲眼看见你。
反之，我们该问这里的真理是什么，也该问顺从真理是什么意思。
九节说，“少年人用什么使他的行径纯洁呢？是要遵行你的话。
那时你为你的大名要怎样行呢？
有些人不能明白主的恢复是怎么一回事。
帖后2:5　我还在你们那里的时候，曾一再把这些事告诉你们，你们不记得么？
我要向全宇宙宣告，无论事情怎样，我相信你是我的神。
”当时我并不知道那是什么，直到我进到召会中，与你们一同站在一的立场上。
就一面的意义说，我们不知道什么，也不作什么。
到那时候你就晓得如何向别人陈明真理，不是仅仅激发或激动人，而是使人扎实，得着真理的构成（李常受文集一九八四年第二册，四○二至四○三页）。
论到借着赞美主而从事属灵的争战，我要温柔地请问你们这些一同学习的弟兄姊妹：“在这个月里，你个人向着主有几次赞美呢？今年你赞美主几次呢？年长的圣徒们，在主的恢复这许多年来，你有没有赞美主呢？”有些人可能说，“有。
可能你经历一段感情的结束，当时不明白为什么会发生这样的事，日后回想，才懂得感谢神。
在宇宙中有这么多的东西，有这么多的故事；但是六千年来，还没有一个人看见过神。
然而，我们是否真正明白在主的恢复里是什么意思，主所恢复的又是什么？以下的信息会指出三个主要的点，说明主的恢复到底是什么。


Retrieving extra information...
[336.1584  336.1584  336.1584  336.1584  336.1584  336.1584  437.74524
 457.0722  491.19138 524.97955 547.4698  561.1646  561.1646  635.23145
 641.3999  641.3999  641.3999  641.3999  641.3999  641.3999 ]
[10211 10762 11196 12282 12928 13579 13596 11211 12946 12292 10226  5370
  9340  2110  3021  4193  4830  5107  5176  6307]

result: 第八周
第八周
第八周
第八周
第八周
第八周
第八周　周六
第八周　周一
第八周　周五
第八周　周四
第八周　周二
第八篇
第八篇
”（八页）
第七周
第七周
第七周
第七周
第七周
第七周


Retrieving extra information...
[149.68991 257.37964 293.2322  390.10983 412.68298 416.7586  426.44324
 448.9715  448.9715  448.9715  474.88263 485.05545 510.15057 515.02356
 539.4849  539.485   539.485   539.485   543.3683  544.59344]
[ 9906  9659  9919  3820  9914  3819  9908  6576  9134 13120  3777  9967
    28    99    13    79  4119  5287  9977  9915]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
我们需要在以下各方面享受基督作七倍加强的灵。
七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。
我们需要在以下各方面享受基督作七倍加强的灵
”耶和华的七眼也是七倍加强的灵。
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。
至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。
随着金这样成形在你里面，就会有七灵照耀并彰显神。
召会作灯台有七灯，就是神的七灵。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶
我们若向主认真，愿意起来建造神的殿，我们就需要看见，今天在主恢复的众召会中间，最大的需要就是经历七倍加强的灵。

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。\n今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。\n这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。\n我们需要在以下各方面享受基督作七倍加强的灵。\n七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。\n我们需要在以下各方面享受基督作七倍加强的灵\n”耶和华的七眼也是七倍加强的灵。\n三\u3000我们需要在以下各方面享受基督作七倍加强的灵：\n三\u3000我们需要在以下各方面享受基督作七倍加强的灵：\n三\u3000我们需要在以下各方面享受基督作七倍加强的灵：\n那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。\n至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。\n随着金这样成形在你里面，就会有七灵照耀并彰显神。\n召会作灯台有七灯，就是神的七灵。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶\n我们若向主认真，愿意起来建造神的殿，我们就需要看见，今天在主恢复的众召会中间，最大的需要就是经历七倍加强的灵。\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;七倍加强的灵是什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;问题：七倍加强的灵是什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;用户提供了一段文本片段，但没有明确说明文档的主题。</span><span class="se">\n</span><span class="s1">问题：七倍加强的灵是什么？&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Retrieving extra information...
[149.68991 257.37964 293.2322  390.10983 412.68298 416.7586  426.44324
 448.9715  448.9715  448.9715  474.88263 485.05545 510.15057 515.02356
 539.4849  539.485   539.485   539.485   543.3683  544.59344]
[ 9906  9659  9919  3820  9914  3819  9908  6576  9134 13120  3777  9967
    28    99    13    79  4119  5287  9977  9915]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
我们需要在以下各方面享受基督作七倍加强的灵。
七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。
我们需要在以下各方面享受基督作七倍加强的灵
”耶和华的七眼也是七倍加强的灵。
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。
至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。
随着金这样成形在你里面，就会有七灵照耀并彰显神。
召会作灯台有七灯，就是神的七灵。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶
我们若向主认真，愿意起来建造神的殿，我们就需要看见，今天在主恢复的众召会中间，最大的需要就是经历七倍加强的灵。


Retrieving extra information...
[207.48007 293.95245 316.6468  394.41498 415.14142 427.4111  440.00018
 440.00018 440.00018 456.50128 494.71838 507.38333 543.869   543.869
 543.869   546.0684  546.0684  546.0684  546.0684  550.43463]
[ 9906  9659  9919  3820  3819  9914  6576  9134 13120  9908  3777  9967
  1349  4167  5299    13    79  4119  5287  6918]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
我们需要在以下各方面享受基督作七倍加强的灵。
我们需要在以下各方面享受基督作七倍加强的灵
七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
”耶和华的七眼也是七倍加强的灵。
那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。
至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。
a　召会作为灯台，乃是三一神扎实的具体化身，有七倍加强的灵作为神神圣性情的油。
a　召会作为灯台，乃是三一神扎实的具体化身，有七倍加强的灵作为神神圣性情的油。
a　召会作为灯台，乃是三一神扎实的具体化身，有七倍加强的灵作为神神圣性情的油。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。


Retrieving extra information...
[455.2392  474.6516  554.92584 554.92584 554.92584 555.4395  558.1987
 561.82495 562.31335 562.31335 562.31335 573.8733  575.1859  578.14307
 582.34247 584.78894 590.16046 591.0485  592.72095 594.661  ]
[ 9906  9919 11058 13036 13470  1623  1622   813  3182  3861  5811  6918
  1880   488  9659  3820 13501  9728  3819  4528]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
一　很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
一　很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
一　很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战
”然而，主给我们的不是胆怯的灵，乃是能力的灵（参提后一7）。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。
然而在六节，当以斯拉在他的叙述中说到自己时，只说“他是经学家”，而不提他是亚伦家的祭司；他没有高举自己祭司的身分。
但那只是起始阶段的信心，并不是路加十八章里主要寻找的信心。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
我们需要在以下各方面享受基督作七倍加强的灵。
在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎不懂得什么叫作属灵的争战。
然而，我讲这篇信息时，里面并没有责备的灵。
我们需要在以下各方面享受基督作七倍加强的灵
提前6:7　因为我们没有带什么到世界来，也不能带什么去；

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。\n这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。\n一\u3000很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n一\u3000很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n一\u3000很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战\n”然而，主给我们的不是胆怯的灵，乃是能力的灵（参提后一7）。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。\n然而在六节，当以斯拉在他的叙述中说到自己时，只说“他是经学家”，而不提他是亚伦家的祭司；他没有高举自己祭司的身分。\n但那只是起始阶段的信心，并不是路加十八章里主要寻找的信心。\n今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。\n我们需要在以下各方面享受基督作七倍加强的灵。\n在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎不懂得什么叫作属灵的争战。\n然而，我讲这篇信息时，里面并没有责备的灵。\n我们需要在以下各方面享受基督作七倍加强的灵\n提前6:7\u3000因为我们没有带什么到世界来，也不能带什么去；\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Chat with PDF</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_in_english</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;You are an AI agent that summarizes chat in less than three setences.&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_in_chinese</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;系统&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">chats_in_english</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;You are an AI assistant providing helpful advice.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;You are given the following extracted parts of a long document and a question.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;Provide a conversational answer based on the context provided.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;You should only provide hyperlinks that reference the context below.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;Do NOT make up hyperlinks.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;If you can</span><span class="se">\&#39;</span><span class="s1">t find the answer in the context below, use your prior knowledge,</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;but in most of the cases the answer will be in the context.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="c1"># &#39;If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\n&#39; + \</span>
    <span class="s1">&#39;Answer in Markdown format.</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">chats_in_chinese</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;系统&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;你是一个提供有用建议的 AI 助手。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;你被提供了一份长文档的一部分（额外信息）和一个问题。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;请根据我所提供的文本提供会话式的回答。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;你只应该提供与下面的文本相关的超链接。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;**不要**编造超链接。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;如果在下面的文本中找不到答案，可以使用你先前所知道的知识，</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;但在大多数情况下，答案是在文本中的。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="c1"># &#39;如果问题与上下文不相关，请礼貌地回复您只回答与上下文相关的问题。\n&#39; + \</span>
    <span class="s1">&#39;请用中文以 Markdown 格式回答。</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">PyPDF2</span>

<span class="k">def</span> <span class="nf">extract_text</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Extract text from a PDF file.&#39;&#39;&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">pdf_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">page</span><span class="o">.</span><span class="n">extract_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">PyPDF2</span><span class="o">.</span><span class="n">PdfReader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">pages</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_the_bot</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">,</span> <span class="n">openai_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;split sentences in chinese&#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OpenAI Key:&#39;</span><span class="p">,</span> <span class="n">openai_key</span><span class="p">)</span>

    <span class="n">pdf_content</span> <span class="o">=</span> <span class="n">extract_text</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Text Length:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_text</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Building the index...&#39;</span><span class="p">)</span>
    <span class="n">indexer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">pdf_content</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">index.ntotal:&#39;</span><span class="p">,</span> <span class="n">indexer</span><span class="o">.</span><span class="n">ntotal</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pdf_content</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">chat</span><span class="p">(</span><span class="n">chat_history</span><span class="p">,</span> <span class="n">user_input</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;chat in chinese&#39;&#39;&#39;</span>
    <span class="k">global</span> <span class="n">sentences</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">messages_in_chinese:&#39;</span><span class="p">,</span> <span class="n">messages_in_chinese</span><span class="p">)</span>
    <span class="c1"># messages_in_english.append({&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Question:\n&#39; + user_input})</span>
    <span class="c1"># print(&#39;\nmessages_in_english:&#39;, messages_in_english)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Summarizing the chat history...&#39;</span><span class="p">)</span>

    <span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">messages_in_chinese</span>
    <span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Summarized Histoy: </span><span class="si">{</span><span class="n">summary</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">extra_info</span> <span class="o">=</span> <span class="n">retrieve</span><span class="p">(</span><span class="n">summary</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;问题：&#39;</span> <span class="o">+</span> <span class="n">user_input</span><span class="p">)</span>

    <span class="n">chats_in_chinese</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;用户&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;额外信息：</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">extra_info</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;问题：&#39;</span> <span class="o">+</span> <span class="n">user_input</span><span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">chats_in_chinese:&#39;</span><span class="p">,</span> <span class="n">chats_in_chinese</span><span class="p">)</span>
    <span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">chats_in_chinese</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">chats_in_chinese</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
    <span class="p">)</span>

    <span class="n">chat_output</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">ChatGPT: </span><span class="si">{</span><span class="n">chat_output</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># messages_in_chinese.append({&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: user_input})</span>
    <span class="c1"># messages_in_chinese.append({&#39;role&#39;: &#39;助手&#39;, &#39;content&#39;: chat_output})</span>
    <span class="k">yield</span> <span class="n">chat_history</span> <span class="o">+</span> <span class="p">[(</span><span class="n">user_input</span><span class="p">,</span> <span class="n">chat_output</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gradio</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_demo</span><span class="p">(</span><span class="n">mock_openai</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Blocks</span><span class="p">()</span> <span class="k">as</span> <span class="n">demo</span><span class="p">:</span>
        <span class="n">gradio</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="s1">&#39;Chat with a PDF document&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Tab</span><span class="p">(</span><span class="s1">&#39;Select PDF&#39;</span><span class="p">):</span>
            <span class="n">pdf</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">File</span><span class="p">()</span>
            <span class="n">openai_key</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;OpenAI API Key&#39;</span><span class="p">,)</span>
            <span class="n">text_output</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;PDF content&#39;</span><span class="p">)</span>
            <span class="n">text_button</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="s1">&#39;Build the Bot!!!&#39;</span><span class="p">)</span>
            <span class="n">text_button</span><span class="o">.</span><span class="n">click</span><span class="p">(</span><span class="n">build_the_bot</span><span class="p">,</span> <span class="p">[</span><span class="n">pdf</span><span class="p">,</span> <span class="n">openai_key</span><span class="p">],</span> <span class="n">text_output</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Tab</span><span class="p">(</span><span class="s1">&#39;Knowledge Bot&#39;</span><span class="p">):</span>
            <span class="n">chatbot</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Chatbot</span><span class="p">()</span>
            <span class="n">message</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="s1">&#39;What is this document about?&#39;</span><span class="p">)</span>
            <span class="n">message</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="p">[</span><span class="n">chatbot</span><span class="p">,</span> <span class="n">message</span><span class="p">],</span> <span class="n">chatbot</span><span class="p">)</span>
    <span class="n">demo</span><span class="o">.</span><span class="n">queue</span><span class="p">()</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">debug</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">True</span>
    <span class="n">demo</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ipymock</span> <span class="kn">import</span> <span class="n">do</span>
<span class="kn">from</span> <span class="nn">ipymock.browser</span> <span class="kn">import</span> <span class="n">common</span><span class="p">,</span> <span class="n">get_conversation</span><span class="p">,</span> <span class="n">mock_openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">common</span><span class="o">.</span><span class="n">conversation_id</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do</span><span class="p">(</span>
    <span class="n">mock_openai</span><span class="o">=</span><span class="n">mock_openai</span><span class="p">,</span>
    <span class="n">test_demo</span><span class="o">=</span><span class="n">test_demo</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
=&gt; no.0  ::tools::test_demo  setup  passed

Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div><iframe src="http://127.0.0.1:7860/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen></iframe></div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 本文讨论 TerraUSD 稳定币的稳定机制和去年的脱锚事件，并强调了维持“基础锚定市场”和“外部锚定市场”的套利行为所控制的市场的规模比较对于了解稳定币的稳定性很重要。最后，文章提出了将“外部锚定市场”转化为“基础锚定市场”是提高系统稳定性的唯一方法。

Retrieving extra information...
[575.85126 580.8882  583.3136  587.01587 588.3385  609.59955 610.3556
 611.7924  611.7924  611.7924  612.34534 612.8718  613.65656 614.2593
 617.09534 619.9896  622.2654  624.4966  624.9232  625.8043 ]
[ 6397  6622  3147 12978  4241  4792 11808  3182  3861  5811  6711  3874
  8512  2782  6918  1994 13386  3155  5450 12342]

result: 实际上，这是指我们的心思、情感和意志，从神以外的各样事物中蒙拯救，而固定在神这唯一的对象和独一的目标上。
因此，一个地方召会建立在其上的召会立场，必须是由“一”所构成，并在“一”里得维系；这一乃是由那灵执行，并由召会所在地保守的（李常受文集一九九三年第二册，九○至九一页）。
I.　The Lord&#39;s recovery is unique, and it must be absolutely pure, single, and holy, without any mixture; thus, we need Ezras and Nehemiahs to carry out a purifying work; in all the steps of the Lord&#39;s recovery, there is the need of purification:
要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除了任何形式的狡猾雄心。
……我们若不应用这原则，一切未受钉十字架察验的天然性能、才干和美德，在我们中间就会像“野兽”一样。
我们必须非常纯净，使圣别的种类永远不会与任何外邦的事物混合（李常受文集一九六九年第二册，四九六至四九七页）。
E.　Nehemiah, as the governor, in the position of a king, was a man with a pure heart for the rebuilding of Jerusalem&#39;s wall in carrying out God&#39;s economy; he was a pattern of what a leader among God&#39;s people should be—cf. 1 Tim. 3:2-7; 1 Pet. 5:1-3:
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
本篇信息的篇题是“洁净被掳归回之人的内在意义”。
我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。
2.　The problem is that we have come back from Babylon to Jerusalem, yet at Jerusalem we may still keep many things for our own interests; we may not offer everything on the altar for God&#39;s interests and for God&#39;s satisfaction—Rom. 12:1:
在主恢复之外的人无法理解我们中间到底是怎么运作的。
对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。
这里所说重新构成的需要，有如以色列人从埃及出来之时的需要；但从巴比伦归回的百姓因着和外邦人通婚而有了搀杂，使得情形更加艰难。
B.　Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God&#39;s eternal economy:
a.　The Lord&#39;s recovery is the holy seed; we must be so pure that the holy seed will never be mingled with anything heathen.
1.　In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;
这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n1.\u3000It is very difficult to find a person whose spirit is pure (7:1); pureness is the prerequisite in the leadership and a basic condition of our service (1 Tim. 3:9; 1:5); the problem of mixture is the greatest problem among workers; impureness is often the source of misunderstanding and suspicion (2 Tim. 1:3; 1 Tim. 3:9; Titus 1:15).\n反之，我们该问这里的真理是什么，也该问顺从真理是什么意思。\nA.\u3000All of us should look to the Lord and pray that we will have dispensational value to God; we need to ask ourselves what we are doing to close this dispensation and to bring in the next age, the kingdom age; this is a special time, so there is the need of special believers to do a special work.\nVI.\u3000With God\&#39;s move, as the divine history, in man\&#39;s history, there is the new creation—the new man with a new heart, a new spirit, a new life, a new nature, a new history, and a new consummation; we praise the Lord that we are in the divine history, experiencing and enjoying the mysterious, divine things for our organic salvation, so that we may make ourselves ready to become His overcoming bride to bring Him back—Hymns, #16; Rom. 5:10, 17-18, 21; 6:4; Ezek. 36:26; 2 Cor. 3:16-18; Matt. 5:8; Titus 3:5; Eph. 5:26-27; 6:17-18; Rev. 19:7; Matt. 24:44; 25:10.\n用这样的题目作为本次训练的总结，甚至作整本圣经结晶读经的总结，似乎让人感到意外。\nC.\u3000There was the need of teaching and reconstitution to bring the people of God into a culture that was according to God, a culture that expressed God; this kind of culture requires a great deal of education—v. 8.\n1.\u3000A factious man is a heretical, sectarian man who causes divisions by forming parties in the church according to his own opinions; in order to maintain good order in the church, a factious, divisive person should be refused, rejected, after a first and second admonition—v. 10.\n以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\n1.\u3000Literally, the Greek words rendered &#34;faith&#34; mean &#34;the faith&#34;; this denotes the persistent faith for our persistent prayer, like that of the widow.\nI.\u3000The intrinsic significance of Ezra\&#39;s ministry is embodied in the words purification, education, and reconstitution; the intrinsic significance of Nehemiah\&#39;s leadership is embodied in the words separation, protection, and expression; we need to cooperate with the Lord in His heavenly ministry to build up the church as the house of God and the kingdom of God by living out and working out the New Jerusalem according to this intrinsic significance—1 Kings 8:48; Psa. 48:1-2; 1 Tim. 3:15; Eph. 2:21-22.\n”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。\nC.\u3000The law makes demands on man according to what God is; grace supplies man with what God is to meet what God demands; grace is God enjoyed by man—John 1:16-17; Gal. 6:18; 2 Cor. 13:14; 12:9; 1 Pet. 4:10; Eph. 3:2; 4:29; 6:24.\nb.\u3000If we see that the prayers of the greatest worth are prayers in ascension, then we can understand that prayer is a warfare, and we will utter prayers of warfare; such is the nature of the prayer spoken of in Ephesians 6:\n3.\u3000If a church goes astray or is misled, the apostles have the obligation and responsibility to deal with the situation according to God\&#39;s word, which has authority—vv. 26-27; 2 Cor. 10:6; 2 Tim. 1:13; 4:2.\nThe Intrinsic Significance of the Purification of the Returned Captives\n2.\u3000We all need to be helped through the Life-studies and the Recovery Version with the footnotes to see the intrinsic significance of the word of the Bible—Neh. 8:8, 13.\nB.\u3000They were unaware that the dispensation of law was altogether over, that the dispensation of grace should be fully honored, and that any disregard of the distinction between these two dispensations would be against God\&#39;s dispensational administration and would be a great damage to God\&#39;s economical plan for the building up of the church as the expression of Christ—John 1:16-17; Rev. 2:9.\nIII.\u3000In the Lord\&#39;s recovery we need Ezras, priestly teachers who contact God, who are saturated with God, who are one with God, who are mingled with God, who are filled with God, and who are skillful in the Word of God; this is the kind of person who is qualified to be a teacher in the recovery—Matt. 13:52; 2 Cor. 3:5-6; 1 Tim. 2:7; 2 Tim. 1:11:\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n实际上，这是指我们的心思、情感和意志，从神以外的各样事物中蒙拯救，而固定在神这唯一的对象和独一的目标上。\n因此，一个地方召会建立在其上的召会立场，必须是由“一”所构成，并在“一”里得维系；这一乃是由那灵执行，并由召会所在地保守的（李常受文集一九九三年第二册，九○至九一页）。\nI.\u3000The Lord\&#39;s recovery is unique, and it must be absolutely pure, single, and holy, without any mixture; thus, we need Ezras and Nehemiahs to carry out a purifying work; in all the steps of the Lord\&#39;s recovery, there is the need of purification:\n要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除了任何形式的狡猾雄心。\n……我们若不应用这原则，一切未受钉十字架察验的天然性能、才干和美德，在我们中间就会像“野兽”一样。\n我们必须非常纯净，使圣别的种类永远不会与任何外邦的事物混合（李常受文集一九六九年第二册，四九六至四九七页）。\nE.\u3000Nehemiah, as the governor, in the position of a king, was a man with a pure heart for the rebuilding of Jerusalem\&#39;s wall in carrying out God\&#39;s economy; he was a pattern of what a leader among God\&#39;s people should be—cf. 1 Tim. 3:2-7; 1 Pet. 5:1-3:\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n本篇信息的篇题是“洁净被掳归回之人的内在意义”。\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。\n2.\u3000The problem is that we have come back from Babylon to Jerusalem, yet at Jerusalem we may still keep many things for our own interests; we may not offer everything on the altar for God\&#39;s interests and for God\&#39;s satisfaction—Rom. 12:1:\n在主恢复之外的人无法理解我们中间到底是怎么运作的。\n对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。\n这里所说重新构成的需要，有如以色列人从埃及出来之时的需要；但从巴比伦归回的百姓因着和外邦人通婚而有了搀杂，使得情形更加艰难。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\na.\u3000The Lord\&#39;s recovery is the holy seed; we must be so pure that the holy seed will never be mingled with anything heathen.\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。\n\n\n问题：What is this document about?&#39;}]

ChatGPT: 根据文本，召会立场必须由“一”所构成，并在“一”里得维系；这是由那灵执行，并由召会所在地保守的。因此，要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除任何形式的狡猾雄心。需要对付灵重在对付我

messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 好的，这次对话主要涉及到了对人类情感的理解、人工智能在医疗行业的应用、以及人工智能与工作的关系。

Retrieving extra information...
[560.0207  580.6549  599.6284  603.5715  604.7684  605.70654 606.26
 607.6616  609.8817  616.5469  618.50104 620.88055 622.4879  622.8662
 624.0831  626.81396 627.3507  628.6865  629.2973  631.0054 ]
[ 2690 12691  6988  7878 10302  3872  6436  7779  1832  1875   263  2023
  1885  3506 12498  2051  1817  2959 12342  7023]

result: 《对同工长老们以及爱主寻求主者爱心的话》一书，第四章的题目就是“正确的跟随人”。
”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。
我们不该把启示录二十一、二十二章里“纯”、“明净”、“透明”这些辞视为理所当然，我们读的时候，需要对这些辞有更深入、更扩大的领会。
本篇信息乃是要将这些辞一一应用于我们的经历。
并且他这话不是凭空说的，也不是想像出来的；乃是他根据许多的事实，所产生出来的一个感觉。
我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。
因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。
当我们借由这分职事的帮助来读主话的时候，就能看见主的话是何等美妙。
到那时候你就晓得如何向别人陈明真理，不是仅仅激发或激动人，而是使人扎实，得着真理的构成（李常受文集一九八四年第二册，四○二至四○三页）。
”经学家的功用需要配上祭司的功用；祭司的功用是借着我们在灵里与主联合，与主是一而享受主，但其中也需要话。
可能你经历一段感情的结束，当时不明白为什么会发生这样的事，日后回想，才懂得感谢神。
这里所列诗篇一百一十九篇的经节，给我们看见诗人不仅爱神、寻求神的说话，他也有祭司经学家的功用。
我们都该盼望被人这样描述：这位弟兄对圣经爱不释手，并且他手中神的话就是他手中神的智慧。
在篇题里我们看见有人的历史，然而在人的历史里有神的历史。
有些人可能第一次听见这样的话，在此我们也只能讲到一些基本的内容。
”（世界局势与神的行动，三七页）长老与同工都该是祭司教师，就是习练于圣经中的话语，并且善于教导。
我和你们交通这事，是要让你们晓得我们的书撰写的方式。
在《对同工长老们以及爱主寻求主者爱心的话》一书中，有对我们的警告：“你在跟随任何你所欣赏，并叫你受吸引之同工的事上，必须谨慎。
这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。
”我们各人都要在与主私下、亲密的交通中向主祷告，以回应本篇信息的话。


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n1.\u3000It is very difficult to find a person whose spirit is pure (7:1); pureness is the prerequisite in the leadership and a basic condition of our service (1 Tim. 3:9; 1:5); the problem of mixture is the greatest problem among workers; impureness is often the source of misunderstanding and suspicion (2 Tim. 1:3; 1 Tim. 3:9; Titus 1:15).\n反之，我们该问这里的真理是什么，也该问顺从真理是什么意思。\nA.\u3000All of us should look to the Lord and pray that we will have dispensational value to God; we need to ask ourselves what we are doing to close this dispensation and to bring in the next age, the kingdom age; this is a special time, so there is the need of special believers to do a special work.\nVI.\u3000With God\&#39;s move, as the divine history, in man\&#39;s history, there is the new creation—the new man with a new heart, a new spirit, a new life, a new nature, a new history, and a new consummation; we praise the Lord that we are in the divine history, experiencing and enjoying the mysterious, divine things for our organic salvation, so that we may make ourselves ready to become His overcoming bride to bring Him back—Hymns, #16; Rom. 5:10, 17-18, 21; 6:4; Ezek. 36:26; 2 Cor. 3:16-18; Matt. 5:8; Titus 3:5; Eph. 5:26-27; 6:17-18; Rev. 19:7; Matt. 24:44; 25:10.\n用这样的题目作为本次训练的总结，甚至作整本圣经结晶读经的总结，似乎让人感到意外。\nC.\u3000There was the need of teaching and reconstitution to bring the people of God into a culture that was according to God, a culture that expressed God; this kind of culture requires a great deal of education—v. 8.\n1.\u3000A factious man is a heretical, sectarian man who causes divisions by forming parties in the church according to his own opinions; in order to maintain good order in the church, a factious, divisive person should be refused, rejected, after a first and second admonition—v. 10.\n以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\n1.\u3000Literally, the Greek words rendered &#34;faith&#34; mean &#34;the faith&#34;; this denotes the persistent faith for our persistent prayer, like that of the widow.\nI.\u3000The intrinsic significance of Ezra\&#39;s ministry is embodied in the words purification, education, and reconstitution; the intrinsic significance of Nehemiah\&#39;s leadership is embodied in the words separation, protection, and expression; we need to cooperate with the Lord in His heavenly ministry to build up the church as the house of God and the kingdom of God by living out and working out the New Jerusalem according to this intrinsic significance—1 Kings 8:48; Psa. 48:1-2; 1 Tim. 3:15; Eph. 2:21-22.\n”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。\nC.\u3000The law makes demands on man according to what God is; grace supplies man with what God is to meet what God demands; grace is God enjoyed by man—John 1:16-17; Gal. 6:18; 2 Cor. 13:14; 12:9; 1 Pet. 4:10; Eph. 3:2; 4:29; 6:24.\nb.\u3000If we see that the prayers of the greatest worth are prayers in ascension, then we can understand that prayer is a warfare, and we will utter prayers of warfare; such is the nature of the prayer spoken of in Ephesians 6:\n3.\u3000If a church goes astray or is misled, the apostles have the obligation and responsibility to deal with the situation according to God\&#39;s word, which has authority—vv. 26-27; 2 Cor. 10:6; 2 Tim. 1:13; 4:2.\nThe Intrinsic Significance of the Purification of the Returned Captives\n2.\u3000We all need to be helped through the Life-studies and the Recovery Version with the footnotes to see the intrinsic significance of the word of the Bible—Neh. 8:8, 13.\nB.\u3000They were unaware that the dispensation of law was altogether over, that the dispensation of grace should be fully honored, and that any disregard of the distinction between these two dispensations would be against God\&#39;s dispensational administration and would be a great damage to God\&#39;s economical plan for the building up of the church as the expression of Christ—John 1:16-17; Rev. 2:9.\nIII.\u3000In the Lord\&#39;s recovery we need Ezras, priestly teachers who contact God, who are saturated with God, who are one with God, who are mingled with God, who are filled with God, and who are skillful in the Word of God; this is the kind of person who is qualified to be a teacher in the recovery—Matt. 13:52; 2 Cor. 3:5-6; 1 Tim. 2:7; 2 Tim. 1:11:\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n实际上，这是指我们的心思、情感和意志，从神以外的各样事物中蒙拯救，而固定在神这唯一的对象和独一的目标上。\n因此，一个地方召会建立在其上的召会立场，必须是由“一”所构成，并在“一”里得维系；这一乃是由那灵执行，并由召会所在地保守的（李常受文集一九九三年第二册，九○至九一页）。\nI.\u3000The Lord\&#39;s recovery is unique, and it must be absolutely pure, single, and holy, without any mixture; thus, we need Ezras and Nehemiahs to carry out a purifying work; in all the steps of the Lord\&#39;s recovery, there is the need of purification:\n要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除了任何形式的狡猾雄心。\n……我们若不应用这原则，一切未受钉十字架察验的天然性能、才干和美德，在我们中间就会像“野兽”一样。\n我们必须非常纯净，使圣别的种类永远不会与任何外邦的事物混合（李常受文集一九六九年第二册，四九六至四九七页）。\nE.\u3000Nehemiah, as the governor, in the position of a king, was a man with a pure heart for the rebuilding of Jerusalem\&#39;s wall in carrying out God\&#39;s economy; he was a pattern of what a leader among God\&#39;s people should be—cf. 1 Tim. 3:2-7; 1 Pet. 5:1-3:\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n本篇信息的篇题是“洁净被掳归回之人的内在意义”。\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。\n2.\u3000The problem is that we have come back from Babylon to Jerusalem, yet at Jerusalem we may still keep many things for our own interests; we may not offer everything on the altar for God\&#39;s interests and for God\&#39;s satisfaction—Rom. 12:1:\n在主恢复之外的人无法理解我们中间到底是怎么运作的。\n对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。\n这里所说重新构成的需要，有如以色列人从埃及出来之时的需要；但从巴比伦归回的百姓因着和外邦人通婚而有了搀杂，使得情形更加艰难。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\na.\u3000The Lord\&#39;s recovery is the holy seed; we must be so pure that the holy seed will never be mingled with anything heathen.\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n《对同工长老们以及爱主寻求主者爱心的话》一书，第四章的题目就是“正确的跟随人”。\n”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。\n我们不该把启示录二十一、二十二章里“纯”、“明净”、“透明”这些辞视为理所当然，我们读的时候，需要对这些辞有更深入、更扩大的领会。\n本篇信息乃是要将这些辞一一应用于我们的经历。\n并且他这话不是凭空说的，也不是想像出来的；乃是他根据许多的事实，所产生出来的一个感觉。\n我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。\n因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。\n当我们借由这分职事的帮助来读主话的时候，就能看见主的话是何等美妙。\n到那时候你就晓得如何向别人陈明真理，不是仅仅激发或激动人，而是使人扎实，得着真理的构成（李常受文集一九八四年第二册，四○二至四○三页）。\n”经学家的功用需要配上祭司的功用；祭司的功用是借着我们在灵里与主联合，与主是一而享受主，但其中也需要话。\n可能你经历一段感情的结束，当时不明白为什么会发生这样的事，日后回想，才懂得感谢神。\n这里所列诗篇一百一十九篇的经节，给我们看见诗人不仅爱神、寻求神的说话，他也有祭司经学家的功用。\n我们都该盼望被人这样描述：这位弟兄对圣经爱不释手，并且他手中神的话就是他手中神的智慧。\n在篇题里我们看见有人的历史，然而在人的历史里有神的历史。\n有些人可能第一次听见这样的话，在此我们也只能讲到一些基本的内容。\n”（世界局势与神的行动，三七页）长老与同工都该是祭司教师，就是习练于圣经中的话语，并且善于教导。\n我和你们交通这事，是要让你们晓得我们的书撰写的方式。\n在《对同工长老们以及爱主寻求主者爱心的话》一书中，有对我们的警告：“你在跟随任何你所欣赏，并叫你受吸引之同工的事上，必须谨慎。\n这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。\n”我们各人都要在与主私下、亲密的交通中向主祷告，以回应本篇信息的话。\n\n\n问题：这篇文档是关于什么的？&#39;}]

ChatGPT: 请问这篇文章的主题是什么？

这篇文章的主题是基督徒的信仰生活以及如何正确地跟随上帝。它提到了如何在生活中以正确的动机行动，如何在困难时仍然赞美上帝，以及如何通过阅读圣经来更好地了解上帝的话语。此外，文章还提到了作为基督徒的责任和角色，包括成为教师和祭司。
Keyboard interruption in main thread... closing server.
Closing server running on port: 7860
=&gt; no.0  ::tools::test_demo  runtest  passed

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
<span class="n">HuggingFaceEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;GanymedeNil/text2vec-large-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 128, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 1024, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
), model_name=&#39;GanymedeNil/text2vec-large-chinese&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ChatGLM-6B"><a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">ChatGLM 6B</a><a class="anchor-link" href="#ChatGLM-6B">&#182;</a></h2><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/THUDM/chatglm-6b">Hugging Face - ChatGLM 6B</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ninehills/chatglm-openai-api">https://github.com/ninehills/chatglm-openai-api</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Chinese-LLaMA-and-Alpaca"><a target="_blank" rel="noopener" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca">Chinese LLaMA and Alpaca</a><a class="anchor-link" href="#Chinese-LLaMA-and-Alpaca">&#182;</a></h2><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/ziqingyang/chinese-alpaca-lora-7b">Hugging Face - Chinese Alpaca LoRA 7B</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/ziqingyang/chinese-alpaca-lora-13b">Hugging Face - Chinese Alpaca LoRA 13B</a></li>
</ul>

</div>
</div>
</div>
 




	</div>

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
    	<li class="prev"><a href="/2023/08/07/漂泊/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
  		

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2023/04/12/LangChain-Embeddings/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">Comments</h2>

  <script data-isso="https://jhub.dtype.info/isso/" src="https://jhub.dtype.info/isso/js/embed.min.js"></script>
  <section id="isso-thread"></section>
  
</section>


	
	</div> <!-- col-md-9/col-md-12 -->
	
	
		<div class="col-md-3"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2023-04-19 
	</div>
	

	<!-- categories -->
    

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/Metaverse/">Metaverse<span>12</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	

</div><!-- row -->

	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2024 Andrew
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>

</html>
