<!DOCTYPE HTML>
<html>

<head>

  <meta charset="utf-8">
  
  <title>Page 2 | Andrew&#39;s Blog</title>
  <meta name="author" content="Andrew">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Andrew&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/notebook.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/tabs.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  <script src="/js/tabs.js"></script>

  <!-- analytics -->
  



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration -->

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Andrew&#39;s Blog</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <div class="page-header">
  <h1>Andrew&#39;s Blog</h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">
      <i class="fa fa-heart"></i>
      PURSUE ULTIMATE FACTS
</div>    

		<div class="mypage">
		
		<!-- title and entry -->
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-08-07 </div>
			<div class="article-title"><a href="/2023/08/07/漢字文から音読み文に転換/" >漢字文から音読み文に転換</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Python-%E3%81%A7%E3%80%81%E6%BC%A2%E5%AD%97%E6%96%87%E3%81%8B%E3%82%89%E9%9F%B3%E8%AA%AD%E3%81%BF%E6%96%87%E3%81%AB%E8%BB%A2%E6%8F%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82">Python &#12391;&#12289;&#28450;&#23383;&#25991;&#12363;&#12425;&#38899;&#35501;&#12415;&#25991;&#12395;&#36578;&#25563;&#12375;&#12414;&#12377;&#12290;<a class="anchor-link" href="#Python-%E3%81%A7%E3%80%81%E6%BC%A2%E5%AD%97%E6%96%87%E3%81%8B%E3%82%89%E9%9F%B3%E8%AA%AD%E3%81%BF%E6%96%87%E3%81%AB%E8%BB%A2%E6%8F%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 漢字から音読みに変換する対応表</span>
<span class="n">kanji_to_onyomi</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;神&#39;</span><span class="p">:</span> <span class="s1">&#39;シン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;是&#39;</span><span class="p">:</span> <span class="s1">&#39;ゼ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;信&#39;</span><span class="p">:</span> <span class="s1">&#39;シン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;実&#39;</span><span class="p">:</span> <span class="s1">&#39;ジツ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;的&#39;</span><span class="p">:</span> <span class="s1">&#39;テキ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;你&#39;</span><span class="p">:</span> <span class="s1">&#39;ジ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;們&#39;</span><span class="p">:</span> <span class="s1">&#39;モン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;乃&#39;</span><span class="p">:</span> <span class="s1">&#39;ナイ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;是&#39;</span><span class="p">:</span> <span class="s1">&#39;ゼ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;爲&#39;</span><span class="p">:</span> <span class="s1">&#39;イ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;他&#39;</span><span class="p">:</span> <span class="s1">&#39;タ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;所&#39;</span><span class="p">:</span> <span class="s1">&#39;ショ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;召&#39;</span><span class="p">:</span> <span class="s1">&#39;ショウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;進&#39;</span><span class="p">:</span> <span class="s1">&#39;シン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;入&#39;</span><span class="p">:</span> <span class="s1">&#39;ニュウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;了&#39;</span><span class="p">:</span> <span class="s1">&#39;リョウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;儿&#39;</span><span class="p">:</span> <span class="s1">&#39;ジン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;子&#39;</span><span class="p">:</span> <span class="s1">&#39;ス&#39;</span><span class="p">,</span>
    <span class="s1">&#39;我&#39;</span><span class="p">:</span> <span class="s1">&#39;ガ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;主&#39;</span><span class="p">:</span> <span class="s1">&#39;シュ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;耶&#39;</span><span class="p">:</span> <span class="s1">&#39;ヤ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;穌&#39;</span><span class="p">:</span> <span class="s1">&#39;ソ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;基&#39;</span><span class="p">:</span> <span class="s1">&#39;キ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;督&#39;</span><span class="p">:</span> <span class="s1">&#39;トク&#39;</span><span class="p">,</span>
    <span class="s1">&#39;的&#39;</span><span class="p">:</span> <span class="s1">&#39;テキ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;交&#39;</span><span class="p">:</span> <span class="s1">&#39;コウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;通&#39;</span><span class="p">:</span> <span class="s1">&#39;ツウ&#39;</span><span class="p">,</span>
    <span class="c1"># 他の漢字と音読みの対応を追加</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">convert_to_onyomi_sentence</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">):</span>
    <span class="c1"># 入力された漢字文を音読み文に変換する関数</span>
    <span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">)</span>  <span class="c1"># 文を単語に分割</span>
    <span class="n">onyomi_sentence</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="n">onyomi</span> <span class="o">=</span> <span class="n">kanji_to_onyomi</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>  <span class="c1"># 辞書から音読みを取得、なければそのまま単語を使用</span>
        <span class="n">onyomi_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onyomi</span><span class="p">)</span>

    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">onyomi_sentence</span><span class="p">)</span>

<span class="c1"># 漢字文を入力</span>
<span class="n">input_sentence</span> <span class="o">=</span> <span class="s1">&#39;神是信実的，你們乃是爲他所召，進入了他儿子我們主耶穌基督的交通。&#39;</span>
<span class="c1"># 音読み文に変換</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">convert_to_onyomi_sentence</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  <span class="c1"># 出力: &quot;シンゼシンジツテキ，ジモンナイゼイタショショウ，シンニュウリョウタジンスガモンシュヤソキトクテキコウツウ。&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>シンゼシンジツテキ，ジモンナイゼイタショショウ，シンニュウリョウタジンスガモンシュヤソキトクテキコウツウ。
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Python-%E3%81%A7%E3%80%81Janome-%E3%81%A7%E3%80%81%E6%BC%A2%E5%AD%97%E6%96%87%E3%81%8B%E3%82%89%E9%9F%B3%E8%AA%AD%E3%81%BF%E6%96%87%E3%81%AB%E8%BB%A2%E6%8F%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82">Python &#12391;&#12289;Janome &#12391;&#12289;&#28450;&#23383;&#25991;&#12363;&#12425;&#38899;&#35501;&#12415;&#25991;&#12395;&#36578;&#25563;&#12375;&#12414;&#12377;&#12290;<a class="anchor-link" href="#Python-%E3%81%A7%E3%80%81Janome-%E3%81%A7%E3%80%81%E6%BC%A2%E5%AD%97%E6%96%87%E3%81%8B%E3%82%89%E9%9F%B3%E8%AA%AD%E3%81%BF%E6%96%87%E3%81%AB%E8%BB%A2%E6%8F%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Janome を使って漢字文から音読み文に変換するには、まず漢字を形態素に分割し、それぞれの形態素に対応する音読みを取得する必要があります。ただし、Janome 自体は音読みを直接提供する機能はありません。そのため、別途辞書や API などから音読みを取得する必要があります。</p>
<p>以下は、辞書を使用して漢字文から音読み文に変換するサンプルコードです。このコードでは、kanji_to_onyomi という辞書に漢字と対応する音読みを登録し、入力された漢字文を音読み文に変換します。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>janome
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: janome in /home/jupyter-saintway/.local/lib/python3.9/site-packages (0.5.0)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">janome.tokenizer</span> <span class="kn">import</span> <span class="n">Tokenizer</span>

<span class="c1"># 漢字から音読みに変換する対応表（例としていくつかの漢字と音読みを登録）</span>
<span class="n">kanji_to_onyomi</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;神&#39;</span><span class="p">:</span> <span class="s1">&#39;シン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;是&#39;</span><span class="p">:</span> <span class="s1">&#39;ゼ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;信&#39;</span><span class="p">:</span> <span class="s1">&#39;シン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;実&#39;</span><span class="p">:</span> <span class="s1">&#39;ジツ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;的&#39;</span><span class="p">:</span> <span class="s1">&#39;テキ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;你&#39;</span><span class="p">:</span> <span class="s1">&#39;ジ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;們&#39;</span><span class="p">:</span> <span class="s1">&#39;モン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;乃&#39;</span><span class="p">:</span> <span class="s1">&#39;ナイ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;是&#39;</span><span class="p">:</span> <span class="s1">&#39;ゼ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;爲&#39;</span><span class="p">:</span> <span class="s1">&#39;イ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;他&#39;</span><span class="p">:</span> <span class="s1">&#39;タ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;所&#39;</span><span class="p">:</span> <span class="s1">&#39;ショ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;召&#39;</span><span class="p">:</span> <span class="s1">&#39;ショウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;進&#39;</span><span class="p">:</span> <span class="s1">&#39;シン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;入&#39;</span><span class="p">:</span> <span class="s1">&#39;ニュウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;了&#39;</span><span class="p">:</span> <span class="s1">&#39;リョウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;儿&#39;</span><span class="p">:</span> <span class="s1">&#39;ジン&#39;</span><span class="p">,</span>
    <span class="s1">&#39;子&#39;</span><span class="p">:</span> <span class="s1">&#39;ス&#39;</span><span class="p">,</span>
    <span class="s1">&#39;我&#39;</span><span class="p">:</span> <span class="s1">&#39;ガ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;主&#39;</span><span class="p">:</span> <span class="s1">&#39;シュ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;耶&#39;</span><span class="p">:</span> <span class="s1">&#39;ヤ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;穌&#39;</span><span class="p">:</span> <span class="s1">&#39;ソ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;基&#39;</span><span class="p">:</span> <span class="s1">&#39;キ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;督&#39;</span><span class="p">:</span> <span class="s1">&#39;トク&#39;</span><span class="p">,</span>
    <span class="s1">&#39;的&#39;</span><span class="p">:</span> <span class="s1">&#39;テキ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;交&#39;</span><span class="p">:</span> <span class="s1">&#39;コウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;通&#39;</span><span class="p">:</span> <span class="s1">&#39;ツウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;信実&#39;</span><span class="p">:</span> <span class="s1">&#39;シンジツ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;進入&#39;</span><span class="p">:</span> <span class="s1">&#39;シンニュウ&#39;</span><span class="p">,</span>
    <span class="s1">&#39;交通&#39;</span><span class="p">:</span> <span class="s1">&#39;コウツウ&#39;</span><span class="p">,</span>
    <span class="c1"># 他の漢字と音読みの対応を追加</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">get_onyomi</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
    <span class="c1"># 漢字を対応表から検索し、音読みを取得する関数</span>
    <span class="k">return</span> <span class="n">kanji_to_onyomi</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">surface</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">surface</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">convert_to_onyomi_sentence</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">):</span>
    <span class="c1"># 入力された漢字文を音読み文に変換する関数</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">)</span>
    <span class="c1"># print([token.surface for token in tokens])</span>
    <span class="n">onyomi_sentence</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
        <span class="n">onyomi</span> <span class="o">=</span> <span class="n">get_onyomi</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="n">onyomi_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onyomi</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">onyomi_sentence</span><span class="p">)</span>

    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">onyomi_sentence</span><span class="p">)</span>

<span class="c1"># 漢字文を入力</span>
<span class="n">input_sentence</span> <span class="o">=</span> <span class="s1">&#39;神是信実的，你們乃是爲他所召，進入了他儿子我們主耶穌基督的交通。&#39;</span>
<span class="c1"># 音読み文に変換</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">convert_to_onyomi_sentence</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  <span class="c1"># 出力: &#39;シンゼシンジツテキ，ジモンナイゼイタショショウ，シンニュウリョウタジンスガモンシュヤソキトクテキコウツウ。&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;シン&#39;, &#39;ゼ&#39;, &#39;シンジツ&#39;, &#39;テキ&#39;, &#39;，&#39;, &#39;你們乃&#39;, &#39;ゼ&#39;, &#39;爲他所&#39;, &#39;ショウ&#39;, &#39;，&#39;, &#39;シンニュウ&#39;, &#39;リョウ&#39;, &#39;タ&#39;, &#39;儿子我&#39;, &#39;們主耶&#39;, &#39;穌基督&#39;, &#39;テキ&#39;, &#39;コウツウ&#39;, &#39;。&#39;]
シンゼシンジツテキ，你們乃ゼ爲他所ショウ，シンニュウリョウタ儿子我們主耶穌基督テキコウツウ。
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>このコードでは、Janome の Tokenizer を使って日本語の形態素解析を行い、文を形態素に分割しています。それぞれの形態素には、表層形（原形）と品詞などの情報が含まれています。</p>
<p>上記のコードを実行すると、入力した日本語の文が形態素に分割されて、表層形と品詞の情報が表示されるでしょう。Janome はシンプルで使いやすいライブラリなので、日本語の形態素解析に便利です。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Python-%E3%81%A7%E3%80%81MeCab-%E3%81%A7%E3%80%81UniDic-%E3%81%A7%E3%80%81%E6%BC%A2%E5%AD%97%E6%96%87%E3%81%8B%E3%82%89%E9%9F%B3%E8%AA%AD%E3%81%BF%E6%96%87%E3%81%AB%E8%BB%A2%E6%8F%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82">Python &#12391;&#12289;<a target="_blank" rel="noopener" href="https://taku910.github.io/mecab/">MeCab</a> &#12391;&#12289;UniDic &#12391;&#12289;&#28450;&#23383;&#25991;&#12363;&#12425;&#38899;&#35501;&#12415;&#25991;&#12395;&#36578;&#25563;&#12375;&#12414;&#12377;&#12290;<a class="anchor-link" href="#Python-%E3%81%A7%E3%80%81MeCab-%E3%81%A7%E3%80%81UniDic-%E3%81%A7%E3%80%81%E6%BC%A2%E5%AD%97%E6%96%87%E3%81%8B%E3%82%89%E9%9F%B3%E8%AA%AD%E3%81%BF%E6%96%87%E3%81%AB%E8%BB%A2%E6%8F%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>MeCab を使用して UniDic 辞書を利用し、漢字文から音読み文に変換するためには、以下の手順に従ってください。まず、Python で MeCab を使えるようにしてから、サンプルコードを提供します。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>MeCab と UniDic のインストール：</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>unidic-lite
pip<span class="w"> </span>install<span class="w"> </span>mecab-python3
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Defaulting to user installation because normal site-packages is not writeable
Collecting unidic-lite
  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status &#39;done&#39;
Building wheels for collected packages: unidic-lite
  Building wheel for unidic-lite (setup.py): started
  Building wheel for unidic-lite (setup.py): finished with status &#39;done&#39;
  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658836 sha256=d354e3491cb194fab1fab224d3595dfa0419a6d75edec0bdd76fad8f60ec4d3a
  Stored in directory: /home/jupyter-saintway/.cache/pip/wheels/56/9c/4f/2c115e896b4b6c584039ca19de3581d333856782ef108cdc5c
Successfully built unidic-lite
Installing collected packages: unidic-lite
Successfully installed unidic-lite-1.0.8
Defaulting to user installation because normal site-packages is not writeable
Collecting mecab-python3
  Downloading mecab_python3-1.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)
Installing collected packages: mecab-python3
Successfully installed mecab-python3-1.0.6
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>このコードでは、MeCab の Tagger に UniDic のパスを指定して、日本語の形態素解析を行い、漢字文を音読み文に変換しています。漢字の音読みは UniDic の「名詞固有名詞」のフィーチャー情報の7番目に格納されているため、それを取得しています。</p>
<p>注意：/path/to/unidic の部分は、UniDic 辞書の実際のインストールパスに置き換えてください。</p>
<p>また、UniDic に登録されていない単語や未知の単語に対しては、'*'として示されることがあります。その場合は元の漢字をそのまま使用します。さらに、Juman++ などの他の形態素解析エンジンや辞書を利用することも検討してください。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">MeCab</span>

<span class="c1"># MeCab + UniDicを使って漢字文から音読みを取得する関数</span>
<span class="k">def</span> <span class="nf">get_onyomi</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">mecab</span> <span class="o">=</span> <span class="n">MeCab</span><span class="o">.</span><span class="n">Tagger</span><span class="p">(</span><span class="s1">&#39;-d /path/to/unidic&#39;</span><span class="p">)</span>  <span class="c1"># UniDicのパスを指定してください</span>
        <span class="n">node</span> <span class="o">=</span> <span class="n">mecab</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">onyomi_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        
        <span class="k">while</span> <span class="n">node</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">7</span> <span class="ow">and</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;名詞&#39;</span> <span class="ow">and</span> <span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;固有名詞&#39;</span><span class="p">:</span>
                <span class="n">onyomi_text</span> <span class="o">+=</span> <span class="n">features</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span> <span class="k">if</span> <span class="n">features</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;*&#39;</span> <span class="k">else</span> <span class="n">node</span><span class="o">.</span><span class="n">surface</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">onyomi_text</span> <span class="o">+=</span> <span class="n">node</span><span class="o">.</span><span class="n">surface</span>

            <span class="n">node</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">next</span>

        <span class="k">return</span> <span class="n">onyomi_text</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;エラー:&#39;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># 漢字文を入力</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="s1">&#39;漢字文を入力してください。&#39;</span>
<span class="c1"># 音読みに変換</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">get_onyomi</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  <span class="c1"># 出力例: &#39;漢字文をニュウリョクシテクダサイ。&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p><a target="_blank" rel="noopener" href="https://github.com/ku-nlp/jumanpp">Juman++</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">cmake</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">protobuf</span><span class="o">-</span><span class="n">compiler</span> <span class="n">libprotobuf</span><span class="o">-</span><span class="n">dev</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ku-nlp/jumanpp.git<span class="w"> </span>~/jumanpp
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
mkdir<span class="w"> </span>-p<span class="w"> </span>~/jumanpp/build
<span class="nb">cd</span><span class="w"> </span>~/jumanpp/build
cmake<span class="w"> </span>~/jumanpp<span class="w"> </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Release
<span class="nb">cd</span><span class="w"> </span>~/jumanpp
sudo<span class="w"> </span>make<span class="w"> </span>install
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p><a target="_blank" rel="noopener" href="https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc4/jumanpp-2.0.0-rc4.tar.xz">https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc4/jumanpp-2.0.0-rc4.tar.xz</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p><a target="_blank" rel="noopener" href="https://lotus.kuee.kyoto-u.ac.jp/nl-resource/jumanpp/jumanpp-1.02.tar.xz">https://lotus.kuee.kyoto-u.ac.jp/nl-resource/jumanpp/jumanpp-1.02.tar.xz</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
<span class="nb">cd</span><span class="w"> </span>~<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>wget<span class="w"> </span>https://lotus.kuee.kyoto-u.ac.jp/nl-resource/jumanpp/jumanpp-1.02.tar.xz
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
<span class="nb">cd</span><span class="w"> </span>~<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>tar<span class="w"> </span>xJvf<span class="w"> </span>~/jumanpp-1.02.tar.xz
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
sudo<span class="w"> </span>apt<span class="w"> </span>update
sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>libboost-all-dev
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
<span class="nb">cd</span><span class="w"> </span>~/jumanpp-1.02
./configure
make
sudo<span class="w"> </span>make<span class="w"> </span>install
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>pyknp
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pyknp in /home/jupyter-saintway/.local/lib/python3.9/site-packages (0.6.1)
Requirement already satisfied: six in /home/jupyter-saintway/.local/lib/python3.9/site-packages (from pyknp) (1.16.0)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pyknp</span> <span class="kn">import</span> <span class="n">Juman</span>
<span class="n">juman</span> <span class="o">=</span> <span class="n">Juman</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">halfwidth_to_fullwidth</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="n">code</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">code</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s1">&#39;　&#39;</span>
        <span class="k">elif</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;!&#39;</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">code</span> <span class="o">&lt;=</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;~&#39;</span><span class="p">):</span>
            <span class="c1"># Convert ASCII characters in the range 0x0021 to 0x007E</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="nb">chr</span><span class="p">(</span><span class="n">code</span> <span class="o">+</span> <span class="mh">0xFEE0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">char</span>
    <span class="k">return</span> <span class="n">result</span>

<span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">halfwidth_to_fullwidth</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">line</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="k">yield</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="k">continue</span>
        <span class="n">mrphs</span> <span class="o">=</span> <span class="n">juman</span><span class="o">.</span><span class="n">analysis</span><span class="p">(</span><span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">mrph_list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">mrph</span> <span class="ow">in</span> <span class="n">mrphs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mrph</span><span class="o">.</span><span class="n">midasi</span> <span class="o">==</span> <span class="n">mrph</span><span class="o">.</span><span class="n">yomi</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">mrph</span><span class="o">.</span><span class="n">midasi</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="s1">&#39;　</span><span class="si">{}</span><span class="s1">［</span><span class="si">{}</span><span class="s1">］&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">mrph</span><span class="o">.</span><span class="n">midasi</span><span class="p">,</span>
                    <span class="n">mrph</span><span class="o">.</span><span class="n">yomi</span>
                <span class="p">)</span>
        <span class="k">yield</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>

<span class="k">def</span> <span class="nf">render_to_latex</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">halfwidth_to_fullwidth</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">line</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="k">yield</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="k">continue</span>
        <span class="n">mrphs</span> <span class="o">=</span> <span class="n">juman</span><span class="o">.</span><span class="n">analysis</span><span class="p">(</span><span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">mrph_list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">mrph</span> <span class="ow">in</span> <span class="n">mrphs</span><span class="p">:</span>
            <span class="k">yield</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">frac</span><span class="se">{{</span><span class="si">{</span><span class="n">mrph</span><span class="o">.</span><span class="n">yomi</span><span class="si">}</span><span class="se">}}{{</span><span class="si">{</span><span class="n">mrph</span><span class="o">.</span><span class="n">midasi</span><span class="si">}</span><span class="se">}}</span><span class="s1">&#39;</span>
        <span class="k">yield</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Math</span>
<span class="n">line</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">render_to_latex</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">朝の養い</span>

<span class="s1">啓21:3　……見よ、神の幕屋が人と共にある．神は彼らと共に幕屋を張り……</span>
<span class="s1">22　わたしはその中に宮を見なかった．主なる神、全能者と小羊が、その宮だからである。</span>

<span class="s1">　わたしは七十年以上を費やして聖書を学びましたが、ごく最近になって、聖書が実はただ一つの事、すなわち宇宙的な合併を明らかにしていることを見ました。目的を持つ神にはエコノミーがあり、彼は彼のエコノミーの中で、宇宙的な合併を持つことを意図されます。</span>
<span class="s1">　わたしたちは、新エルサレムが神のエコノミーの目標であることを見てきましたが、新エルサレムが一つの合併であることを見ませんでした。啓示録第21章2節で使徒ヨハネは、「わたしはまた聖なる都、新エルサレム……を見た」と言い、次の節では「神の幕屋」としての新エルサレムについて語っています。神の幕屋として、新エルサレムは神の住まいであり、……［また］宇宙的な合併です。（リー全集、1994年―1997年、第5巻（下）、「御父により神聖な栄光をもってキリストの栄光が現されたことの結果」、第4編）</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">word</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">:</span>
        <span class="n">display</span><span class="p">(</span><span class="n">Math</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>
        <span class="n">line</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">line</span> <span class="o">+=</span> <span class="n">word</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle $
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle \frac{あさ}{朝}\frac{の}{の}\frac{やしない}{養い}$
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle $
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle \frac{ひらく}{啓}\frac{２１}{２１}\frac{：}{：}\frac{３}{３}\frac{　}{　}\frac{……}{……}\frac{みよ}{見よ}\frac{、}{、}\frac{かみ}{神}\frac{の}{の}\frac{まくや}{幕屋}\frac{が}{が}\frac{じん}{人}\frac{と}{と}\frac{ともに}{共に}\frac{ある}{ある}\frac{．}{．}\frac{かみ}{神}\frac{は}{は}\frac{かれ}{彼}\frac{ら}{ら}\frac{と}{と}\frac{ともに}{共に}\frac{まくや}{幕屋}\frac{を}{を}\frac{はり}{張り}\frac{……}{……}$
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle \frac{２２}{２２}\frac{　}{　}\frac{わたし}{わたし}\frac{は}{は}\frac{その}{その}\frac{なか}{中}\frac{に}{に}\frac{みや}{宮}\frac{を}{を}\frac{み}{見}\frac{なかった}{なかった}\frac{．}{．}\frac{おもなる}{主なる}\frac{かみ}{神}\frac{、}{、}\frac{ぜん}{全}\frac{のう}{能}\frac{しゃ}{者}\frac{と}{と}\frac{しょう}{小}\frac{ひつじ}{羊}\frac{が}{が}\frac{、}{、}\frac{その}{その}\frac{みや}{宮}\frac{だ}{だ}\frac{から}{から}\frac{である}{である}\frac{。}{。}$
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle $
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle \frac{わたし}{わたし}\frac{は}{は}\frac{七十}{七十}\frac{ねん}{年}\frac{いじょう}{以上}\frac{を}{を}\frac{ついやして}{費やして}\frac{せいしょ}{聖書}\frac{を}{を}\frac{まなび}{学び}\frac{ました}{ました}\frac{が}{が}\frac{、}{、}\frac{ごく}{ごく}\frac{さいきん}{最近}\frac{に}{に}\frac{なって}{なって}\frac{、}{、}\frac{せいしょ}{聖書}\frac{が}{が}\frac{じつは}{実は}\frac{ただ}{ただ}\frac{一}{一}\frac{つ}{つ}\frac{の}{の}\frac{じ}{事}\frac{、}{、}\frac{すなわち}{すなわち}\frac{うちゅう}{宇宙}\frac{てきな}{的な}\frac{がっぺい}{合併}\frac{を}{を}\frac{あきらかに}{明らかに}\frac{して}{して}\frac{いる}{いる}\frac{こと}{こと}\frac{を}{を}\frac{み}{見}\frac{ました}{ました}\frac{。}{。}\frac{もくてき}{目的}\frac{を}{を}\frac{もつ}{持つ}\frac{かみ}{神}\frac{に}{に}\frac{は}{は}\frac{エコノミー}{エコノミー}\frac{が}{が}\frac{あり}{あり}\frac{、}{、}\frac{かれ}{彼}\frac{は}{は}\frac{かれ}{彼}\frac{の}{の}\frac{エコノミー}{エコノミー}\frac{の}{の}\frac{なか}{中}\frac{で}{で}\frac{、}{、}\frac{うちゅう}{宇宙}\frac{てきな}{的な}\frac{がっぺい}{合併}\frac{を}{を}\frac{もつ}{持つ}\frac{こと}{こと}\frac{を}{を}\frac{いと}{意図}\frac{さ}{さ}\frac{れ}{れ}\frac{ます}{ます}\frac{。}{。}$
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle \frac{わたし}{わたし}\frac{たち}{たち}\frac{は}{は}\frac{、}{、}\frac{しん}{新}\frac{えるされむ}{エルサレム}\frac{が}{が}\frac{かみ}{神}\frac{の}{の}\frac{エコノミー}{エコノミー}\frac{の}{の}\frac{もくひょう}{目標}\frac{である}{である}\frac{こと}{こと}\frac{を}{を}\frac{みて}{見て}\frac{き}{き}\frac{ました}{ました}\frac{が}{が}\frac{、}{、}\frac{しん}{新}\frac{えるされむ}{エルサレム}\frac{が}{が}\frac{一}{一}\frac{つ}{つ}\frac{の}{の}\frac{がっぺい}{合併}\frac{である}{である}\frac{こと}{こと}\frac{を}{を}\frac{み}{見}\frac{ませ}{ませ}\frac{ん}{ん}\frac{でした}{でした}\frac{。}{。}\frac{けいじ}{啓示}\frac{ろく}{録}\frac{だい}{第}\frac{２１}{２１}\frac{しょう}{章}\frac{２}{２}\frac{せつ}{節}\frac{で}{で}\frac{しと}{使徒}\frac{ヨハネ}{ヨハネ}\frac{は}{は}\frac{、}{、}\frac{「}{「}\frac{わたし}{わたし}\frac{は}{は}\frac{また}{また}\frac{せいなる}{聖なる}\frac{と}{都}\frac{、}{、}\frac{しん}{新}\frac{えるされむ}{エルサレム}\frac{……}{……}\frac{を}{を}\frac{みた}{見た}\frac{」}{」}\frac{と}{と}\frac{いい}{言い}\frac{、}{、}\frac{つぎの}{次の}\frac{せつ}{節}\frac{で}{で}\frac{は}{は}\frac{「}{「}\frac{かみ}{神}\frac{の}{の}\frac{まくや}{幕屋}\frac{」}{」}\frac{と}{と}\frac{して}{して}\frac{の}{の}\frac{しん}{新}\frac{えるされむ}{エルサレム}\frac{に}{に}\frac{ついて}{ついて}\frac{かたって}{語って}\frac{い}{い}\frac{ます}{ます}\frac{。}{。}\frac{かみ}{神}\frac{の}{の}\frac{まくや}{幕屋}\frac{と}{と}\frac{して}{して}\frac{、}{、}\frac{しん}{新}\frac{えるされむ}{エルサレム}\frac{は}{は}\frac{かみ}{神}\frac{の}{の}\frac{すまい}{住まい}\frac{であり}{であり}\frac{、}{、}\frac{……}{……}\frac{［}{［}\frac{また}{また}\frac{］}{］}\frac{うちゅう}{宇宙}\frac{てきな}{的な}\frac{がっぺい}{合併}\frac{です}{です}\frac{。}{。}\frac{（}{（}\frac{りー}{リー}\frac{ぜんしゅう}{全集}\frac{、}{、}\frac{１９９４}{１９９４}\frac{ねん}{年}\frac{―}{―}\frac{１９９７}{１９９７}\frac{ねん}{年}\frac{、}{、}\frac{だい}{第}\frac{５}{５}\frac{かん}{巻}\frac{（}{（}\frac{した}{下}\frac{）}{）}\frac{、}{、}\frac{「}{「}\frac{ご}{御}\frac{ちち}{父}\frac{に}{に}\frac{より}{より}\frac{しんせいな}{神聖な}\frac{えいこう}{栄光}\frac{を}{を}\frac{もって}{もって}\frac{キリスト}{キリスト}\frac{の}{の}\frac{えいこう}{栄光}\frac{が}{が}\frac{あらわさ}{現さ}\frac{れた}{れた}\frac{こと}{こと}\frac{の}{の}\frac{けっか}{結果}\frac{」}{」}\frac{、}{、}\frac{だい}{第}\frac{４}{４}\frac{へん}{編}\frac{）}{）}$
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_latex output_subarea ">
$\displaystyle $
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">render</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">朝の養い</span>

<span class="s2">啓21:9-11　……「ここに来なさい．あなたに小羊の妻である花嫁を見せよう」。そして彼はわたしを霊の中で、大きな高い山へ連れて行き、聖なる都エルサレムが、天から出て神から下って来るのをわたしに見せたが、それは神の栄光を持っていた。その光は最も尊い宝石のようであり、水晶のように透明な碧玉のようであった。</span>

<span class="s2">　新約の主要な内容とは、三一の神がご自身の大いなる喜びにしたがって永遠のエコノミーを持っておられ、それは彼の命と性質の中でご自身を彼の選ばれ、贖われた民の中へと分与し、それによって彼らをご自身の複製とし、彼らが彼を表現するためであるということです。この団体の表現は新エルサレムにおいて究極的に完成します（エペソ3:9．1:9-23）。聖書の究極的な完成である新エルサレムは、神が人と成ることと、人が神格においてではなく、命と性質において神となることと関係があります（啓21:2．3:12）。キリストの中で、神は人と成り、人を彼の命と性質において神とします。それによって贖う神と贖われた人は、共にミングリングされ、構成されて、一つの実体、すなわち新エルサレムとなることができます（21:3、22）。最終的に、三一の、永遠の神は新エルサレムとなってわたしたちすべてと合併し、わたしたちもまた神の有機的な救いの過程を通して（ローマ5:10）、新エルサレムとなります。（「新約の結論（25）」、メッセージ428）</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
　朝［あさ］の　養い［やしない］

　啓［ひらく］２１：９－１１　……「ここに来なさい．あなたに　小［しょう］　羊［ひつじ］の　妻［つま］である　花嫁［はなよめ］を　見せよう［みせよう］」。そして　彼［かれ］はわたしを　霊［れい］の　中［なか］で、　大きな［おおきな］　高い［たかい］　山［やま］へ　連れて［つれて］　行き［いき］、　聖なる［せいなる］　都［みやこ］　エルサレム［えるされむ］が、　天から［てんから］　出て［でて］　神［かみ］から　下って［くだって］　来る［くる］のをわたしに　見せた［みせた］が、それは　神［かみ］の　栄光［えいこう］を　持って［もって］いた。その　光［ひかり］は　最も［もっとも］　尊い［とうとい］　宝石［ほうせき］のようであり、　水晶［すいしょう］のように　透明な［とうめいな］　碧玉［へきぎょく］のようであった。

　新約［しんやく］の　主要な［しゅような］　内容［ないよう］とは、三一の　神［かみ］がご　自身［じしん］の　大いなる［おおいなる］　喜び［よろこび］にしたがって　永遠の［えいえんの］エコノミーを　持って［もって］おられ、それは　彼［かれ］の　命［いのち］と　性質［せいしつ］の　中［なか］でご　自身［じしん］を　彼［かれ］の　選ば［えらば］れ、贖われた　民［みん］の　中［なか］へと　分与［ぶんよ］し、それによって　彼［かれ］らをご　自身［じしん］の　複製［ふくせい］とし、　彼［かれ］らが　彼［かれ］を　表現［ひょうげん］するためであるということです。この　団体［だんたい］の　表現［ひょうげん］は　新［しん］　エルサレム［えるされむ］において　究極［きゅうきょく］　的に［てきに］　完成［かんせい］します（エペソ３：９．１：９－２３）。　聖書［せいしょ］の　究極［きゅうきょく］　的な［てきな］　完成［かんせい］である　新［しん］　エルサレム［えるされむ］は、　神［かみ］が　人［じん］と　成る［なる］ことと、　人［じん］が　神格［しんかく］においてではなく、　命［いのち］と　性質［せいしつ］において　神［かみ］となることと　関係［かんけい］があります（　啓［ひらく］２１：２．３：１２）。キリストの　中［なか］で、　神［かみ］は　人［じん］と　成り［なり］、　人［じん］を　彼［かれ］の　命［いのち］と　性質［せいしつ］において　神［かみ］とします。それによって贖う　神［かみ］と贖われた　人［じん］は、　共に［ともに］ミングリングされ、　構成［こうせい］されて、一つの　実体［じったい］、すなわち　新［しん］　エルサレム［えるされむ］となることができます（２１：３、２２）。　最終［さいしゅう］　的に［てきに］、三一の、　永遠の［えいえんの］　神［かみ］は　新［しん］　エルサレム［えるされむ］となってわたしたちすべてと　合併［がっぺい］し、わたしたちもまた　神［かみ］の　有機［ゆうき］　的な［てきな］　救い［すくい］の　過程［かてい］を　通して［とおして］（　ローマ［ろーま］５：１０）、　新［しん］　エルサレム［えるされむ］となります。（「　新約［しんやく］の　結論［けつろん］（２５）」、　メッセージ［めっせーじ］４２８）

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">render</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">神是信実的，你們乃是爲他所召，進入了他儿子我們主耶穌基督的交通。</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
　神［かみ］是信　実［み］　的［てき］，你們　乃［だい］　是［ぜ］爲他　所［しょ］　召［めし］，　進入［しんにゅう］　了［りょう］　他［た］儿子我們　主［しゅ］耶穌基督　的［てき］　交通［こうつう］。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">render</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">神、是、信、実、的，你、們、乃、是、爲、他、所、召，進、入、了、他、儿、子、我、們、主、耶、穌、基、督、的、交、通。</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
　神［かみ］、　是［ぜ］、　信［しん］、　実［み］、　的［てき］，你、們、　乃［だい］、　是［ぜ］、爲、　他［ほか］、　所［しょ］、　召［めし］，　進［しん］、　入［はいり］、　了［りょう］、　他［ほか］、儿、　子［し］、　我［われ］、們、　主［おも］、耶、穌、　基［もと］、督、　的［てき］、交、　通［つう］。

</pre>
</div>
</div>

</div>
</div>

</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/08/07/漢字文から音読み文に転換/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-08-07 </div>
			<div class="article-title"><a href="/2023/08/07/漂泊/" >漂泊</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <iframe style="width: 90%; aspect-ratio: 16/9;" src="https://www.youtube.com/embed/jECkG1qKIE8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<hr>
<div class="tabs" id="wandering"><ul class="nav-tabs"><li class="tab active"><a href="#wandering-1">Wandering</a></li><li class="tab"><a href="#wandering-2">漂泊</a></li></ul><div class="tab-content"><div class="tab-pane active" id="wandering-1"><blockquote>
<p>Life Hymn 570 - Wandering (<a target="_blank" rel="noopener" href="https://www.hymnal.net/en/hymn/ns/26">O the joy of having nothing</a>)<br>by Brother Darby, Zheng &amp; Andrew</p>
<p>Original Lyrics: Brother Darby<br>Lyrics Adaptation: Brother Zhicheng<br>Melody Adaptation: Sister Yuting<br>Sung by: Young Sisters of the Cleveland Church<br>Lyrics Readaptation: Brother Andrew</p>
<hr>
<p>[V1]<br>The glorious God revealed, drawing me forward;<br>All earthly things are no longer closely connected to me.<br>The glorious God revealed, with a face as solid as a rock;<br>In wandering, there is hope, walking step by step in the heavenly realm.</p>
<hr>
<p>[C]<br>Oh, what joy, oh, what joy,<br>that we can have nothing,<br>see nothing, manifest nothing,<br>but a living Christ in glory;<br>Oh, what joy, oh, what joy,<br>that we can have nothing,<br>see nothing, worry about nothing,<br>but regard His interests here on the earth.</p>
</blockquote></div><div class="tab-pane" id="wandering-2"><blockquote>
<p>生命诗歌 570 - 漂泊 (<a target="_blank" rel="noopener" href="https://www.hymnal.net/en/hymn/ns/26">O the joy of having nothing</a>)</p>
<p>词原作：达秘弟兄<br>词改编：郑志成弟兄<br>曲改编：郑范郁婷姊妹<br>唱：克里夫兰教会青年姊妹<br>词再改编：盛伟弟兄</p>
<hr>
<p>[V1]<br>荣耀之神显现，吸引我向前；<br>地上一切事物，不再紧相联。<br>荣耀之神显现，面如石坚；<br>漂泊中有盼望，步步行走属天。</p>
<hr>
<p>[C]<br>哦！何等喜乐，何等喜乐，<br>我们能够一无所有，<br>一无所见，一无所显，<br>惟显荣耀的基督；<br>何等喜乐，何等喜乐，<br>我们能够一无所有，<br>一无所见，一无所顾，<br>惟顾祂在地这里的权益。</p>
</blockquote></div></div></div>

	
	</div>
	
  
</div>
	<a type="button" href="/2023/08/07/漂泊/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-19 </div>
			<div class="article-title"><a href="/2023/04/19/Text2Vec/" >Text2Vec</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Text2Vec"><a target="_blank" rel="noopener" href="https://github.com/shibing624/text2vec">Text2Vec</a><a class="anchor-link" href="#Text2Vec">&#182;</a></h2><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers">Sentence Transformer</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/shibing624/text2vec-base-chinese">CoSENT hfl/chinese-macbert-base</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/GanymedeNil/text2vec-large-chinese">CoSENT hfl/chinese-lert-large</a><ul>
<li>GanymedeNil/text2vec-large-chinese</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>all-mpnet-base-v2</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;sentence-transformers/all-mpnet-base-v2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 384, &#39;do_lower_case&#39;: False}) with Transformer model: MPNetModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 768, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
  (2): Normalize()
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
total 857056
drwxr-xr-x  16 saintway  staff   512B Apr 12 14:31 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   5 saintway  staff   160B Apr 19 17:23 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 12 14:28 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 12 14:28 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff    10K Apr 12 14:28 README.md
-rw-r--r--   1 saintway  staff   571B Apr 12 14:28 config.json
-rw-r--r--   1 saintway  staff   116B Apr 12 14:28 config_sentence_transformers.json
-rw-r--r--   1 saintway  staff    38K Apr 12 14:28 data_config.json
-rw-r--r--   1 saintway  staff   349B Apr 12 14:31 modules.json
-rw-r--r--   1 saintway  staff   418M Apr 12 14:31 pytorch_model.bin
-rw-r--r--   1 saintway  staff    53B Apr 12 14:31 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   239B Apr 12 14:31 special_tokens_map.json
-rw-r--r--   1 saintway  staff   455K Apr 12 14:31 tokenizer.json
-rw-r--r--   1 saintway  staff   363B Apr 12 14:31 tokenizer_config.json
-rw-r--r--   1 saintway  staff    13K Apr 12 14:31 train_script.py
-rw-r--r--   1 saintway  staff   226K Apr 12 14:31 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
cat<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/modules.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[
  {
    &#34;idx&#34;: 0,
    &#34;name&#34;: &#34;0&#34;,
    &#34;path&#34;: &#34;&#34;,
    &#34;type&#34;: &#34;sentence_transformers.models.Transformer&#34;
  },
  {
    &#34;idx&#34;: 1,
    &#34;name&#34;: &#34;1&#34;,
    &#34;path&#34;: &#34;1_Pooling&#34;,
    &#34;type&#34;: &#34;sentence_transformers.models.Pooling&#34;
  },
  {
    &#34;idx&#34;: 2,
    &#34;name&#34;: &#34;2&#34;,
    &#34;path&#34;: &#34;2_Normalize&#34;,
    &#34;type&#34;: &#34;sentence_transformers.models.Normalize&#34;
  }
]</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
cat<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/sentence_bert_config.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{
  &#34;max_seq_length&#34;: 384,
  &#34;do_lower_case&#34;: false
}</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
cat<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/1_Pooling/config.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{
  &#34;word_embedding_dimension&#34;: 768,
  &#34;pooling_mode_cls_token&#34;: false,
  &#34;pooling_mode_mean_tokens&#34;: true,
  &#34;pooling_mode_max_tokens&#34;: false,
  &#34;pooling_mode_mean_sqrt_len_tokens&#34;: false
}</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/data_config.json
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> 40K	/Users/saintway/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2/data_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>all-MiniLM-L6-v2</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 256, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 384, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
  (2): Normalize()
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
total 210456
drwxr-xr-x  16 saintway  staff   512B Apr 19 17:38 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   6 saintway  staff   192B Apr 19 17:38 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 19 17:37 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 19 17:38 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff    10K Apr 19 17:38 README.md
-rw-r--r--   1 saintway  staff   612B Apr 19 17:38 config.json
-rw-r--r--   1 saintway  staff   116B Apr 19 17:38 config_sentence_transformers.json
-rw-r--r--   1 saintway  staff    38K Apr 19 17:38 data_config.json
-rw-r--r--   1 saintway  staff   349B Apr 19 17:38 modules.json
-rw-r--r--   1 saintway  staff    87M Apr 19 17:38 pytorch_model.bin
-rw-r--r--   1 saintway  staff    53B Apr 19 17:38 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   112B Apr 19 17:38 special_tokens_map.json
-rw-r--r--   1 saintway  staff   455K Apr 19 17:38 tokenizer.json
-rw-r--r--   1 saintway  staff   350B Apr 19 17:38 tokenizer_config.json
-rw-r--r--   1 saintway  staff    13K Apr 19 17:38 train_script.py
-rw-r--r--   1 saintway  staff   226K Apr 19 17:38 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>CoSENT hfl/chinese-macbert-base</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Full Model Architecture:</p>
<pre><code>CoSENT(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_mean_tokens': True})
)
</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;shibing624/text2vec-base-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 128, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 768, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/modules.json
<span class="p">[</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Transformer&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;1_Pooling&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Pooling&quot;</span>
  <span class="p">}</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Overwriting /Users/saintway/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/modules.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/sentence_bert_config.json
<span class="p">{</span>
  <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
  <span class="s2">&quot;do_lower_case&quot;</span><span class="p">:</span> <span class="n">false</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /Users/saintway/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/sentence_bert_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
mkdir<span class="w"> </span>-p<span class="w"> </span>~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/1_Pooling
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/1_Pooling/config.json
<span class="p">{</span>
  <span class="s2">&quot;word_embedding_dimension&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>
  <span class="s2">&quot;pooling_mode_mean_tokens&quot;</span><span class="p">:</span> <span class="n">true</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /Users/saintway/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese/1_Pooling/config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/shibing624_text2vec-base-chinese
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 831776
drwxr-xr-x  13 saintway  staff   416B Apr 19 19:22 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   7 saintway  staff   224B Apr 19 17:43 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 19 17:42 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 19 19:22 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff   4.0K Apr 19 17:43 README.md
-rw-r--r--   1 saintway  staff   856B Apr 19 17:43 config.json
-rw-r--r--   1 saintway  staff   546B Apr 19 17:43 logs.txt
-rw-r--r--   1 saintway  staff   230B Apr 19 19:17 modules.json
-rw-r--r--   1 saintway  staff   390M Apr 19 17:43 pytorch_model.bin
-rw-r--r--   1 saintway  staff    54B Apr 19 19:11 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   112B Apr 19 17:43 special_tokens_map.json
-rw-r--r--   1 saintway  staff   319B Apr 19 17:43 tokenizer_config.json
-rw-r--r--   1 saintway  staff   107K Apr 19 17:43 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>CoSENT hfl/chinese-lert-large</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;GanymedeNil/text2vec-large-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 128, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 1024, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/modules.json
<span class="p">[</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Transformer&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;1_Pooling&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers.models.Pooling&quot;</span>
  <span class="p">}</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /home/jupyter-saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/modules.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/sentence_bert_config.json
<span class="p">{</span>
  <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
  <span class="s2">&quot;do_lower_case&quot;</span><span class="p">:</span> <span class="n">false</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /home/jupyter-saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/sentence_bert_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
mkdir<span class="w"> </span>-p<span class="w"> </span>~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/1_Pooling
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> ~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/1_Pooling/config.json
<span class="p">{</span>
  <span class="s2">&quot;word_embedding_dimension&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
  <span class="s2">&quot;pooling_mode_mean_tokens&quot;</span><span class="p">:</span> <span class="n">true</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing /home/jupyter-saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese/1_Pooling/config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 2569336
drwxr-xr-x  14 saintway  staff   448B Apr 19 19:28 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   7 saintway  staff   224B Apr 19 17:43 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.4K Apr 19 17:16 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 19 19:28 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff   317B Apr 19 17:16 README.md
-rw-r--r--   1 saintway  staff   821B Apr 19 17:16 config.json
-rw-r--r--   1 saintway  staff    69B Apr 19 17:16 eval_results.txt
-rw-r--r--   1 saintway  staff   230B Apr 19 19:28 modules.json
-rw-r--r--   1 saintway  staff   1.2G Apr 19 17:23 pytorch_model.bin
-rw-r--r--   1 saintway  staff    54B Apr 19 19:28 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   125B Apr 19 17:23 special_tokens_map.json
-rw-r--r--   1 saintway  staff   429K Apr 19 17:23 tokenizer.json
-rw-r--r--   1 saintway  staff   514B Apr 19 17:23 tokenizer_config.json
-rw-r--r--   1 saintway  staff   107K Apr 19 17:23 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.2G	/Users/saintway/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Transformer and Indexer</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;GanymedeNil/text2vec-large-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">faiss</span>
<span class="n">indexer</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Preparing Text</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">BSHTMLLoader</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s1">&#39;_morning/htm&#39;</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">BSHTMLLoader</span><span class="p">)</span>
<span class="n">raw_documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="k">for</span> <span class="n">raw_document</span> <span class="ow">in</span> <span class="n">raw_documents</span><span class="p">:</span>
    <span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="s1">&#39;。</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Embedding</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">embed</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">sentences</span>

    <span class="c1"># words = extra_text.split(&#39; &#39;)</span>
    <span class="c1"># sentences = [words[i: i+num_words] for i in range(0, len(words), num_words)]</span>
    <span class="c1"># sentences = [&#39; &#39;.join(word_list) for word_list in sentences]</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="s1">&#39;。</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))):</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">sentence</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Number of Sentences:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
    <span class="c1"># print(sentences)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Embedding the sentences...&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">raw_document</span> <span class="ow">in</span> <span class="n">raw_documents</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">embeddings</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1024</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Loading Faiss Indexer from Disk</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">pickle</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="c1"># load vectorstore</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">indexer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Indexing</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Building the index...&#39;</span><span class="p">)</span>
<span class="n">indexer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">index.ntotal:&#39;</span><span class="p">,</span> <span class="n">indexer</span><span class="o">.</span><span class="n">ntotal</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Saving Faiss Indexer to Disk</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="c1"># save vectorstore</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/lert_indexing_morning.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">indexer</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/lert_indexing_morning.pkl
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
-rw-r--r--  1 saintway  staff    55M Apr 19 21:42 /Users/saintway/lert_indexing_morning.pkl
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Searching</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">retrieve</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Searching for:&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">xq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
    <span class="n">D</span><span class="p">,</span> <span class="n">I</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">xq</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distance:&#39;</span><span class="p">,</span> <span class="n">D</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Index:&#39;</span><span class="p">,</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Retrieving related information...&#39;</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">result:&#39;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;你知道什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;第八周讲了什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;七倍加强的灵是什么？&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Retrieving extra information...
[656.14075 686.03516 686.03516 701.83813 708.9243  709.8529  711.5835
 729.1748  740.6108  756.9905  759.0303  759.19086 760.30756 762.8627
 763.7213  764.0825  770.2078  770.9846  771.6991  776.6118 ]
[ 5330  6025  8696  4925  1817   292  3119  6404  2026  5745  2730  9065
   509 12541 12823  1832 12689   263 10313  2867]

result: 你会明白主的心思，你也会知道什么是主的意愿。
你知道每一个十字路口都是一个十字架么？有的是大十字架，有的是小十字架，但它们都是十字架。
你知道每一个十字路口都是一个十字架么？有的是大十字架，有的是小十字架，但它们都是十字架。
你晓得误会是从哪里来的么？它的根源常常是不纯净。
我和你们交通这事，是要让你们晓得我们的书撰写的方式。
当我们愿意对祂说，“主啊，我不知道自己的光景如何，也不知道自己需要什么；但是你知道。
……“我从前风闻有你，现在亲眼看见你。
反之，我们该问这里的真理是什么，也该问顺从真理是什么意思。
九节说，“少年人用什么使他的行径纯洁呢？是要遵行你的话。
那时你为你的大名要怎样行呢？
有些人不能明白主的恢复是怎么一回事。
帖后2:5　我还在你们那里的时候，曾一再把这些事告诉你们，你们不记得么？
我要向全宇宙宣告，无论事情怎样，我相信你是我的神。
”当时我并不知道那是什么，直到我进到召会中，与你们一同站在一的立场上。
就一面的意义说，我们不知道什么，也不作什么。
到那时候你就晓得如何向别人陈明真理，不是仅仅激发或激动人，而是使人扎实，得着真理的构成（李常受文集一九八四年第二册，四○二至四○三页）。
论到借着赞美主而从事属灵的争战，我要温柔地请问你们这些一同学习的弟兄姊妹：“在这个月里，你个人向着主有几次赞美呢？今年你赞美主几次呢？年长的圣徒们，在主的恢复这许多年来，你有没有赞美主呢？”有些人可能说，“有。
可能你经历一段感情的结束，当时不明白为什么会发生这样的事，日后回想，才懂得感谢神。
在宇宙中有这么多的东西，有这么多的故事；但是六千年来，还没有一个人看见过神。
然而，我们是否真正明白在主的恢复里是什么意思，主所恢复的又是什么？以下的信息会指出三个主要的点，说明主的恢复到底是什么。


Retrieving extra information...
[336.1584  336.1584  336.1584  336.1584  336.1584  336.1584  437.74524
 457.0722  491.19138 524.97955 547.4698  561.1646  561.1646  635.23145
 641.3999  641.3999  641.3999  641.3999  641.3999  641.3999 ]
[10211 10762 11196 12282 12928 13579 13596 11211 12946 12292 10226  5370
  9340  2110  3021  4193  4830  5107  5176  6307]

result: 第八周
第八周
第八周
第八周
第八周
第八周
第八周　周六
第八周　周一
第八周　周五
第八周　周四
第八周　周二
第八篇
第八篇
”（八页）
第七周
第七周
第七周
第七周
第七周
第七周


Retrieving extra information...
[149.68991 257.37964 293.2322  390.10983 412.68298 416.7586  426.44324
 448.9715  448.9715  448.9715  474.88263 485.05545 510.15057 515.02356
 539.4849  539.485   539.485   539.485   543.3683  544.59344]
[ 9906  9659  9919  3820  9914  3819  9908  6576  9134 13120  3777  9967
    28    99    13    79  4119  5287  9977  9915]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
我们需要在以下各方面享受基督作七倍加强的灵。
七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。
我们需要在以下各方面享受基督作七倍加强的灵
”耶和华的七眼也是七倍加强的灵。
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。
至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。
随着金这样成形在你里面，就会有七灵照耀并彰显神。
召会作灯台有七灯，就是神的七灵。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶
我们若向主认真，愿意起来建造神的殿，我们就需要看见，今天在主恢复的众召会中间，最大的需要就是经历七倍加强的灵。

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。\n今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。\n这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。\n我们需要在以下各方面享受基督作七倍加强的灵。\n七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。\n我们需要在以下各方面享受基督作七倍加强的灵\n”耶和华的七眼也是七倍加强的灵。\n三\u3000我们需要在以下各方面享受基督作七倍加强的灵：\n三\u3000我们需要在以下各方面享受基督作七倍加强的灵：\n三\u3000我们需要在以下各方面享受基督作七倍加强的灵：\n那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。\n至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。\n随着金这样成形在你里面，就会有七灵照耀并彰显神。\n召会作灯台有七灯，就是神的七灵。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n３\u3000经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。\n七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶\n我们若向主认真，愿意起来建造神的殿，我们就需要看见，今天在主恢复的众召会中间，最大的需要就是经历七倍加强的灵。\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;七倍加强的灵是什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;问题：七倍加强的灵是什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve</span><span class="p">(</span><span class="s1">&#39;用户提供了一段文本片段，但没有明确说明文档的主题。</span><span class="se">\n</span><span class="s1">问题：七倍加强的灵是什么？&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Retrieving extra information...
[149.68991 257.37964 293.2322  390.10983 412.68298 416.7586  426.44324
 448.9715  448.9715  448.9715  474.88263 485.05545 510.15057 515.02356
 539.4849  539.485   539.485   539.485   543.3683  544.59344]
[ 9906  9659  9919  3820  9914  3819  9908  6576  9134 13120  3777  9967
    28    99    13    79  4119  5287  9977  9915]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
我们需要在以下各方面享受基督作七倍加强的灵。
七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。
我们需要在以下各方面享受基督作七倍加强的灵
”耶和华的七眼也是七倍加强的灵。
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。
至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。
随着金这样成形在你里面，就会有七灵照耀并彰显神。
召会作灯台有七灯，就是神的七灵。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶
我们若向主认真，愿意起来建造神的殿，我们就需要看见，今天在主恢复的众召会中间，最大的需要就是经历七倍加强的灵。


Retrieving extra information...
[207.48007 293.95245 316.6468  394.41498 415.14142 427.4111  440.00018
 440.00018 440.00018 456.50128 494.71838 507.38333 543.869   543.869
 543.869   546.0684  546.0684  546.0684  546.0684  550.43463]
[ 9906  9659  9919  3820  3819  9914  6576  9134 13120  9908  3777  9967
  1349  4167  5299    13    79  4119  5287  6918]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
我们需要在以下各方面享受基督作七倍加强的灵。
我们需要在以下各方面享受基督作七倍加强的灵
七倍加强的灵乃是为着三一神完满的彰显和神殿的重建。
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
三　我们需要在以下各方面享受基督作七倍加强的灵：
”耶和华的七眼也是七倍加强的灵。
那灵就是三一神经过种种过程，包括成为肉体、人性生活、钉死、复活、升天，成为赐生命、七倍加强的灵。
至终祂这赐生命的灵─七倍加强的灵─会把祂的生命分赐到我们全人里面，叫我们全人从里到外都变作生命。
a　召会作为灯台，乃是三一神扎实的具体化身，有七倍加强的灵作为神神圣性情的油。
a　召会作为灯台，乃是三一神扎实的具体化身，有七倍加强的灵作为神神圣性情的油。
a　召会作为灯台，乃是三一神扎实的具体化身，有七倍加强的灵作为神神圣性情的油。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
３　经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。
对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。


Retrieving extra information...
[455.2392  474.6516  554.92584 554.92584 554.92584 555.4395  558.1987
 561.82495 562.31335 562.31335 562.31335 573.8733  575.1859  578.14307
 582.34247 584.78894 590.16046 591.0485  592.72095 594.661  ]
[ 9906  9919 11058 13036 13470  1623  1622   813  3182  3861  5811  6918
  1880   488  9659  3820 13501  9728  3819  4528]

result: ”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。
这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。
一　很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
一　很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
一　很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。
很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战
”然而，主给我们的不是胆怯的灵，乃是能力的灵（参提后一7）。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。
然而在六节，当以斯拉在他的叙述中说到自己时，只说“他是经学家”，而不提他是亚伦家的祭司；他没有高举自己祭司的身分。
但那只是起始阶段的信心，并不是路加十八章里主要寻找的信心。
今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。
我们需要在以下各方面享受基督作七倍加强的灵。
在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎不懂得什么叫作属灵的争战。
然而，我讲这篇信息时，里面并没有责备的灵。
我们需要在以下各方面享受基督作七倍加强的灵
提前6:7　因为我们没有带什么到世界来，也不能带什么去；

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;”七灵乃是七倍加强的灵，不是七个灵，而是一位灵加强了七倍。\n这灵加强了七倍，不是为着我们的属灵或能力，而是完全为着建造。\n一\u3000很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n一\u3000很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n一\u3000很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战。\n很可惜的是，在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎都不懂得什么叫作属灵的争战\n”然而，主给我们的不是胆怯的灵，乃是能力的灵（参提后一7）。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。\n然而在六节，当以斯拉在他的叙述中说到自己时，只说“他是经学家”，而不提他是亚伦家的祭司；他没有高举自己祭司的身分。\n但那只是起始阶段的信心，并不是路加十八章里主要寻找的信心。\n今天这赐生命的灵是七倍加强的，我们能以七倍加强的方式来经历这复活的生命。\n我们需要在以下各方面享受基督作七倍加强的灵。\n在今日的召会中，因着生命的软弱，属灵力量的缺乏，和真理亮光的不够明亮，信徒几乎不懂得什么叫作属灵的争战。\n然而，我讲这篇信息时，里面并没有责备的灵。\n我们需要在以下各方面享受基督作七倍加强的灵\n提前6:7\u3000因为我们没有带什么到世界来，也不能带什么去；\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Chat with PDF</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_in_english</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;You are an AI agent that summarizes chat in less than three setences.&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_in_chinese</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;系统&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">chats_in_english</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;You are an AI assistant providing helpful advice.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;You are given the following extracted parts of a long document and a question.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;Provide a conversational answer based on the context provided.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;You should only provide hyperlinks that reference the context below.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;Do NOT make up hyperlinks.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;If you can</span><span class="se">\&#39;</span><span class="s1">t find the answer in the context below, use your prior knowledge,</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;but in most of the cases the answer will be in the context.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="c1"># &#39;If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\n&#39; + \</span>
    <span class="s1">&#39;Answer in Markdown format.</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">chats_in_chinese</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;系统&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;你是一个提供有用建议的 AI 助手。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;你被提供了一份长文档的一部分（额外信息）和一个问题。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;请根据我所提供的文本提供会话式的回答。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;你只应该提供与下面的文本相关的超链接。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;**不要**编造超链接。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;如果在下面的文本中找不到答案，可以使用你先前所知道的知识，</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;但在大多数情况下，答案是在文本中的。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="c1"># &#39;如果问题与上下文不相关，请礼貌地回复您只回答与上下文相关的问题。\n&#39; + \</span>
    <span class="s1">&#39;请用中文以 Markdown 格式回答。</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">PyPDF2</span>

<span class="k">def</span> <span class="nf">extract_text</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Extract text from a PDF file.&#39;&#39;&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">pdf_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">page</span><span class="o">.</span><span class="n">extract_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">PyPDF2</span><span class="o">.</span><span class="n">PdfReader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">pages</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_the_bot</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">,</span> <span class="n">openai_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;split sentences in chinese&#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OpenAI Key:&#39;</span><span class="p">,</span> <span class="n">openai_key</span><span class="p">)</span>

    <span class="n">pdf_content</span> <span class="o">=</span> <span class="n">extract_text</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Text Length:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_text</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Building the index...&#39;</span><span class="p">)</span>
    <span class="n">indexer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">pdf_content</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">index.ntotal:&#39;</span><span class="p">,</span> <span class="n">indexer</span><span class="o">.</span><span class="n">ntotal</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pdf_content</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">chat</span><span class="p">(</span><span class="n">chat_history</span><span class="p">,</span> <span class="n">user_input</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;chat in chinese&#39;&#39;&#39;</span>
    <span class="k">global</span> <span class="n">sentences</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">messages_in_chinese:&#39;</span><span class="p">,</span> <span class="n">messages_in_chinese</span><span class="p">)</span>
    <span class="c1"># messages_in_english.append({&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Question:\n&#39; + user_input})</span>
    <span class="c1"># print(&#39;\nmessages_in_english:&#39;, messages_in_english)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Summarizing the chat history...&#39;</span><span class="p">)</span>

    <span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">messages_in_chinese</span>
    <span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Summarized Histoy: </span><span class="si">{</span><span class="n">summary</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">extra_info</span> <span class="o">=</span> <span class="n">retrieve</span><span class="p">(</span><span class="n">summary</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;问题：&#39;</span> <span class="o">+</span> <span class="n">user_input</span><span class="p">)</span>

    <span class="n">chats_in_chinese</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;用户&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;额外信息：</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">extra_info</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;问题：&#39;</span> <span class="o">+</span> <span class="n">user_input</span><span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">chats_in_chinese:&#39;</span><span class="p">,</span> <span class="n">chats_in_chinese</span><span class="p">)</span>
    <span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">chats_in_chinese</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">chats_in_chinese</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
    <span class="p">)</span>

    <span class="n">chat_output</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">ChatGPT: </span><span class="si">{</span><span class="n">chat_output</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># messages_in_chinese.append({&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: user_input})</span>
    <span class="c1"># messages_in_chinese.append({&#39;role&#39;: &#39;助手&#39;, &#39;content&#39;: chat_output})</span>
    <span class="k">yield</span> <span class="n">chat_history</span> <span class="o">+</span> <span class="p">[(</span><span class="n">user_input</span><span class="p">,</span> <span class="n">chat_output</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gradio</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_demo</span><span class="p">(</span><span class="n">mock_openai</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Blocks</span><span class="p">()</span> <span class="k">as</span> <span class="n">demo</span><span class="p">:</span>
        <span class="n">gradio</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="s1">&#39;Chat with a PDF document&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Tab</span><span class="p">(</span><span class="s1">&#39;Select PDF&#39;</span><span class="p">):</span>
            <span class="n">pdf</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">File</span><span class="p">()</span>
            <span class="n">openai_key</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;OpenAI API Key&#39;</span><span class="p">,)</span>
            <span class="n">text_output</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;PDF content&#39;</span><span class="p">)</span>
            <span class="n">text_button</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="s1">&#39;Build the Bot!!!&#39;</span><span class="p">)</span>
            <span class="n">text_button</span><span class="o">.</span><span class="n">click</span><span class="p">(</span><span class="n">build_the_bot</span><span class="p">,</span> <span class="p">[</span><span class="n">pdf</span><span class="p">,</span> <span class="n">openai_key</span><span class="p">],</span> <span class="n">text_output</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Tab</span><span class="p">(</span><span class="s1">&#39;Knowledge Bot&#39;</span><span class="p">):</span>
            <span class="n">chatbot</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Chatbot</span><span class="p">()</span>
            <span class="n">message</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="s1">&#39;What is this document about?&#39;</span><span class="p">)</span>
            <span class="n">message</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="p">[</span><span class="n">chatbot</span><span class="p">,</span> <span class="n">message</span><span class="p">],</span> <span class="n">chatbot</span><span class="p">)</span>
    <span class="n">demo</span><span class="o">.</span><span class="n">queue</span><span class="p">()</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">debug</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">True</span>
    <span class="n">demo</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ipymock</span> <span class="kn">import</span> <span class="n">do</span>
<span class="kn">from</span> <span class="nn">ipymock.browser</span> <span class="kn">import</span> <span class="n">common</span><span class="p">,</span> <span class="n">get_conversation</span><span class="p">,</span> <span class="n">mock_openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">common</span><span class="o">.</span><span class="n">conversation_id</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do</span><span class="p">(</span>
    <span class="n">mock_openai</span><span class="o">=</span><span class="n">mock_openai</span><span class="p">,</span>
    <span class="n">test_demo</span><span class="o">=</span><span class="n">test_demo</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
=&gt; no.0  ::tools::test_demo  setup  passed

Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div><iframe src="http://127.0.0.1:7860/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen></iframe></div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 本文讨论 TerraUSD 稳定币的稳定机制和去年的脱锚事件，并强调了维持“基础锚定市场”和“外部锚定市场”的套利行为所控制的市场的规模比较对于了解稳定币的稳定性很重要。最后，文章提出了将“外部锚定市场”转化为“基础锚定市场”是提高系统稳定性的唯一方法。

Retrieving extra information...
[575.85126 580.8882  583.3136  587.01587 588.3385  609.59955 610.3556
 611.7924  611.7924  611.7924  612.34534 612.8718  613.65656 614.2593
 617.09534 619.9896  622.2654  624.4966  624.9232  625.8043 ]
[ 6397  6622  3147 12978  4241  4792 11808  3182  3861  5811  6711  3874
  8512  2782  6918  1994 13386  3155  5450 12342]

result: 实际上，这是指我们的心思、情感和意志，从神以外的各样事物中蒙拯救，而固定在神这唯一的对象和独一的目标上。
因此，一个地方召会建立在其上的召会立场，必须是由“一”所构成，并在“一”里得维系；这一乃是由那灵执行，并由召会所在地保守的（李常受文集一九九三年第二册，九○至九一页）。
I.　The Lord&#39;s recovery is unique, and it must be absolutely pure, single, and holy, without any mixture; thus, we need Ezras and Nehemiahs to carry out a purifying work; in all the steps of the Lord&#39;s recovery, there is the need of purification:
要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除了任何形式的狡猾雄心。
……我们若不应用这原则，一切未受钉十字架察验的天然性能、才干和美德，在我们中间就会像“野兽”一样。
我们必须非常纯净，使圣别的种类永远不会与任何外邦的事物混合（李常受文集一九六九年第二册，四九六至四九七页）。
E.　Nehemiah, as the governor, in the position of a king, was a man with a pure heart for the rebuilding of Jerusalem&#39;s wall in carrying out God&#39;s economy; he was a pattern of what a leader among God&#39;s people should be—cf. 1 Tim. 3:2-7; 1 Pet. 5:1-3:
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
三　对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。
本篇信息的篇题是“洁净被掳归回之人的内在意义”。
我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。
2.　The problem is that we have come back from Babylon to Jerusalem, yet at Jerusalem we may still keep many things for our own interests; we may not offer everything on the altar for God&#39;s interests and for God&#39;s satisfaction—Rom. 12:1:
在主恢复之外的人无法理解我们中间到底是怎么运作的。
对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。
这里所说重新构成的需要，有如以色列人从埃及出来之时的需要；但从巴比伦归回的百姓因着和外邦人通婚而有了搀杂，使得情形更加艰难。
B.　Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God&#39;s eternal economy:
a.　The Lord&#39;s recovery is the holy seed; we must be so pure that the holy seed will never be mingled with anything heathen.
1.　In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;
这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n1.\u3000It is very difficult to find a person whose spirit is pure (7:1); pureness is the prerequisite in the leadership and a basic condition of our service (1 Tim. 3:9; 1:5); the problem of mixture is the greatest problem among workers; impureness is often the source of misunderstanding and suspicion (2 Tim. 1:3; 1 Tim. 3:9; Titus 1:15).\n反之，我们该问这里的真理是什么，也该问顺从真理是什么意思。\nA.\u3000All of us should look to the Lord and pray that we will have dispensational value to God; we need to ask ourselves what we are doing to close this dispensation and to bring in the next age, the kingdom age; this is a special time, so there is the need of special believers to do a special work.\nVI.\u3000With God\&#39;s move, as the divine history, in man\&#39;s history, there is the new creation—the new man with a new heart, a new spirit, a new life, a new nature, a new history, and a new consummation; we praise the Lord that we are in the divine history, experiencing and enjoying the mysterious, divine things for our organic salvation, so that we may make ourselves ready to become His overcoming bride to bring Him back—Hymns, #16; Rom. 5:10, 17-18, 21; 6:4; Ezek. 36:26; 2 Cor. 3:16-18; Matt. 5:8; Titus 3:5; Eph. 5:26-27; 6:17-18; Rev. 19:7; Matt. 24:44; 25:10.\n用这样的题目作为本次训练的总结，甚至作整本圣经结晶读经的总结，似乎让人感到意外。\nC.\u3000There was the need of teaching and reconstitution to bring the people of God into a culture that was according to God, a culture that expressed God; this kind of culture requires a great deal of education—v. 8.\n1.\u3000A factious man is a heretical, sectarian man who causes divisions by forming parties in the church according to his own opinions; in order to maintain good order in the church, a factious, divisive person should be refused, rejected, after a first and second admonition—v. 10.\n以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\n1.\u3000Literally, the Greek words rendered &#34;faith&#34; mean &#34;the faith&#34;; this denotes the persistent faith for our persistent prayer, like that of the widow.\nI.\u3000The intrinsic significance of Ezra\&#39;s ministry is embodied in the words purification, education, and reconstitution; the intrinsic significance of Nehemiah\&#39;s leadership is embodied in the words separation, protection, and expression; we need to cooperate with the Lord in His heavenly ministry to build up the church as the house of God and the kingdom of God by living out and working out the New Jerusalem according to this intrinsic significance—1 Kings 8:48; Psa. 48:1-2; 1 Tim. 3:15; Eph. 2:21-22.\n”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。\nC.\u3000The law makes demands on man according to what God is; grace supplies man with what God is to meet what God demands; grace is God enjoyed by man—John 1:16-17; Gal. 6:18; 2 Cor. 13:14; 12:9; 1 Pet. 4:10; Eph. 3:2; 4:29; 6:24.\nb.\u3000If we see that the prayers of the greatest worth are prayers in ascension, then we can understand that prayer is a warfare, and we will utter prayers of warfare; such is the nature of the prayer spoken of in Ephesians 6:\n3.\u3000If a church goes astray or is misled, the apostles have the obligation and responsibility to deal with the situation according to God\&#39;s word, which has authority—vv. 26-27; 2 Cor. 10:6; 2 Tim. 1:13; 4:2.\nThe Intrinsic Significance of the Purification of the Returned Captives\n2.\u3000We all need to be helped through the Life-studies and the Recovery Version with the footnotes to see the intrinsic significance of the word of the Bible—Neh. 8:8, 13.\nB.\u3000They were unaware that the dispensation of law was altogether over, that the dispensation of grace should be fully honored, and that any disregard of the distinction between these two dispensations would be against God\&#39;s dispensational administration and would be a great damage to God\&#39;s economical plan for the building up of the church as the expression of Christ—John 1:16-17; Rev. 2:9.\nIII.\u3000In the Lord\&#39;s recovery we need Ezras, priestly teachers who contact God, who are saturated with God, who are one with God, who are mingled with God, who are filled with God, and who are skillful in the Word of God; this is the kind of person who is qualified to be a teacher in the recovery—Matt. 13:52; 2 Cor. 3:5-6; 1 Tim. 2:7; 2 Tim. 1:11:\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n实际上，这是指我们的心思、情感和意志，从神以外的各样事物中蒙拯救，而固定在神这唯一的对象和独一的目标上。\n因此，一个地方召会建立在其上的召会立场，必须是由“一”所构成，并在“一”里得维系；这一乃是由那灵执行，并由召会所在地保守的（李常受文集一九九三年第二册，九○至九一页）。\nI.\u3000The Lord\&#39;s recovery is unique, and it must be absolutely pure, single, and holy, without any mixture; thus, we need Ezras and Nehemiahs to carry out a purifying work; in all the steps of the Lord\&#39;s recovery, there is the need of purification:\n要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除了任何形式的狡猾雄心。\n……我们若不应用这原则，一切未受钉十字架察验的天然性能、才干和美德，在我们中间就会像“野兽”一样。\n我们必须非常纯净，使圣别的种类永远不会与任何外邦的事物混合（李常受文集一九六九年第二册，四九六至四九七页）。\nE.\u3000Nehemiah, as the governor, in the position of a king, was a man with a pure heart for the rebuilding of Jerusalem\&#39;s wall in carrying out God\&#39;s economy; he was a pattern of what a leader among God\&#39;s people should be—cf. 1 Tim. 3:2-7; 1 Pet. 5:1-3:\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n本篇信息的篇题是“洁净被掳归回之人的内在意义”。\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。\n2.\u3000The problem is that we have come back from Babylon to Jerusalem, yet at Jerusalem we may still keep many things for our own interests; we may not offer everything on the altar for God\&#39;s interests and for God\&#39;s satisfaction—Rom. 12:1:\n在主恢复之外的人无法理解我们中间到底是怎么运作的。\n对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。\n这里所说重新构成的需要，有如以色列人从埃及出来之时的需要；但从巴比伦归回的百姓因着和外邦人通婚而有了搀杂，使得情形更加艰难。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\na.\u3000The Lord\&#39;s recovery is the holy seed; we must be so pure that the holy seed will never be mingled with anything heathen.\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。\n\n\n问题：What is this document about?&#39;}]

ChatGPT: 根据文本，召会立场必须由“一”所构成，并在“一”里得维系；这是由那灵执行，并由召会所在地保守的。因此，要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除任何形式的狡猾雄心。需要对付灵重在对付我

messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 好的，这次对话主要涉及到了对人类情感的理解、人工智能在医疗行业的应用、以及人工智能与工作的关系。

Retrieving extra information...
[560.0207  580.6549  599.6284  603.5715  604.7684  605.70654 606.26
 607.6616  609.8817  616.5469  618.50104 620.88055 622.4879  622.8662
 624.0831  626.81396 627.3507  628.6865  629.2973  631.0054 ]
[ 2690 12691  6988  7878 10302  3872  6436  7779  1832  1875   263  2023
  1885  3506 12498  2051  1817  2959 12342  7023]

result: 《对同工长老们以及爱主寻求主者爱心的话》一书，第四章的题目就是“正确的跟随人”。
”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。
我们不该把启示录二十一、二十二章里“纯”、“明净”、“透明”这些辞视为理所当然，我们读的时候，需要对这些辞有更深入、更扩大的领会。
本篇信息乃是要将这些辞一一应用于我们的经历。
并且他这话不是凭空说的，也不是想像出来的；乃是他根据许多的事实，所产生出来的一个感觉。
我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。
因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。
当我们借由这分职事的帮助来读主话的时候，就能看见主的话是何等美妙。
到那时候你就晓得如何向别人陈明真理，不是仅仅激发或激动人，而是使人扎实，得着真理的构成（李常受文集一九八四年第二册，四○二至四○三页）。
”经学家的功用需要配上祭司的功用；祭司的功用是借着我们在灵里与主联合，与主是一而享受主，但其中也需要话。
可能你经历一段感情的结束，当时不明白为什么会发生这样的事，日后回想，才懂得感谢神。
这里所列诗篇一百一十九篇的经节，给我们看见诗人不仅爱神、寻求神的说话，他也有祭司经学家的功用。
我们都该盼望被人这样描述：这位弟兄对圣经爱不释手，并且他手中神的话就是他手中神的智慧。
在篇题里我们看见有人的历史，然而在人的历史里有神的历史。
有些人可能第一次听见这样的话，在此我们也只能讲到一些基本的内容。
”（世界局势与神的行动，三七页）长老与同工都该是祭司教师，就是习练于圣经中的话语，并且善于教导。
我和你们交通这事，是要让你们晓得我们的书撰写的方式。
在《对同工长老们以及爱主寻求主者爱心的话》一书中，有对我们的警告：“你在跟随任何你所欣赏，并叫你受吸引之同工的事上，必须谨慎。
这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。
”我们各人都要在与主私下、亲密的交通中向主祷告，以回应本篇信息的话。


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n1.\u3000It is very difficult to find a person whose spirit is pure (7:1); pureness is the prerequisite in the leadership and a basic condition of our service (1 Tim. 3:9; 1:5); the problem of mixture is the greatest problem among workers; impureness is often the source of misunderstanding and suspicion (2 Tim. 1:3; 1 Tim. 3:9; Titus 1:15).\n反之，我们该问这里的真理是什么，也该问顺从真理是什么意思。\nA.\u3000All of us should look to the Lord and pray that we will have dispensational value to God; we need to ask ourselves what we are doing to close this dispensation and to bring in the next age, the kingdom age; this is a special time, so there is the need of special believers to do a special work.\nVI.\u3000With God\&#39;s move, as the divine history, in man\&#39;s history, there is the new creation—the new man with a new heart, a new spirit, a new life, a new nature, a new history, and a new consummation; we praise the Lord that we are in the divine history, experiencing and enjoying the mysterious, divine things for our organic salvation, so that we may make ourselves ready to become His overcoming bride to bring Him back—Hymns, #16; Rom. 5:10, 17-18, 21; 6:4; Ezek. 36:26; 2 Cor. 3:16-18; Matt. 5:8; Titus 3:5; Eph. 5:26-27; 6:17-18; Rev. 19:7; Matt. 24:44; 25:10.\n用这样的题目作为本次训练的总结，甚至作整本圣经结晶读经的总结，似乎让人感到意外。\nC.\u3000There was the need of teaching and reconstitution to bring the people of God into a culture that was according to God, a culture that expressed God; this kind of culture requires a great deal of education—v. 8.\n1.\u3000A factious man is a heretical, sectarian man who causes divisions by forming parties in the church according to his own opinions; in order to maintain good order in the church, a factious, divisive person should be refused, rejected, after a first and second admonition—v. 10.\n以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\n1.\u3000Literally, the Greek words rendered &#34;faith&#34; mean &#34;the faith&#34;; this denotes the persistent faith for our persistent prayer, like that of the widow.\nI.\u3000The intrinsic significance of Ezra\&#39;s ministry is embodied in the words purification, education, and reconstitution; the intrinsic significance of Nehemiah\&#39;s leadership is embodied in the words separation, protection, and expression; we need to cooperate with the Lord in His heavenly ministry to build up the church as the house of God and the kingdom of God by living out and working out the New Jerusalem according to this intrinsic significance—1 Kings 8:48; Psa. 48:1-2; 1 Tim. 3:15; Eph. 2:21-22.\n”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。\nC.\u3000The law makes demands on man according to what God is; grace supplies man with what God is to meet what God demands; grace is God enjoyed by man—John 1:16-17; Gal. 6:18; 2 Cor. 13:14; 12:9; 1 Pet. 4:10; Eph. 3:2; 4:29; 6:24.\nb.\u3000If we see that the prayers of the greatest worth are prayers in ascension, then we can understand that prayer is a warfare, and we will utter prayers of warfare; such is the nature of the prayer spoken of in Ephesians 6:\n3.\u3000If a church goes astray or is misled, the apostles have the obligation and responsibility to deal with the situation according to God\&#39;s word, which has authority—vv. 26-27; 2 Cor. 10:6; 2 Tim. 1:13; 4:2.\nThe Intrinsic Significance of the Purification of the Returned Captives\n2.\u3000We all need to be helped through the Life-studies and the Recovery Version with the footnotes to see the intrinsic significance of the word of the Bible—Neh. 8:8, 13.\nB.\u3000They were unaware that the dispensation of law was altogether over, that the dispensation of grace should be fully honored, and that any disregard of the distinction between these two dispensations would be against God\&#39;s dispensational administration and would be a great damage to God\&#39;s economical plan for the building up of the church as the expression of Christ—John 1:16-17; Rev. 2:9.\nIII.\u3000In the Lord\&#39;s recovery we need Ezras, priestly teachers who contact God, who are saturated with God, who are one with God, who are mingled with God, who are filled with God, and who are skillful in the Word of God; this is the kind of person who is qualified to be a teacher in the recovery—Matt. 13:52; 2 Cor. 3:5-6; 1 Tim. 2:7; 2 Tim. 1:11:\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n实际上，这是指我们的心思、情感和意志，从神以外的各样事物中蒙拯救，而固定在神这唯一的对象和独一的目标上。\n因此，一个地方召会建立在其上的召会立场，必须是由“一”所构成，并在“一”里得维系；这一乃是由那灵执行，并由召会所在地保守的（李常受文集一九九三年第二册，九○至九一页）。\nI.\u3000The Lord\&#39;s recovery is unique, and it must be absolutely pure, single, and holy, without any mixture; thus, we need Ezras and Nehemiahs to carry out a purifying work; in all the steps of the Lord\&#39;s recovery, there is the need of purification:\n要履行同工或长老的义务，就必须有清洁的心，在主的恢复中，在存心、目的、动机和行动上，洁除了任何形式的狡猾雄心。\n……我们若不应用这原则，一切未受钉十字架察验的天然性能、才干和美德，在我们中间就会像“野兽”一样。\n我们必须非常纯净，使圣别的种类永远不会与任何外邦的事物混合（李常受文集一九六九年第二册，四九六至四九七页）。\nE.\u3000Nehemiah, as the governor, in the position of a king, was a man with a pure heart for the rebuilding of Jerusalem\&#39;s wall in carrying out God\&#39;s economy; he was a pattern of what a leader among God\&#39;s people should be—cf. 1 Tim. 3:2-7; 1 Pet. 5:1-3:\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n三\u3000对付灵重在对付我们里面不纯的动机、存心和其他杂质—帖前五23，提后一7。\n本篇信息的篇题是“洁净被掳归回之人的内在意义”。\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。\n2.\u3000The problem is that we have come back from Babylon to Jerusalem, yet at Jerusalem we may still keep many things for our own interests; we may not offer everything on the altar for God\&#39;s interests and for God\&#39;s satisfaction—Rom. 12:1:\n在主恢复之外的人无法理解我们中间到底是怎么运作的。\n对付灵重在对付我们里面不纯的动机、存心和其他杂质（帖前五23，提后一7）。\n这里所说重新构成的需要，有如以色列人从埃及出来之时的需要；但从巴比伦归回的百姓因着和外邦人通婚而有了搀杂，使得情形更加艰难。\nB.\u3000Recovery means the restoration or return to a normal condition after a damage or a loss has been incurred; recovery means to go back to God\&#39;s original intention and standard as revealed in the Scriptures, which is according to the present advance of His recovery of the contents of God\&#39;s eternal economy:\na.\u3000The Lord\&#39;s recovery is the holy seed; we must be so pure that the holy seed will never be mingled with anything heathen.\n1.\u3000In Romans 14 Paul was liberal and gracious regarding the receiving of those who differ in doctrine or practice; however, in Romans 16:17 he was unyielding and resolute in saying that we must &#34;mark those who make divisions and causes of stumbling contrary to the teaching which you have learned, and turn away from them.&#34;\n这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n《对同工长老们以及爱主寻求主者爱心的话》一书，第四章的题目就是“正确的跟随人”。\n”但我还要问：“你是为着什么赞美主？是什么时候赞美主呢？是一切都顺利，一切都美好的时候赞美主么？当你在手术台上的时候，能不能赞美主呢？当你要动心脏手术，在加护病房里，或是当你所爱的人过世的时候，你能不能赞美呢？”我们不是为着任何事件赞美主。\n我们不该把启示录二十一、二十二章里“纯”、“明净”、“透明”这些辞视为理所当然，我们读的时候，需要对这些辞有更深入、更扩大的领会。\n本篇信息乃是要将这些辞一一应用于我们的经历。\n并且他这话不是凭空说的，也不是想像出来的；乃是他根据许多的事实，所产生出来的一个感觉。\n我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。\n因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。\n当我们借由这分职事的帮助来读主话的时候，就能看见主的话是何等美妙。\n到那时候你就晓得如何向别人陈明真理，不是仅仅激发或激动人，而是使人扎实，得着真理的构成（李常受文集一九八四年第二册，四○二至四○三页）。\n”经学家的功用需要配上祭司的功用；祭司的功用是借着我们在灵里与主联合，与主是一而享受主，但其中也需要话。\n可能你经历一段感情的结束，当时不明白为什么会发生这样的事，日后回想，才懂得感谢神。\n这里所列诗篇一百一十九篇的经节，给我们看见诗人不仅爱神、寻求神的说话，他也有祭司经学家的功用。\n我们都该盼望被人这样描述：这位弟兄对圣经爱不释手，并且他手中神的话就是他手中神的智慧。\n在篇题里我们看见有人的历史，然而在人的历史里有神的历史。\n有些人可能第一次听见这样的话，在此我们也只能讲到一些基本的内容。\n”（世界局势与神的行动，三七页）长老与同工都该是祭司教师，就是习练于圣经中的话语，并且善于教导。\n我和你们交通这事，是要让你们晓得我们的书撰写的方式。\n在《对同工长老们以及爱主寻求主者爱心的话》一书中，有对我们的警告：“你在跟随任何你所欣赏，并叫你受吸引之同工的事上，必须谨慎。\n这两件事虽然简单，却会使我们有正确的思维，以领会本篇关于历代志中特别之事内在意义的信息。\n”我们各人都要在与主私下、亲密的交通中向主祷告，以回应本篇信息的话。\n\n\n问题：这篇文档是关于什么的？&#39;}]

ChatGPT: 请问这篇文章的主题是什么？

这篇文章的主题是基督徒的信仰生活以及如何正确地跟随上帝。它提到了如何在生活中以正确的动机行动，如何在困难时仍然赞美上帝，以及如何通过阅读圣经来更好地了解上帝的话语。此外，文章还提到了作为基督徒的责任和角色，包括成为教师和祭司。
Keyboard interruption in main thread... closing server.
Closing server running on port: 7860
=&gt; no.0  ::tools::test_demo  runtest  passed

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
<span class="n">HuggingFaceEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;GanymedeNil/text2vec-large-chinese&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({&#39;max_seq_length&#39;: 128, &#39;do_lower_case&#39;: False}) with Transformer model: BertModel 
  (1): Pooling({&#39;word_embedding_dimension&#39;: 1024, &#39;pooling_mode_cls_token&#39;: False, &#39;pooling_mode_mean_tokens&#39;: True, &#39;pooling_mode_max_tokens&#39;: False, &#39;pooling_mode_mean_sqrt_len_tokens&#39;: False})
), model_name=&#39;GanymedeNil/text2vec-large-chinese&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ChatGLM-6B"><a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">ChatGLM 6B</a><a class="anchor-link" href="#ChatGLM-6B">&#182;</a></h2><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/THUDM/chatglm-6b">Hugging Face - ChatGLM 6B</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ninehills/chatglm-openai-api">https://github.com/ninehills/chatglm-openai-api</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Chinese-LLaMA-and-Alpaca"><a target="_blank" rel="noopener" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca">Chinese LLaMA and Alpaca</a><a class="anchor-link" href="#Chinese-LLaMA-and-Alpaca">&#182;</a></h2><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/ziqingyang/chinese-alpaca-lora-7b">Hugging Face - Chinese Alpaca LoRA 7B</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/ziqingyang/chinese-alpaca-lora-13b">Hugging Face - Chinese Alpaca LoRA 13B</a></li>
</ul>

</div>
</div>
</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/19/Text2Vec/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-12 </div>
			<div class="article-title"><a href="/2023/04/12/LangChain-Embeddings/" >LangChain Embeddings</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Open-Text-Embeddings">Open Text Embeddings<a class="anchor-link" href="#Open-Text-Embeddings">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="LangChain-Embeddings"><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/reference/modules/embeddings.html">LangChain Embeddings</a><a class="anchor-link" href="#LangChain-Embeddings">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="LLaMA-Embeddings"><a target="_blank" rel="noopener" href="https://huggingface.co/shalomma/llama-7b-embeddings">LLaMA Embeddings</a><a class="anchor-link" href="#LLaMA-Embeddings">&#182;</a></h4><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/abetlen/llama-cpp-python">https://github.com/abetlen/llama-cpp-python</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>llama-cpp-python
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully installed llama-cpp-python-0.1.32 typing-extensions-4.5.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p><a target="_blank" rel="noopener" href="https://huggingface.co/Pi3141/gpt4-x-alpaca-native-13B-ggml">GPT4 x Alpaca without LoRA ggml</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>git+https://github.com/huggingface/transformers
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span><span class="nv">tokenizers</span><span class="o">==</span><span class="m">0</span>.13.3<span class="w"> </span><span class="nv">protobuf</span><span class="o">==</span><span class="m">3</span>.20.*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: tokenizers==0.13.3 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (0.13.3)
Requirement already satisfied: protobuf==3.20.* in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (3.20.3)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/welcome">HuggingFace Welcome</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;chavinlo/gpt4-x-alpaca&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;chavinlo/gpt4-x-alpaca&#39;</span><span class="p">,</span> <span class="n">resume_download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--chavinlo--gpt4-x-alpaca/snapshots/6a571f458cab9a23d14324ec63e0abd1744c8353
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 0
drwxr-xr-x  14 saintway  staff   448B Apr 14 14:21 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   3 saintway  staff    96B Apr 12 21:08 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
lrwxr-xr-x   1 saintway  staff    52B Apr 12 21:34 <span class="ansi-magenta-fg">added_tokens.json</span> -&gt; ../../blobs/3e03d5f619baf8592fb936d63d05366f9304f7b2
lrwxr-xr-x   1 saintway  staff    52B Apr 12 21:43 <span class="ansi-magenta-fg">config.json</span> -&gt; ../../blobs/849ee4b803bc92eb21e60c3946d20e4cbc69eefa
lrwxr-xr-x   1 saintway  staff    76B Apr 13 02:27 <span class="ansi-magenta-fg">pytorch_model-00001-of-00006.bin</span> -&gt; ../../blobs/c022dd1d22c5ed2501abdb220f8315e6f51a5197026ed72bdbd2fdbac641d27b
lrwxr-xr-x   1 saintway  staff    76B Apr 13 13:32 <span class="ansi-magenta-fg">pytorch_model-00002-of-00006.bin</span> -&gt; ../../blobs/5481821b5869b58b15c3175e712e41cd6b7b5596557b10aa2c2655a4cf019a7a
lrwxr-xr-x   1 saintway  staff    76B Apr 14 11:53 <span class="ansi-magenta-fg">pytorch_model-00003-of-00006.bin</span> -&gt; ../../blobs/df46de31831a882cd57c9beefdad97e1ae442fe071871bad60223b23c1a08df9
lrwxr-xr-x   1 saintway  staff    76B Apr 14 13:21 <span class="ansi-magenta-fg">pytorch_model-00004-of-00006.bin</span> -&gt; ../../blobs/0e5f42d9943bdbc6e12288733a65d6e337c2cc1a3ff90654cdf96df3f43437ee
lrwxr-xr-x   1 saintway  staff    76B Apr 14 14:06 <span class="ansi-magenta-fg">pytorch_model-00005-of-00006.bin</span> -&gt; ../../blobs/6149b601c773fce7642e3424878c2c8182a221a2723e93d3da10e0f28850d00e
lrwxr-xr-x   1 saintway  staff    76B Apr 14 14:21 <span class="ansi-magenta-fg">pytorch_model-00006-of-00006.bin</span> -&gt; ../../blobs/1b02c47b8a6151783c6ab90a8e5acba320940d2197cff255cf8f23eab10f8180
lrwxr-xr-x   1 saintway  staff    52B Apr 12 21:43 <span class="ansi-magenta-fg">pytorch_model.bin.index.json</span> -&gt; ../../blobs/eb488e9b33396741832583081e6ca45eb6f4de49
lrwxr-xr-x   1 saintway  staff    52B Apr 12 21:34 <span class="ansi-magenta-fg">special_tokens_map.json</span> -&gt; ../../blobs/318f9131477d72be713dcfee9da3a2e43d7ac8ad
lrwxr-xr-x   1 saintway  staff    76B Apr 12 21:34 <span class="ansi-magenta-fg">tokenizer.model</span> -&gt; ../../blobs/9e556afd44213b6bd1be2b850ebbbd98f5481437a8021afaf58ee7fb1818d347
lrwxr-xr-x   1 saintway  staff    52B Apr 12 21:08 <span class="ansi-magenta-fg">tokenizer_config.json</span> -&gt; ../../blobs/8edc6b4c1db134f5d717a6a4f271dfa3194f2295
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--chavinlo--gpt4-x-alpaca/blobs
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 101790056
drwxr-xr-x  14 saintway  staff   448B Apr 14 22:10 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   7 saintway  staff   224B Apr 14 22:10 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   9.2G Apr 14 13:21 0e5f42d9943bdbc6e12288733a65d6e337c2cc1a3ff90654cdf96df3f43437ee
-rw-r--r--   1 saintway  staff   2.3G Apr 14 14:21 1b02c47b8a6151783c6ab90a8e5acba320940d2197cff255cf8f23eab10f8180
-rw-r--r--   1 saintway  staff    96B Apr 12 21:34 318f9131477d72be713dcfee9da3a2e43d7ac8ad
-rw-r--r--   1 saintway  staff    20B Apr 12 21:34 3e03d5f619baf8592fb936d63d05366f9304f7b2
-rw-r--r--   1 saintway  staff   9.3G Apr 14 22:10 5481821b5869b58b15c3175e712e41cd6b7b5596557b10aa2c2655a4cf019a7a
-rw-r--r--   1 saintway  staff   9.2G Apr 14 14:06 6149b601c773fce7642e3424878c2c8182a221a2723e93d3da10e0f28850d00e
-rw-r--r--   1 saintway  staff   535B Apr 12 21:43 849ee4b803bc92eb21e60c3946d20e4cbc69eefa
-rw-r--r--   1 saintway  staff   329B Apr 12 21:08 8edc6b4c1db134f5d717a6a4f271dfa3194f2295
-rw-r--r--   1 saintway  staff   488K Apr 12 21:34 9e556afd44213b6bd1be2b850ebbbd98f5481437a8021afaf58ee7fb1818d347
-rw-r--r--   1 saintway  staff   9.3G Apr 14 20:53 c022dd1d22c5ed2501abdb220f8315e6f51a5197026ed72bdbd2fdbac641d27b
-rw-r--r--   1 saintway  staff   9.3G Apr 14 11:53 df46de31831a882cd57c9beefdad97e1ae442fe071871bad60223b23c1a08df9
-rw-r--r--   1 saintway  staff    33K Apr 12 21:43 eb488e9b33396741832583081e6ca45eb6f4de49
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="n">alpaca_embeddings</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/.cache/huggingface/hub/models--chavinlo--gpt4-x-alpaca/snapshots/6a571f458cab9a23d14324ec63e0abd1744c8353/model.bin&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 准备文本</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;这是一个测试文档。&#39;</span>

<span class="c1"># 使用 HuggingFaceEmbeddings 生成文本嵌入</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">alpaca_embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">doc_result</span> <span class="o">=</span> <span class="n">alpaca_embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">query_result</span><span class="p">))</span>
<span class="c1"># print(query_result)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># print(doc_result)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/huggingface_hub/guides/download">Download files from the HuggingFace Hub</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">hf_hub_download</span>
<span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s1">&#39;Pi3141/gpt4-x-alpaca-native-13B-ggml&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;consolidated.00.pth&#39;</span><span class="p">,</span> <span class="n">resume_download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;/Users/saintway/.cache/huggingface/hub/models--Pi3141--gpt4-x-alpaca-native-13B-ggml/snapshots/43cce6aab1b95712d83165afafa3c7baad140eb9/consolidated.00.pth&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 用 Python 去掉文件中最后一个字节</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/.cache/huggingface/hub/models--Pi3141--gpt4-x-alpaca-native-13B-ggml/blobs/8d308284e190467111257950d4e8b34b1e3f19a70636fa6ea51dfa62f4cf5b55.incomplete&#39;</span><span class="p">),</span> <span class="s1">&#39;rb+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">filehandle</span><span class="p">:</span>
    <span class="n">filehandle</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
    <span class="n">filehandle</span><span class="o">.</span><span class="n">truncate</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">hf_hub_download</span>
<span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s1">&#39;Pi3141/gpt4-x-alpaca-native-13B-ggml&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;ggml-model-q4_1.bin&#39;</span><span class="p">,</span> <span class="n">resume_download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;/Users/saintway/.cache/huggingface/hub/models--Pi3141--gpt4-x-alpaca-native-13B-ggml/snapshots/43cce6aab1b95712d83165afafa3c7baad140eb9/ggml-model-q4_1.bin&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">snapshot_download</span>
<span class="n">snapshot_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s1">&#39;Pi3141/gpt4-x-alpaca-native-13B-ggml&#39;</span><span class="p">,</span> <span class="n">resume_download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Fetching 4 files:   0%|          | 0/4 [00:00&lt;?, ?it/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;/Users/saintway/.cache/huggingface/hub/models--Pi3141--gpt4-x-alpaca-native-13B-ggml/snapshots/43cce6aab1b95712d83165afafa3c7baad140eb9&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--Pi3141--gpt4-x-alpaca-native-13B-ggml/snapshots/43cce6aab1b95712d83165afafa3c7baad140eb9
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 0
drwxr-xr-x  6 saintway  staff   192B Apr 14 11:20 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x  3 saintway  staff    96B Apr 12 23:05 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
lrwxr-xr-x  1 saintway  staff    52B Apr 12 23:05 <span class="ansi-magenta-fg">.gitattributes</span> -&gt; ../../blobs/c7d9f3332a950355d5a77d85000f05e6f45435ea
lrwxr-xr-x  1 saintway  staff    52B Apr 12 23:05 <span class="ansi-magenta-fg">README.md</span> -&gt; ../../blobs/03dbe88acfdc7f800acf2423960468e1c852c9ba
lrwxr-xr-x  1 saintway  staff    76B Apr 14 11:20 <span class="ansi-magenta-fg">consolidated.00.pth</span> -&gt; ../../blobs/fd8008066e6af8a094d3703b7e3bbcb64cdca43e964288758d3b3a1ba6e41499
lrwxr-xr-x  1 saintway  staff    76B Apr 13 09:49 <span class="ansi-magenta-fg">ggml-model-q4_1.bin</span> -&gt; ../../blobs/8d308284e190467111257950d4e8b34b1e3f19a70636fa6ea51dfa62f4cf5b55
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--Pi3141--gpt4-x-alpaca-native-13B-ggml/blobs
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 90434208
drwxr-xr-x  9 saintway  staff   288B Apr 14 11:20 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x  6 saintway  staff   192B Apr 14 11:20 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--  1 saintway  staff   254B Apr 13 09:53 03dbe88acfdc7f800acf2423960468e1c852c9ba
-rw-r--r--@ 1 saintway  staff   9.1G Apr 13 09:53 8d308284e190467111257950d4e8b34b1e3f19a70636fa6ea51dfa62f4cf5b55
-rw-r--r--  1 saintway  staff   2.1G Apr 13 09:53 8d308284e190467111257950d4e8b34b1e3f19a70636fa6ea51dfa62f4cf5b55.incomplete.retry
-rw-r--r--  1 saintway  staff   1.4K Apr 13 09:53 c7d9f3332a950355d5a77d85000f05e6f45435ea
-rw-r--r--  1 saintway  staff    24G Apr 14 11:20 fd8008066e6af8a094d3703b7e3bbcb64cdca43e964288758d3b3a1ba6e41499
-rw-------  1 saintway  staff   6.2G Apr 13 09:53 fd8008066e6af8a094d3703b7e3bbcb64cdca43e964288758d3b3a1ba6e41499.incomplete.retry
-rw-r--r--  1 saintway  staff   1.5G Apr 13 09:53 fd8008066e6af8a094d3703b7e3bbcb64cdca43e964288758d3b3a1ba6e41499.incomplete.tempfile
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="n">alpaca_embeddings</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/ggml-model-q4_1.bin&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 3216.00 MB per state)
llama_init_from_file: kv self size  =  800.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 准备文本</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;这是一个测试文档。&#39;</span>

<span class="c1"># 使用 HuggingFaceInstructEmbeddings 生成文本嵌入</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">alpaca_embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">doc_result</span> <span class="o">=</span> <span class="n">alpaca_embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">query_result</span><span class="p">))</span>
<span class="c1"># print(query_result)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># print(doc_result)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 15205.17 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 28693.65 ms /    12 tokens ( 2391.14 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 28701.20 ms
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>5120
1
5120
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 15205.17 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time =  3616.78 ms /    12 tokens (  301.40 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time =  3628.49 ms
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://sj-langchain.readthedocs.io/en/latest/ecosystem/huggingface.html">LangChain with Hugging Face</a><ul>
<li><a target="_blank" rel="noopener" href="https://sj-langchain.readthedocs.io/en/latest/modules/llms/integrations/huggingface_hub.html">LLM from Hugging Face Hub</a></li>
<li><a target="_blank" rel="noopener" href="https://sj-langchain.readthedocs.io/en/latest/modules/indexes/examples/textsplitter.html">LangChain Text Splitter</a></li>
<li><a target="_blank" rel="noopener" href="https://sj-langchain.readthedocs.io/en/latest/use_cases/evaluation/huggingface_datasets.html">Evaluate Models using HuggingFace Datasets</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="c1"># (1) Import a series of documents.</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">TextLoader</span><span class="p">,</span> <span class="n">silent_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">raw_documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="c1"># (2) Split them into small chunks.</span>
    <span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
        <span class="n">chunk_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">get_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>26</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">get_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Document(page_content=&#39;title: Neuroscience\ndate: 2021-10-14 16:30:20\ntags: Neuro\n---\n\nThe [**ventral tegmental area**](https://en.wikipedia.org/wiki/Ventral_tegmental_area) (**VTA**) (**tegmentum** is Latin for covering), also known as the **ventral tegmental area of Tsai**, or simply **ventral tegmentum**, is a group of neurons located close to the midline on the floor of the midbrain.\n\n---\n\n&gt; \u3000\u3000有些权威认为，有必要把意识的内容 (content) 与“有意识状态的特性” (quality of being conscious) 或“意识本身” (consciousness as such) 区分开来²。这一划分与我的分类异曲同工。\n\u3000\u3000要想产生意识，必须先具备某些神经前提条件。我把这些条件称为 NCC_e。任一特定知觉的 NCC 都是局部作用的、高度特化的、转瞬即逝的，相比起来，NCC_e 的作用方式更全局化也更持久。要是没有相关的 NCC_e 的话，机体或许也还能有简单的行为，但在这样做时绝不会有意识（可能发生这种情形的某些病理条件将在第13章讨论）。根据定义可知，如果没有 NCC_e，就不可能形成任何 NCC。\n\u3000\u3000会不会有这样一种状态，即生物体虽然有意识，却意识不到任何具体内容？换句话说，NCC_e 能否脱离 NCC 而单独存在呢？某些冥想的目标就是要进入这种没有具体内容的意识形式³。但是在目前，还很难对它进行严格的分析。&#39;, metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;})</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">get_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Document(page_content=&#39;&gt; ² =&gt;\n\u3000\u3000有关文献包括：\n* Moore, Philosophical Studies (1922)\n* Grossmann, &#34;Are current concepts and methods in neuroscience inadequate for studying the neural basis of consciousness and mental activity?&#34; (1980)\n* Baars, A Cognitive Theory of Consciousness (1988)\n* Baars, &#34;Surprisingly small subcortical structures are needed for the state of waking consciousness, while cortical projection areas seem to provide perceptual contents of consciousness,&#34; (1995)\n* Bogen, &#34;On the neurophysiology of consciousness: I. An overview,&#34;(1995a)\n* Searle, &#34;The Mystery of Consciousness&#34;, (2000)\n\n&gt; ³ =&gt;\n\u3000\u3000冥想的技巧就在于排除万念而只集中于一个想法、观念或者知觉。这要经过多年的修炼，才能遏制注意力的不断转换（第9章），把注意力长时间集中在一件事上而又不昏昏入睡。由于神经的适应性无时不在，对单件事的觉知会逐渐消退，使得脑中一片空白，主观上没有任何意识内容，但人还是清醒的。\n\n---&#39;, metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;})</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">get_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Document(page_content=&#39;&gt; 我们刚刚知道自然科学借以掌握质的方法––形成量的概念的方法。我们必须提出的问题是，这种方法是不是也能够适用于主观的意识的质。按照我们前面所说，为了使这种方法能够加以运用，必须有与这些质充分确定地、唯一地联系着的空间变化。如果情况真的如此，那么这个问题就可以通过空间–时间的重合方法来解决，因而**测量**便是可能的。但是，这种重合的方法本质上就是进行物理的观察，而就内省法来说，却不存在物理的观察这种事情。由此立刻就可以得出结论：心理学沿着内省的途径决不可能达到知识的理想。因此，它必须尽量使用物理的观察方法来达到它的目的。但这是不是可能的呢？是不是有依存于意识的质的空间变化，就像例如在光学中干涉带的宽度依存于颜色，在电学中磁铁的偏转度依存于磁场的强度那样呢？\n&gt; 现在我们知道，事实上应当承认在主观的质和推断出来的客观世界之间有一种确切规定的、一义的配列关系。大量的经验材料告诉我们，我们可以发现，至少必须假设与所有经验唯一地联系着的“物理的”过程的存在。没有什么意识的质不可能受到作用于身体的力的影响。的确，我们甚至能够用一种简单的物理方法，例如吸进一种气体，就把意识全部消除掉。我们的行动与我们的意志经验相联系，幻觉与身体的疲惫相联系，抑郁症的发作与消化的紊乱相联系。为了研究这类相互联系，心的理论必须抛弃纯粹内省的方法而成为**生理的**心理学。只有这个学科才能在理论上达到对心理的东西的完全的知识。借助于这样一种心理学，我们就可以用概念和所与的主观的质相配列，正如我们能够用概念与推论出来的客观的质相配列一样。这样，主观的质就像客观的质一样成为可知的了。\n&gt; 我们很早就指出，客观世界中最直接地与自我的主观的质相联系的部分就是由大脑的概念，特别是大脑皮层的概念所表示的那一部分。因而在科学知识的精确的世界图景中，可用数值描述的概念代替的主观质的，只是某些大脑过程。相互依存的分析不可避免要引向这些大脑过程。虽然我们还远没有确切地知道所涉及的是何种个别的过程，但至少指出了一条途径：必须以大脑过程来代替主观的质。这就是我们能够充分认识主观的质所具有的唯一的希望。\n&gt; ……&#39;, metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;})</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">get_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)[</span><span class="mi">3</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Document(page_content=&#39;&gt; ……\n&gt; ……诚然，可以按照某种任意的尺度使一些数与心理的量值相配列。但是这些量值并没有就归结为某种别的东西，因而彼此仍然是互不联系的。所以，我们不能说就知道了某种东西的性质或本质。这种情况与我们上面谈到的物理学上的例子完全相同。如果我们对“温度”本身的测量仅仅依据任意的标尺来对数进行配列，那么我们仍然没有知道“温度”的性质。但是热力学理论引入分子的平均运动能量来代替温度，同时也就为排除任何任意因素的量的处理方法提供了自然的原则。只有当量的关系不是单纯地反映一种任意的约定，而是从事物的本性中产生并且从事物本性中觉察到的时候，这种关系才真的是代表了一种**本质**的知识。正像温度在这里归结为力学的规定性，同样，意识的材料如果要真正地被认知，一般也必须依据自然的原则归结为物理的规定性。就温度的情况来说（也就是热的客观的质），只有通过物质的分子结构的假设才可能把它归结为力学的规定；同样，对主观的心理的质的知识需要有深入研究大脑过程本质的生理学假设。遗憾的是，这种研究的现状还不容许我们以实现心理学最终目标所需要的精确性来构述这种假设。\nーー《普通认识论》（Ｍ．石里克），31&#39;, metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;})</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.faiss</span> <span class="kn">import</span> <span class="n">FAISS</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ingest_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">get_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
    <span class="c1"># (3) Create embeddings for each document (using text-embedding-ada-002).</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/ggml-model-q4_1.bin&#39;</span><span class="p">),</span> <span class="n">n_ctx</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">ingest_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 2048
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 3216.00 MB per state)
llama_init_from_file: kv self size  = 3200.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1234747.80 ms /   607 tokens ( 2034.18 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1234897.68 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1014295.96 ms /   384 tokens ( 2641.40 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1014467.79 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 3282788.17 ms /  1245 tokens ( 2636.78 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 3283401.24 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1918145.27 ms /   648 tokens ( 2960.10 ms per token)
llama_print_timings:        eval time = 20809.58 ms /     1 runs   (20809.58 ms per run)
llama_print_timings:       total time = 1939184.53 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 96082.05 ms /    30 tokens ( 3202.73 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 96150.74 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 507646.90 ms /   208 tokens ( 2440.61 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 507789.71 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 276020.03 ms /   115 tokens ( 2400.17 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 276108.72 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2019785.65 ms /   672 tokens ( 3005.63 ms per token)
llama_print_timings:        eval time = 21867.42 ms /     1 runs   (21867.42 ms per run)
llama_print_timings:       total time = 2041848.65 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 3602106.63 ms /  1131 tokens ( 3184.89 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 3602439.90 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 3230592.03 ms /  1040 tokens ( 3106.34 ms per token)
llama_print_timings:        eval time = 22766.44 ms /     1 runs   (22766.44 ms per run)
llama_print_timings:       total time = 3253751.32 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2692559.48 ms /  1530 tokens ( 1759.84 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2692893.27 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2117241.21 ms /  1428 tokens ( 1482.66 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2117414.25 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1295672.21 ms /  1255 tokens ( 1032.41 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1295802.91 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2584795.09 ms /  1406 tokens ( 1838.40 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2585014.00 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2833173.90 ms /  1514 tokens ( 1871.32 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2833446.52 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2497129.27 ms /  1459 tokens ( 1711.53 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2497330.28 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2323893.79 ms /  1448 tokens ( 1604.90 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2324101.06 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 424718.68 ms /   549 tokens (  773.62 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 424798.69 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2024465.75 ms /  1456 tokens ( 1390.43 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2024680.15 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 203939.74 ms /   407 tokens (  501.08 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 204026.72 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2015409.22 ms /  1524 tokens ( 1322.45 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2015592.15 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 147731.28 ms /   397 tokens (  372.12 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 147780.64 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 477176.94 ms /  1092 tokens (  436.98 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 477262.18 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 900018.45 ms /  1332 tokens (  675.69 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 900122.17 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 133290.49 ms /   490 tokens (  272.02 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 133351.61 ms

llama_print_timings:        load time = 12248.83 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 13613.44 ms /    53 tokens (  256.86 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 13634.46 ms
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Save vectorstore</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vectorstore_13B_2048.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vectorstore</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load vectorstore</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vectorstore_13B_2048.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 2048
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 3216.00 MB per state)
llama_init_from_file: kv self size  = 3200.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;你知道什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get context related to the question from the embedding model</span>
<span class="k">for</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>page_content=&#39;title: Neuroscience\ndate: 2021-10-14 16:30:20\ntags: Neuro\n---\n\nThe [**ventral tegmental area**](https://en.wikipedia.org/wiki/Ventral_tegmental_area) (**VTA**) (**tegmentum** is Latin for covering), also known as the **ventral tegmental area of Tsai**, or simply **ventral tegmentum**, is a group of neurons located close to the midline on the floor of the midbrain.\n\n---\n\n&gt; \u3000\u3000有些权威认为，有必要把意识的内容 (content) 与“有意识状态的特性” (quality of being conscious) 或“意识本身” (consciousness as such) 区分开来²。这一划分与我的分类异曲同工。\n\u3000\u3000要想产生意识，必须先具备某些神经前提条件。我把这些条件称为 NCC_e。任一特定知觉的 NCC 都是局部作用的、高度特化的、转瞬即逝的，相比起来，NCC_e 的作用方式更全局化也更持久。要是没有相关的 NCC_e 的话，机体或许也还能有简单的行为，但在这样做时绝不会有意识（可能发生这种情形的某些病理条件将在第13章讨论）。根据定义可知，如果没有 NCC_e，就不可能形成任何 NCC。\n\u3000\u3000会不会有这样一种状态，即生物体虽然有意识，却意识不到任何具体内容？换句话说，NCC_e 能否脱离 NCC 而单独存在呢？某些冥想的目标就是要进入这种没有具体内容的意识形式³。但是在目前，还很难对它进行严格的分析。&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

page_content=&#39;有意注意，是指，对于某次效果的注意。\n无意注意，是指，对于某次非效果的注意。\n\n目标，是指，对于某种效果的某些次记忆所联结着的对于此种效果的拟构。\n意向，是指，对于某些种效果的某些次记忆所联结着的对于某种效果的拟构。\n\n懊悔，是指，对于某次弊害效果的某次记忆、对于某次功效的某次记忆所联结着的对于某次功效的拟构。\n焦虑，是指，对于某次弊害效果的某次记忆、对于某次功效的某次意向所联结着的对于某次弊害效果的拟构。\n\n对于某次功效的目标，联结着，对于此次功效的原因。\n对于某种功效的概括，联结着，对于此种功效的原因。\n\n兴趣，是指，联结着某次快乐的识。\n荒诞，是指，联结着某次乏味的识。\n苦毒，是指，联结着某次痛苦的识。\n\n慾望，是指，对于某次兴趣的表征。\n妄想，是指，对于某次荒诞的表征。？\n苦观，是指，对于某次苦毒的表征。\n\n苦观，分为，记忆苦观、拟构苦观。弊害，…、…\n\n有趣注意，是指，对于某次兴趣的注意。\n无趣注意，是指，对于某次荒诞的注意。\n\n意义，是指，值得的注意。\n神圣，是指，极其丰富的意义。\n积极的态度，是指，充满对于某种意义的信心。\n消极的态度，是指，缺乏对于某种意义的信心。\n积极的注意，导致着，快乐。\n消极的注意，导致着，乏味。\n对于某种意义的怀疑，是指，对于某种意义的信心的减弱。\n对于某种意义的确定，是指，对于某种意义的信心的增强。\n对于某种意义的静思，是指，对于某种意义的减弱。对于某种意义的静思，导致着，忧郁。\n对于某种意义的禅修，是指，对于某种意义的增强。对于某种意义的禅修，导致着，幸福。\n静思、禅修、祷告，都是，某种定觉练习。\n\n---\n\n&gt; 因为我们得了救是因着盼望。只是所盼望的若已得看见，便不是盼望了；因为人所看见的、他何必还盼望呢？但我们若盼望所未看见的，就必坚忍切候着。\n(罗马书 8:24-25 吕振中)\n\n&gt; 所以青春性的私欲、你总要逃避；你要跟那些用洁净心呼求主的人一同追求正义、忠信、仁爱、和平。\n(提摩太后书 2:22 吕振中)\n\n向内往最深处去：净心、呼求主名、并且、等待回应。&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/终极真实.md&#39;}

page_content=&#39;&gt; 我们刚刚知道自然科学借以掌握质的方法––形成量的概念的方法。我们必须提出的问题是，这种方法是不是也能够适用于主观的意识的质。按照我们前面所说，为了使这种方法能够加以运用，必须有与这些质充分确定地、唯一地联系着的空间变化。如果情况真的如此，那么这个问题就可以通过空间–时间的重合方法来解决，因而**测量**便是可能的。但是，这种重合的方法本质上就是进行物理的观察，而就内省法来说，却不存在物理的观察这种事情。由此立刻就可以得出结论：心理学沿着内省的途径决不可能达到知识的理想。因此，它必须尽量使用物理的观察方法来达到它的目的。但这是不是可能的呢？是不是有依存于意识的质的空间变化，就像例如在光学中干涉带的宽度依存于颜色，在电学中磁铁的偏转度依存于磁场的强度那样呢？\n&gt; 现在我们知道，事实上应当承认在主观的质和推断出来的客观世界之间有一种确切规定的、一义的配列关系。大量的经验材料告诉我们，我们可以发现，至少必须假设与所有经验唯一地联系着的“物理的”过程的存在。没有什么意识的质不可能受到作用于身体的力的影响。的确，我们甚至能够用一种简单的物理方法，例如吸进一种气体，就把意识全部消除掉。我们的行动与我们的意志经验相联系，幻觉与身体的疲惫相联系，抑郁症的发作与消化的紊乱相联系。为了研究这类相互联系，心的理论必须抛弃纯粹内省的方法而成为**生理的**心理学。只有这个学科才能在理论上达到对心理的东西的完全的知识。借助于这样一种心理学，我们就可以用概念和所与的主观的质相配列，正如我们能够用概念与推论出来的客观的质相配列一样。这样，主观的质就像客观的质一样成为可知的了。\n&gt; 我们很早就指出，客观世界中最直接地与自我的主观的质相联系的部分就是由大脑的概念，特别是大脑皮层的概念所表示的那一部分。因而在科学知识的精确的世界图景中，可用数值描述的概念代替的主观质的，只是某些大脑过程。相互依存的分析不可避免要引向这些大脑过程。虽然我们还远没有确切地知道所涉及的是何种个别的过程，但至少指出了一条途径：必须以大脑过程来代替主观的质。这就是我们能够充分认识主观的质所具有的唯一的希望。\n&gt; ……&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

page_content=&#39;客体方式，导致着、联结着，主体方式、机体状态\n形体，导致着、联结着，身体、快乐、痛苦\n轻蔑、轻视他人对自己的态度，损害着，羞耻心\n羞耻，对于亲密程度的重视；我们在争辩的时候，真正损害着羞耻心的，实际上是，轻视他人对自己的态度，而不是，轻视他人的（由父所创造的）信念？\n羞耻、光荣，重视他人对自己的态度、敬重\n恥辱、傲慢，轻视他人对自己的态度、轻蔑\n羞耻、羞辱，在含义上，有所不同吗？\n单方的轻视、双方的轻视？\n一方，是，非吾所显明出来的罪；一方，是，吾所显明出来的罪。\n狭隘、愚蠢、固执，轻视他人的信念\n开明、智慧、变通，重视他人的信念&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/终极真实.md&#39;}

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time =  6111.23 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time =  6109.85 ms /     8 tokens (  763.73 ms per token)
llama_print_timings:        eval time = 10089.46 ms /     1 runs   (10089.46 ms per run)
llama_print_timings:       total time = 16205.01 ms
</pre>
</div>
</div>

</div>
</div>

</div>
 




<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Open-Text-Embeddings">Open Text Embeddings<a class="anchor-link" href="#Open-Text-Embeddings">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="LangChain-Embeddings"><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/reference/modules/embeddings.html">LangChain Embeddings</a><a class="anchor-link" href="#LangChain-Embeddings">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Hugging-Face-Embeddings">Hugging Face Embeddings<a class="anchor-link" href="#Hugging-Face-Embeddings">&#182;</a></h4><ul>
<li><a target="_blank" rel="noopener" href="https://www.sbert.net/docs/pretrained_models.html">https://www.sbert.net/docs/pretrained_models.html</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/UKPLab/sentence-transformers">https://github.com/UKPLab/sentence-transformers</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained_models.md">https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained_models.md</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>sentence-transformers
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully installed nltk-3.8.1 scikit-learn-1.2.2 scipy-1.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 threadpoolctl-3.1.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">HuggingFaceEmbeddings</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">HuggingFaceEmbeddings</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Help on function __init__ in module langchain.embeddings.huggingface:

__init__(self, **kwargs: Any)
    Initialize the sentence_transformer.

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">HuggingFaceEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;sentence-transformers/all-mpnet-base-v2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">()</span>

<span class="c1"># 准备文本</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;这是一个测试文档。&#39;</span>

<span class="c1"># 使用 HuggingFaceEmbeddings 生成文本嵌入</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">hf_embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">doc_result</span> <span class="o">=</span> <span class="n">hf_embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">query_result</span><span class="p">))</span>
<span class="c1"># print(query_result)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># print(doc_result)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>768
1
768
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_embeddings</span><span class="o">.</span><span class="n">model_name</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;sentence-transformers/all-mpnet-base-v2&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 857056
drwxr-xr-x  16 saintway  staff   512B Apr 12 14:31 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   5 saintway  staff   160B Apr 19 17:23 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.1K Apr 12 14:28 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 12 14:28 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
-rw-r--r--   1 saintway  staff    10K Apr 12 14:28 README.md
-rw-r--r--   1 saintway  staff   571B Apr 12 14:28 config.json
-rw-r--r--   1 saintway  staff   116B Apr 12 14:28 config_sentence_transformers.json
-rw-r--r--   1 saintway  staff    38K Apr 12 14:28 data_config.json
-rw-r--r--   1 saintway  staff   349B Apr 12 14:31 modules.json
-rw-r--r--   1 saintway  staff   418M Apr 12 14:31 pytorch_model.bin
-rw-r--r--   1 saintway  staff    53B Apr 12 14:31 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   239B Apr 12 14:31 special_tokens_map.json
-rw-r--r--   1 saintway  staff   455K Apr 12 14:31 tokenizer.json
-rw-r--r--   1 saintway  staff   363B Apr 12 14:31 tokenizer_config.json
-rw-r--r--   1 saintway  staff    13K Apr 12 14:31 train_script.py
-rw-r--r--   1 saintway  staff   226K Apr 12 14:31 vocab.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>418M	/Users/saintway/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v2
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Hugging-Face-Instruct-Embeddings"><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/calmgoose/book-embeddings">Hugging Face Instruct Embeddings</a><a class="anchor-link" href="#Hugging-Face-Instruct-Embeddings">&#182;</a></h4><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/UKPLab/sentence-transformers">https://github.com/UKPLab/sentence-transformers</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/HKUNLP/instructor-embedding">https://github.com/HKUNLP/instructor-embedding</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>InstructorEmbedding
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully installed InstructorEmbedding-1.0.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/basujindal/chatPDF">https://github.com/basujindal/chatPDF</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceInstructEmbeddings</span>
<span class="n">hfi_embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceInstructEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;hkunlp/instructor-large&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>load INSTRUCTOR_Transformer
max_seq_length  512
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hfi_embeddings</span><span class="o">.</span><span class="n">model_name</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;hkunlp/instructor-large&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/torch/sentence_transformers/hkunlp_instructor-large
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total 2623328
drwxr-xr-x  15 saintway  staff   480B Apr 12 15:19 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x   5 saintway  staff   160B Apr 19 17:23 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
-rw-r--r--   1 saintway  staff   1.4K Apr 12 15:07 .gitattributes
drwxr-xr-x   3 saintway  staff    96B Apr 12 15:07 <span class="ansi-cyan-intense-fg ansi-bold">1_Pooling</span>
drwxr-xr-x   4 saintway  staff   128B Apr 12 15:08 <span class="ansi-cyan-intense-fg ansi-bold">2_Dense</span>
-rw-r--r--   1 saintway  staff    65K Apr 12 15:08 README.md
-rw-r--r--   1 saintway  staff   1.5K Apr 12 15:08 config.json
-rw-r--r--   1 saintway  staff   122B Apr 12 15:08 config_sentence_transformers.json
-rw-r--r--   1 saintway  staff   461B Apr 12 15:19 modules.json
-rw-r--r--   1 saintway  staff   1.2G Apr 12 15:19 pytorch_model.bin
-rw-r--r--   1 saintway  staff    53B Apr 12 15:19 sentence_bert_config.json
-rw-r--r--   1 saintway  staff   2.1K Apr 12 15:19 special_tokens_map.json
-rw-r--r--   1 saintway  staff   773K Apr 12 15:19 spiece.model
-rw-r--r--   1 saintway  staff   2.3M Apr 12 15:19 tokenizer.json
-rw-r--r--   1 saintway  staff   2.4K Apr 12 15:19 tokenizer_config.json
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/torch/sentence_transformers/hkunlp_instructor-large
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.3G	/Users/saintway/.cache/torch/sentence_transformers/hkunlp_instructor-large
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 准备文本</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;这是一个测试文档。&#39;</span>

<span class="c1"># 使用 HuggingFaceInstructEmbeddings 生成文本嵌入</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">hfi_embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">doc_result</span> <span class="o">=</span> <span class="n">hfi_embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">query_result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">query_result</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">doc_result</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>768
[-0.022137142717838287, -0.019943105056881905, 0.009940845891833305, 0.029961414635181427, 0.0015559268649667501, -0.0010082109365612268, 0.004636477679014206, 0.006970031186938286, -0.039788346737623215, 0.028241422027349472, -1.5192752471193671e-05, -0.008512390777468681, 0.04590446129441261, 0.03056621551513672, -0.030894720926880836, -0.02884022891521454, -0.023664429783821106, -0.010090871714055538, -0.036661747843027115, -0.001970992423593998, 0.05847157910466194, 0.008038687519729137, -0.012776742689311504, 0.05411699786782265, 0.01262636948376894, 0.016430772840976715, -0.04767526313662529, 0.01811787858605385, 0.04832480102777481, -0.0647105798125267, 0.03377210721373558, -0.04854683578014374, -0.040563128888607025, -0.04772289842367172, -0.018774421885609627, 0.020985594019293785, 0.025719504803419113, 0.027344582602381706, 0.026014933362603188, 0.055159278213977814, -0.01577085256576538, 0.01060266699641943, -0.0031603227835148573, -0.039208076894283295, 0.03614024817943573, 0.009471523575484753, -0.025426877662539482, -0.04541698843240738, 0.026563631370663643, -0.03881140425801277, -0.03588118404150009, -0.057559046894311905, -0.007960007525980473, 0.012319786474108696, -0.0029835468158125877, -0.029109695926308632, -0.06043725088238716, 0.03710782155394554, 0.08494839072227478, -0.054077211767435074, -0.03525502607226372, -0.0031806030310690403, -0.09065768867731094, 0.023320553824305534, 0.02501724287867546, -0.05140731483697891, 0.048127785325050354, -0.05498746410012245, 0.029325366020202637, -0.04640709608793259, 0.01205480471253395, -0.047244541347026825, 0.00035423680674284697, -0.09959323704242706, -0.027633335441350937, 0.001402342109940946, 0.02929595485329628, 0.046018004417419434, -0.05788029357790947, 0.042901281267404556, 0.03905021399259567, 0.0020306624937802553, 0.048880625516176224, -0.0019414519192650914, -0.033322807401418686, 0.028527161106467247, -0.005001544952392578, 0.019440239295363426, 0.0041367351077497005, 0.041833482682704926, -0.03431558609008789, -0.0706053078174591, -0.01964596100151539, 0.00529050687327981, -0.004017329774796963, 0.020387377589941025, 0.0496586374938488, 0.006946606561541557, 0.03991807624697685, 0.037570007145404816, 0.03404153883457184, 0.05588211491703987, -0.02905808761715889, 0.03623465821146965, -0.013191419653594494, 0.009090606123209, -0.020825188606977463, -0.02675699256360531, -0.04974988102912903, -0.0004641334235202521, -0.016248611733317375, -0.055453505367040634, -0.014421780593693256, 0.038791216909885406, -0.003007616614922881, -0.05522274225950241, 0.06346995383501053, -0.054133057594299316, -0.06531116366386414, -0.02393488958477974, 0.027049822732806206, 0.021163685247302055, -0.045149073004722595, -0.005699407774955034, -0.0549631305038929, 0.019174829125404358, -0.020559104159474373, 0.0040987106040120125, -0.01622997410595417, 0.003300424898043275, -0.010149079374969006, 0.021996449679136276, 0.041733454912900925, -0.09496010094881058, 0.021827906370162964, 0.014840630814433098, -0.04588484764099121, 0.02394992485642433, 0.016791993752121925, 0.08624919503927231, -0.06361847370862961, -0.03944281488656998, -0.04442731291055679, 0.007785744499415159, -0.023762937635183334, -0.0110867815092206, 0.01138637587428093, -0.05897051468491554, -0.04304634779691696, -0.0173543319106102, 0.06624708324670792, -0.0437123104929924, 0.004276968538761139, 0.07888749241828918, -0.0071301888674497604, 0.024873679503798485, -0.018245670944452286, 0.004486299119889736, 0.00582241453230381, 0.02243458852171898, -0.030916478484869003, 0.049587175250053406, -0.010419673286378384, -0.022187191992998123, -0.0791892409324646, -0.02702951990067959, -0.0035843446385115385, 0.05750065669417381, -0.018682042136788368, -0.030490878969430923, -0.08072890341281891, 0.024044500663876534, 0.05379054695367813, 0.01158835832029581, -0.02660636231303215, 0.03985058143734932, 0.03334967792034149, 0.030472831800580025, -0.02080536261200905, 0.04899463802576065, 0.010174624621868134, -0.015453080646693707, -0.029648398980498314, 0.04518602415919304, 0.0644007995724678, -0.015453620813786983, 0.012724599801003933, 0.02410477213561535, 0.021669277921319008, -0.047304801642894745, -0.0030988911166787148, 0.06250063329935074, -0.037959348410367966, -0.016027355566620827, 0.03403116390109062, -0.0007538921781815588, -0.04373054951429367, 0.024864956736564636, -0.017527837306261063, -0.004101598169654608, -0.0481080487370491, 0.010937296785414219, 0.02215939201414585, 0.042132746428251266, -0.005298169795423746, 0.05001835525035858, -0.03381647542119026, 0.07707470655441284, -0.01247261743992567, 0.015081333927810192, -0.04821961373090744, -0.05602756887674332, 0.002172428648918867, 0.03414832800626755, 0.05385158583521843, 0.03951353579759598, -0.03862477093935013, -0.06857028603553772, 0.05580616369843483, 0.047364167869091034, 0.04966306313872337, 0.00995559711009264, -0.033690739423036575, 0.011581477709114552, 0.035535167902708054, 0.03085923381149769, -0.04816819354891777, -0.03495897352695465, 0.006372313015162945, 0.05013415589928627, -0.029227256774902344, 0.0053755310364067554, -0.019459571689367294, 0.024346565827727318, -0.034451521933078766, -0.0677531510591507, 0.03487487509846687, 0.04172320291399956, 0.010180668905377388, 0.016491739079356194, -0.01668640412390232, 0.03754301741719246, 0.023817863315343857, 0.021770311519503593, 0.02320024184882641, -0.03048897720873356, 0.023136703297495842, -0.019154028967022896, 0.06983145326375961, -0.013741375878453255, 0.03929886966943741, 0.012652753852307796, 0.015791112557053566, 0.007288077380508184, -0.04030032828450203, 0.020244285464286804, 0.0701761543750763, 0.014144702814519405, -0.0366959422826767, 0.034101251512765884, 0.027012642472982407, 0.04800959303975105, 0.07189490646123886, 0.00042301067151129246, 0.04226808249950409, -0.007224685046821833, 0.03213008865714073, 0.03385363519191742, 0.009528609924018383, 0.013251561671495438, 0.025025293231010437, 0.08515191823244095, -0.004974443931132555, -0.01735675148665905, 0.0720532163977623, -0.03935912624001503, 0.004844623617827892, -0.04394184425473213, 0.011392495594918728, -0.03961816802620888, -0.021686410531401634, 0.0632035881280899, -2.6600875571602955e-05, -0.018001483753323555, 0.0002045980654656887, -0.014556610025465488, 0.009118364192545414, 0.025560518726706505, -0.007447301875799894, 0.019972093403339386, -0.015712067484855652, -0.024550966918468475, 0.023652231320738792, -0.0584896020591259, -0.01404705923050642, -0.017441358417272568, -0.040668584406375885, 0.03344985097646713, -0.06545151770114899, -0.0015352212358266115, -0.059208810329437256, -0.034206390380859375, 0.031709667295217514, 0.031845979392528534, 0.017346983775496483, -0.0192494485527277, 0.04217034950852394, -0.04041285440325737, -0.05436360463500023, -0.03852096572518349, -0.04090946912765503, -0.044468097388744354, -0.05580539256334305, 0.04195259511470795, 0.04524538293480873, -0.001072112238034606, 0.05045463517308235, -0.007403041701763868, -0.011037559248507023, -0.0481581874191761, 0.05748680979013443, 0.021998926997184753, -0.0114741837605834, -0.023216141387820244, 0.02764948643743992, 0.0033738191705197096, -0.015397194772958755, -0.04408087953925133, -0.025693349540233612, 0.08350582420825958, 0.08186513930559158, 0.02589094638824463, 0.031298864632844925, 0.022997794672846794, -0.0705040693283081, -0.017929619178175926, -0.0386652797460556, -0.021253539249300957, -0.011709196493029594, -0.04891839995980263, -0.034260012209415436, -0.010942338034510612, -0.019566839560866356, -0.011726225726306438, -0.0073863305151462555, -0.021809587255120277, 0.031185846775770187, 0.036898598074913025, 0.03579287230968475, 0.03630955517292023, -0.008991124108433723, -0.009002245031297207, 0.08667944371700287, 0.0010887794196605682, -0.032698702067136765, -0.06335387378931046, -0.048804596066474915, 0.02329985983669758, 0.005369881168007851, 0.018586451187729836, -0.051516350358724594, 0.04263807460665703, -0.0006810427876189351, -0.001103260088711977, 0.02041923999786377, -0.02518085390329361, 0.007012072950601578, 0.0016074466984719038, 0.010585247538983822, -0.01600584201514721, -0.06097882241010666, 0.006132303737103939, -0.02095993608236313, 0.03893598914146423, -0.05109530687332153, -0.01899784617125988, -0.011300088837742805, 0.009710361249744892, 0.011983739212155342, -0.013006223365664482, -0.04143975302577019, 0.010285450145602226, -0.06305649876594543, -0.03500263765454292, -0.016994699835777283, 0.019823139533400536, 0.010417548008263111, 0.08123686909675598, 0.028307151049375534, -0.00701523432508111, 0.03513439744710922, 0.002012860495597124, 0.05926254391670227, 0.041931524872779846, -0.014769182540476322, 0.03460005670785904, -0.019610265269875526, 0.027883131057024002, 0.013702291995286942, -0.016595499590039253, -0.03288355842232704, -0.06714218854904175, -0.051795538514852524, 0.032413337379693985, -0.013448472134768963, -0.002694027731195092, 0.04136023297905922, -0.059142980724573135, -0.01380129437893629, -0.0022579259239137173, 0.0219892431050539, 0.021225525066256523, -0.04053009673953056, 0.03726652264595032, -0.021588211879134178, 0.02056734822690487, -0.02374904789030552, 0.003405689960345626, -0.03571395203471184, -0.030117657035589218, 0.006589301861822605, 0.04827360436320305, 0.011746781878173351, 0.047028761357069016, 0.07872718572616577, 0.00854527484625578, -0.031543463468551636, 0.046509627252817154, 0.05302605777978897, 0.02241320163011551, -0.05144788697361946, 0.00531784538179636, -0.008528214879333973, -0.010467768646776676, -0.017910946160554886, -0.0448242723941803, 0.003639540169388056, 0.055717598646879196, -0.005372322164475918, -0.01859535463154316, 1.9491570128593594e-05, -0.017520388588309288, -0.02086714655160904, -0.06756243854761124, 0.016911156475543976, 0.020075716078281403, -0.028387082740664482, -0.014232601039111614, 0.06091458722949028, 0.015551713295280933, 0.05874437093734741, 0.011747990734875202, -0.039615631103515625, -0.04280305281281471, 0.029752986505627632, 0.009051498025655746, -0.062423039227724075, -0.03705782815814018, -0.040770962834358215, 0.030891701579093933, 0.030155127868056297, -0.007816113531589508, -0.0807504653930664, 0.017831768840551376, 0.05006144940853119, -0.05361318588256836, 0.062341079115867615, 0.025491494685411453, 0.048408396542072296, 0.029084276407957077, -0.015447879210114479, -0.00034940679324790835, -0.017930610105395317, -0.006148740649223328, -0.009926981292665005, 0.0582754872739315, -0.015238925814628601, -0.03550595045089722, -0.03390232101082802, 0.03024483472108841, 0.006002285983413458, 0.03796408697962761, 0.019458049908280373, -0.031131630763411522, -0.04120856150984764, 0.010978765785694122, 0.0333918035030365, -0.04785642772912979, 0.022198036313056946, 0.04413451626896858, 0.019193124026060104, -0.03626841679215431, -0.031137170270085335, -0.002764541655778885, 0.007364119868725538, 0.06619369983673096, -0.028123170137405396, -0.035441718995571136, -0.042127810418605804, 0.01750461757183075, 0.008765813894569874, -0.046932898461818695, -0.09832718968391418, 0.028079211711883545, -0.001491512986831367, -0.03492061793804169, 0.05971066281199455, 0.02804477885365486, 0.024293120950460434, 0.08744291216135025, -0.008789492771029472, 0.01302084419876337, -0.020782649517059326, 0.04509878158569336, -0.029434096068143845, -0.03194120153784752, 0.01338726095855236, -0.05421733483672142, -0.02326781488955021, -0.041257284581661224, -0.04912155494093895, -0.031217290088534355, 0.006082997191697359, 0.033354438841342926, -0.0216062068939209, 0.010425982065498829, 0.01690390706062317, 0.01642853394150734, 0.0015028663910925388, -0.05256250873208046, -0.008604401722550392, -0.04340226203203201, -0.06464898586273193, -0.04076193645596504, 0.03596508502960205, -0.01954132877290249, 0.02018481120467186, 0.011362768709659576, 0.02293892204761505, 0.015474352054297924, -0.011335867457091808, -0.02486458234488964, 0.026126177981495857, 0.02133898064494133, -0.04850659891963005, -0.045282673090696335, -0.030667219310998917, 0.008212651126086712, 0.01518244668841362, -0.04165206849575043, 0.03790992125868797, 0.02218039147555828, -0.01681869477033615, -0.02027173899114132, 0.009450569748878479, 0.015175608918070793, -0.04803943634033203, -0.06358246505260468, -0.013711309060454369, 0.009996723383665085, 0.040636055171489716, -0.042011044919490814, -0.011027892120182514, 0.02691529504954815, 0.057163577526807785, 0.03753253072500229, 0.022043783217668533, -0.0021431820932775736, 0.04917208105325699, -0.04179786145687103, -0.005483817774802446, -0.08106370270252228, 0.024761244654655457, -0.016964280977845192, 0.03641534224152565, -0.010911267250776291, -0.0011809802381321788, -0.05593414604663849, 0.04463743418455124, -0.04375195503234863, -0.037942975759506226, -0.003339756280183792, 0.014220676384866238, -0.04019850865006447, 0.053015731275081635, -0.028724318370223045, 0.003802355146035552, -0.037122998386621475, 0.030996421352028847, -0.03507940098643303, -0.0007456461898982525, -0.006219014525413513, -0.0005068734171800315, -0.06874105334281921, -0.027668355032801628, -0.015170485712587833, -0.0672307014465332, 0.0110006770119071, 0.04290778934955597, 0.0037627213168889284, 0.01036884170025587, -0.007260350044816732, -0.014498177915811539, 0.008817058056592941, -0.047402523458004, -0.01808319240808487, -0.05033589527010918, -0.028884392231702805, 0.0035344050265848637, 0.03218654543161392, 0.03320618346333504, -0.05054805800318718, -0.0503070168197155, 0.048324212431907654, 0.045269548892974854, 0.006230846047401428, 0.0028933598659932613, 0.03576548025012016, 0.039641764014959335, 0.04235326126217842, 0.00390684325248003, 0.017620764672756195, -0.05768784508109093, 0.005895737558603287, 0.0004468218539841473, -0.006375355180352926, 0.0018062518211081624, -0.01394017692655325, -0.05188938230276108, -0.018782146275043488, 0.09841680526733398, 0.03368517756462097, 0.02949652634561062, -0.02045777440071106, -0.05439259484410286, 0.04644351080060005, 0.02802385576069355, -0.031084785237908363, 0.018647707998752594, 0.015535857528448105, -0.0347856730222702, 0.07113273441791534, 0.02331412024796009, 0.03137088567018509, 0.045221082866191864, 0.01769883558154106, -0.02390470542013645, 0.02507965639233589, -0.03268289566040039, -0.0027856382075697184, 0.03365938365459442, -0.05175941064953804, 0.006154587958008051, -0.033265549689531326, 0.05281004682183266, -0.0404675267636776, 0.0657331719994545, 0.05071451887488365, 0.0020178519189357758, 0.014635175466537476, -0.03720288723707199, -0.010401709005236626, 0.03344612568616867, -0.010997913777828217, 0.06176922470331192, -0.016880199313163757, -0.07420120388269424, 0.04998021200299263, 0.03931588679552078, -0.07584240287542343, 0.023533020168542862, 0.0006756161455996335, 0.02090786024928093, 0.036075837910175323, 0.03659137338399887, -0.05161881819367409, -0.006765023805201054, -0.005993164610117674, 0.013982019387185574, -0.020381171256303787, -0.029386788606643677, 0.04889058321714401, -0.00013371290697250515, -0.0002964060113299638, 0.027174945920705795, -0.009697571396827698, 0.028293093666434288, 0.0374593585729599, -0.04518287256360054, -0.06050867959856987, -0.00014245744387153536, 0.057110074907541275, 0.030268797650933266, -0.013529627583920956, -0.04629375785589218, -0.012579434551298618, 0.018368467688560486, -0.009889695793390274, -0.01691138558089733, 0.03825466334819794, 0.0271073579788208, -0.1041674092411995, -0.014870252460241318, 0.028485944494605064, 0.0070266807451844215, -0.03262393921613693, 0.024559883400797844, 0.0045441146939992905, 0.012745088897645473, 0.021893462166190147, 0.014667946845293045, 0.001110888086259365, -0.06492006778717041, -0.004571379162371159, 0.02366933599114418, -0.015817731618881226, 0.05720985680818558, -0.0345175638794899, 0.018073854967951775, 0.050241053104400635, 0.03106319159269333, 0.0066062589175999165, -0.0469040647149086, -0.027500491589307785, 0.045247793197631836, -0.02852327562868595, 0.040982939302921295, -0.02894440107047558, -0.04443144053220749, -0.03902950510382652, -0.020365344360470772, -0.026738805696368217, 0.05663229525089264, -0.010026874020695686, 0.01433494221419096, 0.011053822934627533, 0.013605833984911442, -0.0018017073161900043, -0.06102275103330612, -0.03922444209456444, -0.024675380438566208, 0.05290922522544861, 0.021725371479988098, -0.01934276521205902, 0.009532574564218521, -0.03275094926357269, -0.03986525163054466, 0.03821403905749321, -0.009230101481080055, -0.04589630663394928, 0.06575308740139008, 0.02526622824370861, -0.018659353256225586, 0.008876781910657883, 0.03926151990890503, -0.05208025500178337, 0.0474589541554451, 0.0033570746891200542, 0.016553008928894997, 0.03175811842083931, 0.0395858995616436, 0.00479521369561553, -0.028426123782992363, -0.04252200201153755, -0.01386924460530281, -0.013864289969205856, 0.0007772607496008277, 0.07288770377635956]
1
768
[[-0.017321424558758736, -0.0290683601051569, 0.02144867181777954, 0.03564919903874397, 0.007519469130784273, -0.0020619011484086514, 0.01159549318253994, 0.0033334267791360617, -0.030980847775936127, 0.028360769152641296, -0.00923326425254345, -0.015223197638988495, 0.045116547495126724, 0.029102467000484467, -0.034634821116924286, -0.02428201586008072, -0.02622298151254654, -0.012027820572257042, -0.033619582653045654, -0.006393300835043192, 0.04940227046608925, -0.005081124138087034, -0.013001572340726852, 0.04863433539867401, 0.01769079640507698, 0.019589051604270935, -0.05099540203809738, 0.02014349400997162, 0.07345512509346008, -0.056142907589673996, 0.017525048926472664, -0.04323125630617142, -0.03591267392039299, -0.04471318796277046, -0.03387963026762009, 0.02250732108950615, 0.0260605551302433, 0.03198987990617752, 0.015925999730825424, 0.055788323283195496, -0.008521814830601215, 0.003774485783651471, -0.004999945871531963, -0.032853759825229645, 0.03646484762430191, 0.010934969410300255, -0.02773832529783249, -0.040138907730579376, 0.03286226838827133, -0.04289257898926735, -0.04034288600087166, -0.05297926440834999, -0.010307238437235355, 0.01675456389784813, 0.002258037682622671, -0.010667218826711178, -0.05834063142538071, 0.03491596132516861, 0.08479320257902145, -0.06158952787518501, -0.032164279371500015, -0.010000646114349365, -0.08898387849330902, 0.02972586452960968, 0.021418822929263115, -0.054490238428115845, 0.0574653334915638, -0.05757038667798042, 0.03782184422016144, -0.047682881355285645, 0.008862263523042202, -0.05072873830795288, 0.004423295613378286, -0.10649670660495758, -0.037948817014694214, -0.003030016552656889, 0.03342246636748314, 0.043445296585559845, -0.05618777126073837, 0.056365132331848145, 0.037387412041425705, 0.002760133007541299, 0.04104584828019142, -0.002229600679129362, -0.030764112249016762, 0.032726626843214035, -0.008634235709905624, 0.02173653617501259, 0.0011450621532276273, 0.04624494910240173, -0.03307458013296127, -0.07201699912548065, -0.016203274950385094, 0.0036587673239409924, -0.012880930677056313, 0.019049828872084618, 0.04802519455552101, 0.012124101631343365, 0.04760000854730606, 0.050861284136772156, 0.038192279636859894, 0.061423029750585556, -0.017844833433628082, 0.026627566665410995, -0.0229574516415596, 0.006922928616404533, -0.03528516739606857, -0.0240724328905344, -0.040312256664037704, -0.0032211754005402327, -0.012484926730394363, -0.0663076713681221, -0.007122499402612448, 0.037984441965818405, 0.0038152653723955154, -0.06272412836551666, 0.0509425513446331, -0.056290652602910995, -0.058687008917331696, -0.010993730276823044, 0.0430663600564003, 0.02154427394270897, -0.041093580424785614, -0.014876669272780418, -0.060619112104177475, 0.024312550202012062, -0.024698927998542786, 0.008390418253839016, -0.019487500190734863, 0.007395193446427584, -0.01375834085047245, 0.011960526928305626, 0.031002424657344818, -0.08624697476625443, 0.024247542023658752, 0.006527060177177191, -0.03665762394666672, 0.02803284116089344, 0.006271459627896547, 0.07319948822259903, -0.05682418495416641, -0.04574257507920265, -0.03672082722187042, 0.015206302516162395, -0.02461088076233864, -0.01586904563009739, 0.013223697431385517, -0.054297711700201035, -0.04598791524767876, -0.006337896920740604, 0.06237014755606651, -0.03651244938373566, 0.01589328609406948, 0.07579127699136734, -0.013197096064686775, 0.026848727837204933, -0.01778201386332512, 0.002971116453409195, 0.008328345604240894, 0.025022976100444794, -0.024580515921115875, 0.034560929983854294, 0.0050260028801858425, -0.02787385880947113, -0.08644828200340271, -0.03169411048293114, 0.005510836839675903, 0.04482191801071167, -0.023682281374931335, -0.0391206219792366, -0.06080467253923416, 0.027954647317528725, 0.03046696074306965, 0.015648001804947853, -0.017990151420235634, 0.04091879352927208, 0.03362458944320679, 0.037195030599832535, -0.0177246555685997, 0.054683029651641846, 0.02061222307384014, -0.025283208116889, -0.028483398258686066, 0.03470484912395477, 0.05267150327563286, -0.010124912485480309, 0.021229730919003487, 0.023600108921527863, 0.014927630312740803, -0.04385334625840187, 0.009330634027719498, 0.06787162274122238, -0.04097283259034157, -0.009420155547559261, 0.036641813814640045, -0.010596320964396, -0.03766893595457077, 0.03683076798915863, -0.028229041025042534, -0.008987233974039555, -0.05227290093898773, 0.03991328924894333, 0.020183095708489418, 0.050611864775419235, -0.004223272204399109, 0.04868282377719879, -0.03727664053440094, 0.07120431214570999, -0.005240161437541246, 0.027111586183309555, -0.05283592268824577, -0.061826545745134354, 0.015926817432045937, 0.02243269421160221, 0.05361457169055939, 0.03672531619668007, -0.027527185156941414, -0.07340686023235321, 0.04527905583381653, 0.04849943891167641, 0.04911305755376816, 0.00674306508153677, -0.04111838340759277, 0.007636277470737696, 0.027770960703492165, 0.03094053640961647, -0.055380359292030334, -0.032657623291015625, 0.018110627308487892, 0.055499594658613205, -0.023379191756248474, 0.006783255375921726, -0.022936547175049782, 0.019551491364836693, -0.03582318127155304, -0.06713026762008667, 0.027420353144407272, 0.03327900543808937, 0.005401282571256161, 0.0005863559781573713, -0.018303031101822853, 0.026252977550029755, 0.02077643573284149, 0.02444145828485489, 0.030188167467713356, -0.03149719163775444, 0.012608859688043594, -0.02100216969847679, 0.08470612019300461, -0.0031517825555056334, 0.033449966460466385, 0.013242308981716633, 0.02110837772488594, 0.014618230983614922, -0.04304170981049538, 0.02197984606027603, 0.06688559055328369, 0.02574421651661396, -0.045794527977705, 0.0373358353972435, 0.03567683696746826, 0.044516921043395996, 0.07325885444879532, 0.007987595163285732, 0.040773455053567886, -0.0027179326862096786, 0.01602841727435589, 0.030576495453715324, 0.013823426328599453, 0.008543203584849834, 0.020804863423109055, 0.08582372218370438, 0.0004137080395594239, -0.01901276409626007, 0.07436161488294601, -0.03382265940308571, 0.007069360930472612, -0.053395360708236694, 0.024815915152430534, -0.0338716134428978, -0.022816475480794907, 0.04400728642940521, -0.020293278619647026, -0.014036102220416069, -0.0034727640450000763, -0.010488650761544704, 0.008831663988530636, 0.0338919535279274, -0.010221480391919613, 0.024804800748825073, -0.004506160970777273, -0.026584165170788765, 0.028500426560640335, -0.06343217194080353, -0.024766407907009125, -0.02698618732392788, -0.04278045892715454, 0.023514093831181526, -0.06462697684764862, 0.00019009616516996175, -0.041659679263830185, -0.02747407555580139, 0.030351657420396805, 0.021620070561766624, 0.02664831466972828, -0.017507608979940414, 0.04152553528547287, -0.04807824641466141, -0.0418708473443985, -0.031889189034700394, -0.04912397265434265, -0.045796893537044525, -0.047752924263477325, 0.037040527909994125, 0.03883790597319603, -0.010969972237944603, 0.052010659128427505, -0.0028239635284990072, 0.010785464197397232, -0.0499294176697731, 0.06617559492588043, 0.01020990964025259, -0.0059270779602229595, -0.008470469154417515, 0.020733419805765152, 0.003880891017615795, -0.03046511486172676, -0.038246043026447296, -0.023029915988445282, 0.08330415189266205, 0.0814347043633461, 0.019334042444825172, 0.01608927547931671, 0.0231016892939806, -0.059429723769426346, -0.017135992646217346, -0.04106093570590019, -0.012111494317650795, -0.007100872695446014, -0.047069329768419266, -0.03065279684960842, -0.015734704211354256, -0.012285885401070118, -0.01509094052016735, -0.006573914550244808, -0.01767726242542267, 0.03516869619488716, 0.03823452070355415, 0.047458309680223465, 0.04796659201383591, 0.0036093818489462137, 0.0051482380367815495, 0.09279636293649673, -0.009012808091938496, -0.029566612094640732, -0.07162266224622726, -0.04701884463429451, 0.018646517768502235, -0.012380776926875114, 0.01323506236076355, -0.05949578434228897, 0.04261186718940735, -0.0020745713263750076, -0.0008975438540801406, 0.027776023373007774, -0.022997431457042694, 0.008152569644153118, -0.003328507300466299, 0.02153967134654522, -0.0015762682305648923, -0.060422927141189575, 0.013903005048632622, -0.020790306851267815, 0.03715454414486885, -0.04409933462738991, -0.027633583173155785, -0.017945939674973488, 0.013620913028717041, 0.002300640568137169, -0.01987757720053196, -0.042235616594552994, 0.010321836918592453, -0.06352412700653076, -0.03793075680732727, -0.009916971437633038, 0.009865921922028065, 0.013699888251721859, 0.07334297895431519, 0.028970519080758095, -0.008001064881682396, 0.037864528596401215, -0.0046511320397257805, 0.05371379479765892, 0.04236424341797829, -0.005195035599172115, 0.045150261372327805, -0.024089565500617027, 0.02996688149869442, 0.01702144183218479, -0.024357546120882034, -0.02874450944364071, -0.07051112502813339, -0.043213099241256714, 0.015171256847679615, -0.013019931502640247, 0.007322291377931833, 0.032377343624830246, -0.0761328786611557, -0.006147494073957205, -0.009803448803722858, 0.026521947234869003, 0.02876337245106697, -0.03936163708567619, 0.04309429973363876, -0.02219192497432232, 0.028185781091451645, -0.020020579919219017, 0.007225584704428911, -0.039547450840473175, -0.038863398134708405, 0.0023863662499934435, 0.03486962988972664, 0.009217005223035812, 0.04753095656633377, 0.07488342374563217, 0.021021869033575058, -0.019261261448264122, 0.05075135827064514, 0.05234203487634659, 0.042802054435014725, -0.058917783200740814, 0.009169568307697773, -0.0114184794947505, -0.024603283032774925, -0.020432887598872185, -0.03730656951665878, -0.011245569214224815, 0.0518949069082737, -0.01777232438325882, -0.020640768110752106, 0.015455231070518494, -0.009173426777124405, -0.019948413595557213, -0.07887320220470428, 0.010364311747252941, 0.023990197107195854, -0.02183448150753975, -0.016735829412937164, 0.04933293163776398, 0.010621244087815285, 0.053837575018405914, 0.019890988245606422, -0.02331245131790638, -0.042438603937625885, 0.0376339852809906, 0.011187724769115448, -0.0675845816731453, -0.04671342670917511, -0.05316471308469772, 0.03220190852880478, 0.02316640503704548, -0.010591902770102024, -0.08743032068014145, 0.017634905874729156, 0.0520271360874176, -0.0533728264272213, 0.06312556564807892, 0.03298362344503403, 0.04579544439911842, 0.04387025162577629, -0.0067642005160450935, -0.0012411015341058373, -0.0220523402094841, -0.015545527450740337, -0.004620107356458902, 0.04921107366681099, -0.01686077192425728, -0.02403855137526989, -0.036483075469732285, 0.034233104437589645, -0.0004134571354370564, 0.03333095461130142, 0.023780155926942825, -0.0215507410466671, -0.039365991950035095, 0.007088224403560162, 0.021579977124929428, -0.04926331341266632, 0.015588230453431606, 0.0431477315723896, 0.01689556986093521, -0.02139599435031414, -0.025761902332305908, -0.005895566660910845, 0.009362280368804932, 0.06592248380184174, -0.024581845849752426, -0.033219024538993835, -0.03883035480976105, 0.022612683475017548, 0.004720636177808046, -0.04392965883016586, -0.10522866994142532, 0.03612978011369705, -0.007931091822683811, -0.02656685747206211, 0.0595211498439312, 0.02757774479687214, 0.023897986859083176, 0.07394728809595108, 0.0013310438953340054, 0.015569751150906086, -0.03303242474794388, 0.04341736435890198, -0.03539205342531204, -0.036442358046770096, 0.011251267977058887, -0.05132952705025673, -0.01252642460167408, -0.040165532380342484, -0.044165316969156265, -0.0377374067902565, 0.01601918786764145, 0.033709876239299774, -0.029712719842791557, 0.01371624507009983, 0.012021202594041824, 0.009144358336925507, -0.0012294809566810727, -0.054170094430446625, -0.012410640716552734, -0.03506080433726311, -0.059657350182533264, -0.04365936294198036, 0.03791392594575882, -0.005035681184381247, 0.023932164534926414, 0.0034728029277175665, 0.02458377555012703, 0.013101131655275822, -0.019378934055566788, -0.017877968028187752, 0.032196931540966034, 0.02618904784321785, -0.044426120817661285, -0.04397771507501602, -0.04404795542359352, 0.012077024206519127, 0.0009185854578390718, -0.057090867310762405, 0.03635062649846077, 0.02196238934993744, -0.021085225045681, -0.02153061516582966, 0.013250293210148811, 0.00024128140648826957, -0.046743229031562805, -0.05875478312373161, 0.0014907746808603406, 0.01107202097773552, 0.0355990007519722, -0.044903725385665894, -0.00744067644700408, 0.039901454001665115, 0.054436638951301575, 0.03989597037434578, 0.020156705752015114, -0.0024347302969545126, 0.05408094823360443, -0.03394201770424843, 0.01124644186347723, -0.08133042603731155, 0.012479742057621479, -0.014537785202264786, 0.03361954540014267, -0.016587598249316216, -0.0019532712176442146, -0.04333049803972244, 0.03773229196667671, -0.03504340723156929, -0.02680058404803276, 0.009273001924157143, 0.020638667047023773, -0.03398161754012108, 0.04324514791369438, -0.032252904027700424, 0.012472523376345634, -0.04653674736618996, 0.021308109164237976, -0.03609234094619751, -0.007463605143129826, 0.002886619418859482, -0.010017814114689827, -0.05408637970685959, -0.03729449212551117, -0.018613724038004875, -0.0747760459780693, 0.014677428640425205, 0.04456208646297455, -0.0037362310104072094, 0.01652003638446331, -0.02049092948436737, -0.009004614315927029, 0.01310324389487505, -0.04954605549573898, -0.024893861263990402, -0.054506320506334305, -0.02564423345029354, 0.0038152928464114666, 0.02247799001634121, 0.03442836552858353, -0.04935676231980324, -0.04851234331727028, 0.06551472097635269, 0.04748581722378731, 0.012762893922626972, 0.012478840537369251, 0.03356518596410751, 0.029689347371459007, 0.03162391856312752, 0.0009990492835640907, 0.015171544626355171, -0.039270542562007904, 0.019663330167531967, -0.0032285084016621113, 0.0005036802613176405, 0.005587312392890453, -0.029122715815901756, -0.04797721281647682, -0.029384853318333626, 0.09772323071956635, 0.04215091094374657, 0.036107707768678665, -0.0059586623683571815, -0.06001514196395874, 0.04123353213071823, 0.02582753449678421, -0.033240944147109985, 0.019794894382357597, 0.00762584013864398, -0.04011582210659981, 0.06632877886295319, 0.025751780718564987, 0.0337512381374836, 0.022395649924874306, 0.014725248329341412, -0.026703786104917526, 0.03363873064517975, -0.04476390779018402, -0.0031432872638106346, 0.022113017737865448, -0.04401383548974991, 0.0010328451171517372, -0.03826238587498665, 0.049495622515678406, -0.03614891692996025, 0.04957938194274902, 0.050102073699235916, -9.874166426016018e-05, 0.011222000233829021, -0.028685754165053368, -0.010983431711792946, 0.031677842140197754, -0.010753041133284569, 0.06186556816101074, -0.0074374014511704445, -0.07745931297540665, 0.03900652006268501, 0.03108547255396843, -0.06512308120727539, 0.031722452491521835, 0.008549943566322327, 0.012647946365177631, 0.03415451943874359, 0.04522695019841194, -0.05784319341182709, -0.01139136590063572, -0.014637447893619537, 0.013122860342264175, -0.03127758577466011, -0.02670898847281933, 0.051023080945014954, 0.010094310157001019, -0.009224277921020985, 0.03171323239803314, -0.007032867521047592, 0.02815721184015274, 0.03412032499909401, -0.04599647969007492, -0.05517728999257088, 0.006577468477189541, 0.050992149859666824, 0.03993885591626167, -0.009872814640402794, -0.04027444124221802, -0.006794418208301067, 0.016102338209748268, -0.01627134159207344, -0.03268791362643242, 0.061120036989450455, 0.03230159357190132, -0.11263767629861832, 0.0009169777040369809, 0.036213599145412445, 0.0032208524644374847, -0.035493154078722, 0.01669081673026085, 0.0012780106626451015, 0.007710043806582689, 0.015535444021224976, 0.015169922262430191, 0.0034496274311095476, -0.07034318149089813, -0.009966891258955002, 0.023845499381422997, -0.0037595026660710573, 0.04338093847036362, -0.028243770822882652, 0.013600415550172329, 0.06672463566064835, 0.025279821828007698, 0.012037968263030052, -0.05715629830956459, -0.030268756672739983, 0.03982356935739517, -0.02968951314687729, 0.043989308178424835, -0.03443540632724762, -0.042146142572164536, -0.051622238010168076, -0.01609404757618904, -0.01765049248933792, 0.06530895829200745, -0.006290975026786327, 0.016796844080090523, 0.01698577031493187, 0.00958422850817442, 0.00293816183693707, -0.05678679049015045, -0.03955871984362602, -0.03187083080410957, 0.05141907185316086, 0.019684238359332085, -0.024625755846500397, 0.018303697928786278, -0.03491023927927017, -0.04864603281021118, 0.03176124766469002, -0.011285300366580486, -0.028160076588392258, 0.07350596785545349, 0.02604042924940586, -0.021007336676120758, 0.00442914292216301, 0.034913986921310425, -0.057340387254953384, 0.03061915747821331, 0.004473674576729536, 0.011480627581477165, 0.025294611230492592, 0.03858784958720207, 0.02081691473722458, -0.02084927447140217, -0.034105028957128525, -0.018360333517193794, -0.003101494861766696, 0.0009713417966850102, 0.07005392760038376]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings.huggingface</span> <span class="kn">import</span> <span class="n">DEFAULT_QUERY_INSTRUCTION</span><span class="p">,</span> <span class="n">DEFAULT_EMBED_INSTRUCTION</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">DEFAULT_QUERY_INSTRUCTION</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">DEFAULT_EMBED_INSTRUCTION</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Preparing Documents</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
wget<span class="w"> </span>--recursive<span class="w"> </span>--no-parent<span class="w"> </span>--accept<span class="o">=</span>.html<span class="w"> </span>--directory-prefix<span class="w"> </span>_morning<span class="w"> </span>--no-clobber<span class="w"> </span>http://ailingmusheng.ren/7/2022djth/2022-7_0008.html
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<span class="c1"># 定义一个函数来递归遍历目录树，找到名为 .ipynb_checkpoints 的子目录并删除它们。</span>
<span class="k">def</span> <span class="nf">remove_checkpoints</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">dirs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;.ipynb_checkpoints&#39;</span><span class="p">:</span>
                <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>

<span class="c1"># 调用函数来删除目录下所有名为 .ipynb_checkpoints 的子目录。</span>
<span class="n">remove_checkpoints</span><span class="p">(</span><span class="s1">&#39;_morning&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">delete_ds_store_files</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;.DS_Store&#39;</span><span class="p">:</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>

<span class="n">delete_ds_store_files</span><span class="p">(</span><span class="s1">&#39;_morning&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># 1. 用户设定目录路径。</span>
<span class="n">directory_path</span> <span class="o">=</span> <span class="s1">&#39;_morning&#39;</span>

<span class="c1"># 2. 获取目录及其子目录下的所有文件，并按照扩展名分类。</span>
<span class="n">file_extension_map</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">directory_path</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="n">file_extension</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span><span class="o">.</span><span class="n">suffix</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">file_extension</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">file_extension_map</span><span class="p">:</span>
            <span class="n">file_extension_map</span><span class="p">[</span><span class="n">file_extension</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">file_extension_map</span><span class="p">[</span><span class="n">file_extension</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>

<span class="c1"># 3. 创建新目录，并将同样扩展名的文件移动到该目录下。</span>
<span class="k">for</span> <span class="n">file_extension</span><span class="p">,</span> <span class="n">file_list</span> <span class="ow">in</span> <span class="n">file_extension_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">new_directory_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory_path</span><span class="p">,</span> <span class="n">file_extension</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
        <span class="n">new_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_directory_path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">directory_path</span><span class="p">))</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">new_file_path</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 创建目录，存在则不创建。</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">new_file_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>chardet
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully installed chardet-5.1.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">chardet</span>

<span class="c1"># 读取文件内容</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;_morning/html/ailingmusheng.ren/7/2022djth/2022-7_0008.html&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1"># 检测文件内容的编码类型</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chardet</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># 输出编码类型和可信度</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;编码类型:&#39;</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;encoding&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;可信度:&#39;</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;confidence&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>编码类型: utf-8
可信度: 0.99
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<span class="k">def</span> <span class="nf">remove_xml_lines</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">line</span> <span class="o">!=</span> <span class="s2">&quot;&lt;?xml version=&#39;1.0&#39; encoding=&#39;utf-8&#39;?&gt;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">:</span>
                        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

<span class="n">remove_xml_lines</span><span class="p">(</span><span class="s1">&#39;_morning/htm&#39;</span><span class="p">)</span>
<span class="n">remove_xml_lines</span><span class="p">(</span><span class="s1">&#39;_morning/html&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain/blob/master/langchain/document_loaders/__init__.py">Different Types of Document Loaders</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/html.html">Document Loader - BSHTMLLoader</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain/blob/master/langchain/document_loaders/html_bs.py">https://github.com/hwchase17/langchain/blob/master/langchain/document_loaders/html_bs.py</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">BSHTMLLoader</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s1">&#39;_morning/htm&#39;</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">BSHTMLLoader</span><span class="p">)</span>
<span class="n">raw_documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="k">for</span> <span class="n">raw_document</span> <span class="ow">in</span> <span class="n">raw_documents</span><span class="p">:</span>
    <span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="s1">&#39;。</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from langchain.document_loaders import DirectoryLoader, BSHTMLLoader</span>
<span class="c1"># loader = DirectoryLoader(&#39;_morning/html&#39;, loader_cls=BSHTMLLoader)</span>
<span class="c1"># raw_documents = loader.load()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain/blob/master/langchain/text_splitter.py">https://github.com/hwchase17/langchain/blob/master/langchain/text_splitter.py</a> =&gt; RecursiveCharacterTextSplitter</li>
<li><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain/blob/master/langchain/schema.py">https://github.com/hwchase17/langchain/blob/master/langchain/schema.py</a> =&gt; Document</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
    <span class="n">chunk_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/fxsjy/jieba">结巴中文分词</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Kyubyong/wordvectors">https://github.com/Kyubyong/wordvectors</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/fastText">https://github.com/facebookresearch/fastText</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.docstore.document</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="c1"># import pdb; pdb.set_trace()</span>
<span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">([</span><span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="s1">&#39;第四周历代志、以斯拉记、尼希米记、以斯帖记结晶读经第四周借着神的申言者神圣的鼓励，恢复神殿的建造周四、周五叁撒迦利亚书启示，灯台的七灯（四2，启四5）是神的七灵，七倍加强的灵（一4），就是耶和华的七眼（亚四10），也是救赎之羔羊的七眼（启五6），以及建造之石头的七眼（亚三9），为着三一神完满的彰显和神殿的重建：一在撒迦利亚三章九节里，这块安置在约书亚面前的石头，预表基督是神建造的石头（诗一一八22，太二一42）；耶和华要雕刻这石头，指明基督在十字架上受死时，乃是被神雕刻、剪除；耶和华要在一日之间除掉那地的罪孽，指明神在其上作工的基督，要在一日之间，就是在祂钉十字架之日，除掉以色列地的罪；借着祂在十字架上的死，神的羔羊基督除去了世人的罪（彼前二24，约一29）：１石头、耶和华和羔羊乃是一；基督是救赎的羔羊和建造的石头，也是耶和华；基督乃是羔羊石头—羔羊为着救赎，石头为着建造—启五6，亚三9。２在神的建造里，基督是基石，托住神的建造；是房角石，将祂身体上外邦和犹太的肢体联络在一起；也是恩典的顶石，完成神建造中的一切—赛二八16，林前三11，弗二20，彼前二6，亚四7。３神的羔羊基督是那有七眼之建造的石头，这启示基督的七眼乃是为着神的建造—约一29，亚三9，启五6。４基督是建造的石头，有七眼，就是七灵，为要将祂自己灌注到我们里面，好把我们变化为宝贵的材料，为着神的建造；当主注视我们，祂的七眼就将祂自己灌注到我们里面—亚三9，林前三12，启三1，五6。二为着完成神的建造，七倍加强的灵是基督这救赎之羔羊和建造之石头的眼睛，鉴察并搜寻我们，并用基督的素质、丰富和负担，注入并灌注到我们里面，为着神的建造—亚三9，四7，启一14，五6：１羔羊的七眼，将基督这法理的救赎者注入我们里面；石头的七眼，将基督这生机的拯救者注入我们里面，目的是为着神在地上经纶的行动，要借着祂法理的救赎，凭着祂生机的拯救，达到祂建造的目标—约一29，徒四11~12，罗五10。２在我们里面有两盏灯—神七倍加强的灵在我们的灵里（箴二十27，启四5，林前六17）；我们要被变化，就必须在祷告中向主完全敞开，让主的灯同着七盏火灯搜寻我们魂里的每一个房间，照耀并光照我们内里的各部分，用生命供应各部分。３经历最大变化的人，乃是向主完全敞开的人；借着七倍加强的灵在寻求基督之信徒里的运行，他们就得着加强，成为得胜者，以建造基督的身体，终极完成新耶路撒冷。三基督这位末后的亚当，在复活里成了赐生命的灵（十五45下，约六63上，林后三6下），祂也是七倍加强的灵；这灵就是生命的灵（罗八2）；因此，七灵的功用乃是将神圣的生命分赐到神的子民里面，为着建造神永远的居所新耶路撒冷。四七倍加强的灵乃是七盏火灯，焚烧、光照、暴露、搜寻、审判、洁净并炼净我们，好产生金灯台，完成神新约的经纶—启四5，一2、4、9~12、20。第四周周五晨兴喂养箴二十27人的灵是耶和华的灯，鉴察人的深处。启四5……有七盏火灯在宝座前点着，这七灯就是神的七灵。谁经历最大量的变化？就是向主完全敞开的人。……“主，我向你完全敞开。我要一直向你敞开。我的全人—我的心、我的心思、我的意志和我的情感—是敞开的。求你一直照耀，彻底鉴察我，光照并点活我。我愿完全接受你的光照。”这样，光会渗透每一部分，同时生命会供应给你。泥土所造的人要变化成为基督的形像。随着金这样成形在你里面，就会有七灵照耀并彰显神。愿我们众人向祂敞开，接受祂的光照，并让祂的生命供应我们。然后我们就会变化，并有基督的形像。我们蒙里面的灯光照，就会实际地在我们的地方上成为金灯台，彰显三一神。这样，祂就要得着祂的见证（李常受文集一九七九年第一册，五○七至五○八页）。信息选读这包罗万有、超绝、奇妙、奥秘、美妙的一位，乃是神行政的执行者。……因为祂有资格，因为祂配〔参启五4~6〕，所以七印交给了祂。这一位有资格揭开七印，执行神的经纶。祂执行神经纶的方式，乃是凭着七灵作祂的眼睛。……基督是神经纶的焦点执行者，但祂需要七灵作祂的眼睛，来执行神的经纶。今天七灵在地上焚烧，为着执行神的行政。……焚烧的火焰执行神的经纶，目的是要产生金灯台，众召会。焚烧含示审判、洁净、炼净、产生。……我不相信在世界或召会里似乎令人失望的光景。我相信焚烧之七灵的火焰，支配并指引世界，也审判、洁净并炼净召会，要产生一个纯金的灯台。我们在这里尽量给主机会和入口，来审判我们、洁净我们并炼净我们，好产生一个纯金的灯台。我们向着神七灵的焚烧大大敞开。我们都需要祷告：“亲爱的神圣火焰，来吧！来审判！来洁净！来炼净，使你能产生金灯台。”……因着祂的怜悯，我们向祂敞开。我们每天、每早、每晚都需要祷告：“主，来吧；我们向你敞开！我们全人的每一通道都向你敞开。”……我能作见证，我几乎天天祷告：“主，光照我；主，搜寻我里面，并且暴露我。我喜欢被你光照，并且在你的光中被暴露。”……我们都必须祷告：“主，我们是敞开的。来照耀在我们身上，从我们里面照耀，光照我们全人的每一通道、每一角落。我喜欢被暴露、被清理、被炼净。”这样，主就有路产生纯金的灯台。出自永远者和救赎者的七灵，乃是在神宝座前点着的七盏火灯，在宇宙中执行神的经纶；也是被杀之羔羊的七眼，搜寻并灌注众召会（四5，五6下）。七灵的双重使命乃是执行神的行政，以及搜寻并灌注众召会。七灵搜寻出我们的罪恶，并以基督的丰富灌注我们。当人和你说话的时候，他的两眼同时把他的负担灌注到你里面。照样，神的七灵作为羔羊的眼睛，也把这位奇妙者的负担和素质灌注到我们里面（李常受文集一九八四年第三册，四四八至四五二页）。参读：生命信息，第六十八至七十章；神新约的经纶，第二十三章。确定的话定住的光启示：七灵乃是在神宝座前点着的七盏火灯。经历：七灯来焚烧、光照、暴露、搜寻、审判、洁净并炼净我们。应用：借长时祷告向主完全敞开。一句话：“亲爱的神圣火焰，来吧！来审判！来洁净！来炼净！”&#39;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{})])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;这是一个测试文档。&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[&#39;这&#39;, &#39;是&#39;, &#39;一&#39;, &#39;个&#39;, &#39;测&#39;, &#39;试&#39;, &#39;文&#39;, &#39;档&#39;, &#39;。&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Embedding Documents</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceInstructEmbeddings</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hfi_embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceInstructEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;hkunlp/instructor-large&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>load INSTRUCTOR_Transformer
max_seq_length  512
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p><code>tqdm</code> 是一个 Python 库，用于在循环中添加进度条。它可以用于任何可迭代的对象，如列表、元组、字典、文件等。它提供了一个简单的 API ，可以轻松地将进度条添加到循环中。以下是一个简单的示例代码：</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.autonotebook</span> <span class="kn">import</span> <span class="n">trange</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="mi">1000000</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000000</span><span class="p">)):</span>
    <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [00:00&lt;00:00, 4955597.80it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在这个例子中，我们使用了 <code>tqdm</code> 库来添加一个进度条到循环中。我们使用了内置的 <code>range()</code> 函数来生成一个包含 1000000 个元素的迭代器，并将其传递给 <code>tqdm()</code> 函数。然后，我们使用了一个简单的循环来遍历这个迭代器，并在每次迭代时调用 <code>tqdm.update()</code> 方法来更新进度条。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Loading Faiss Indexer from Disk</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">pickle</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/vectorstore_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="c1"># load vectorstore</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/vectorstore_morning.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Embedding and Indexing</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.vectorstores.faiss</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.vectorstores.faiss</span> <span class="kn">import</span> <span class="n">FAISS</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/vectorstore_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">hfi_embeddings</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Saving Faiss Indexer to Disk</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/vectorstore_morning.pkl&#39;</span><span class="p">)):</span>
    <span class="c1"># save vectorstore</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/vectorstore_morning.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vectorstore</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/vectorstore_morning.pkl
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
-rw-r--r--  1 saintway  staff   1.3G Apr 17 00:47 /Users/saintway/vectorstore_morning.pkl
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Similarity Searching</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;你知道什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get context related to the question from the embedding model</span>
<span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[Document(page_content=&#39;神在人里之行动的五个步骤&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;第十篇\n历代志、以斯拉记、尼希米记、以斯帖记结晶读经\n第十篇\u3000以斯拉记和尼希米记这两卷恢复的书中心并重要的点—主恢复中正确并适当的领导\n调速 \u3000\n本篇信息，我们来到另一个结晶，题目是“以斯拉记和尼希米记这两卷恢复的书中心并重要的点—主恢复中正确并适当的领导”。许多人可能对以斯拉记和尼希米记有这样的结晶，感到意外。相信很少有人能读出这两卷书中心并重要的点，是主恢复中正确并适当的领导。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;}),
 Document(page_content=&#39;因为这爱是在基督里、同着基督、借着基督并为着基督的。”神在人里之行动的五个步骤，就是这“慈绳”（人的绳）；每一步骤都与基督的人性有关。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;经历：属灵人乃是一个受他的灵管治并支配的人。\n应用：我们需要操练灵，全心转向主。\n一句话：基督乃是神经纶的中心与普及。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_6.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。那是因为神在以色列人中间，在以色列人身上，作了许许多多的事，但神却把自己藏在一边，藏在以色列人的旁边，藏在以色列人的背后。不错，祂是一直在那里作事，但另一面祂却一直把自己隐藏起来。一大堆的事都是祂作的，但以色列人却看不出来那一位作这些事者到底是谁。所以当申言者以赛亚发现了这件事，他就在那里说，“……你实在是自隐的神。”&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_1.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;因着己是最大的仇敌，所以我们需要经历神话语的杀死能力。当我们祷读时，我们一面得着滋养，一面某些元素就被杀死。也许你受到疑惑、忌恨、嫉妒、骄傲以及自私的困扰。你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。借着祷读，里面的对头就被除灭。我们祷读主话一段时间后，就会发觉攻击我们的对头消失了。就着非常实际的意义说，我们的对头被接受到我们里面的话杀死了。\n在以弗所五章，话是为着滋养，使新妇美丽。但在六章，话是为着杀死，使召会能作团体的战士，从事属灵的争战（以弗所书生命读经，九八一、九八八、九九○页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_5.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;第九篇\n历代志、以斯拉记、尼希米记、以斯帖记结晶读经\n第九篇\u3000建造与争战—为着召会的建造，需要从事属灵的争战\n调速 \u3000\n本篇信息的篇题是“建造与争战—为着召会的建造，需要从事属灵的争战”。这信息是直接向着基督团体的身体，然后间接向着基督身体上所有肢体说的。属灵的争战乃是基督身体的事，我们必须在身体里争战。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_ts.htm&#39;, &#39;title&#39;: &#39;第九篇&#39;}),
 Document(page_content=&#39;圣经的最后两章讲到这个宇宙的建造，就是神性与人性的调和。我们可以说，那就是神在已过的永远里渴望得着的。在将来的永远，祂要得着这样一个相互的住处。盼望我们众人能对建造有一个新鲜、更新的异象。遗憾地说，今天在基督徒中间，即便是热心的基督徒，也少有人看见并在乎这件事。但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。我们为此被预定、蒙救赎、得重生，我们也为此正在被变化，好成为石头来为着这个建造。所以我们今天要实行召会生活，好在这个时代完成建造的工作。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/4_ts.htm&#39;, &#39;title&#39;: &#39;第四篇&#39;}),
 Document(page_content=&#39;确定的话 定住的光\n启示：主的生命就是人的光。\n经历：正确的教训总是释放生命的光。\n应用：借着传福音和牧养把人带到神圣的光中。\n一句话：出黑暗并进入祂奇妙之光。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/5_h_4.htm&#39;, &#39;title&#39;: &#39;第五周&#39;}),
 Document(page_content=&#39;告诉我不该祷告。相反的，你嘱咐我祷告。因此，主，我现在祷告，求你表白。”……这个比喻的意义很深奥，我们都需要认识这里所启示的神（路加福音生命读经，四○二至四○四页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_5.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;确定的话 定住的光\n启示：“耶和华”的意思是“我是那我是”。\n经历：今天在主的恢复里，我们乃是在应验的阶段。\n应用：当你遭遇试验、试炼和难处时，倚靠耶和华神。\n一句话：你们要称谢耶和华，呼求祂的名。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_2.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;当反对我们的人逼迫我们的时候，我们的神似乎是不义的，因为祂允许祂的儿女遭受不义的逼迫。比方，施浸者约翰被斩，彼得殉道，保罗下监，约翰被放逐。历世历代以来，千千万万诚实、忠信跟从人救主的人都遭受过不义的逼迫，甚至今天我们仍遭受不义的错待。我们的神似乎不公平，因为祂不来审判并表白。\n活神、公义的神在哪里？祂为什么容忍这种光景？祂为什么不审判那些逼迫我们的人？因着这种光景，人救主在路加十八章一至八节用一个不义的审判官，来表征那似乎不为祂受逼迫的子民作些什么的神。……从这比喻我们要学习作个烦扰的寡妇， 一个恒切向神祷告的人（路加福音生命读经，四○一至四○二页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_5.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;当神对某一件事的态度改变时，祂就有一个时代的行动。……神最重要的时代行动是在启示录十二章。祂要结束这个时代，带进国度时代。祂的定旨不是笼统和一般的。祂怎样才能结束这个时代，带进另一个时代？祂必须得着祂时代的凭借（译自《圣洁没有瑕疵》英文版附录）。\n信息选读\n男孩子的被提结束召会时代并引进国度时代。男孩子使神能有所行动。……我们绝不该忘记，神是能被限制的。在祂一切的行动中，祂等候人。神在天上的捆绑是基于我们在地上的捆绑；神在天上的释放是基于我们在地上的释放。每一件事都在于召会。\n作得胜者主要不是为着逃避大灾难。我们需要看见被提对主的价值，不是对我们的价值。\n在所有时代的行动中，男孩子是最大的，因为这除去人的能力和魔鬼的能力，并带进国度。我们活在这时代是最享特权的，我们能为神作得最多。光要使我们看见道路，而力量和能力要使我们能行走这道路。现今要被神使用，就必须付极大的代价。\n神的心意是要受造之物来对付堕落的受造之物。照着祂的定旨，全召会都该对付撒但；然而，召会堕落了……。神的定旨得以在得胜者身上成就，是因为他们与祂同工。……神总是得着一班得胜者，来进行时代的行动。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/7_h_1.htm&#39;, &#39;title&#39;: &#39;第七周&#39;}),
 Document(page_content=&#39;带领的人乃是奴仆\n在神子民中间的领导这件事，非常重大。神对领导的观念，与我们天然的观念迥然不同。我们需要看三处经文：马太二十三章八至十节，希伯来十三章七节和十七节，以及马太二十章二十五至二十八节。乍看之下，马太二十三章和希伯来十三章这两处经文似乎互相矛盾。在马太二十三章八至十节，主说，“但你们不要受拉比的称呼，因为只有一位是你们的夫子，你们都是弟兄；也不要称地上的人为父，因为只有一位是你们的父，就是那天上的；也不要受师尊的称呼，因为只有一位是你们的师尊，就是基督。”主的意思是，没有人是你们的师尊，只有基督是，甚至不该有师尊的称呼，或父的称呼，因为只有一位领头人，就是基督。然而，希伯来十三章七节说，“要记念那些带领你们……的人。”十七节说，“你们要信从那些带领你们的，且要服从。”那么，到底有没有带领的人呢？&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;}),
 Document(page_content=&#39;信息选读\n联结的信使得胜者有资格在基督凯旋回来时与祂相见，这是对得胜者的神圣要求。这是根据路加十八章八节。……今天，整个世界都是不信的。今天不仅在外邦人、异教徒中间，甚至在犹太人、天主教徒、更正教徒和灵恩派的人中间，何处找得到信心？如果主今天来了，祂在哪里找得到信心？地上几乎没有一个人是相信的。但因着祂的怜悯，在已过年间，借着倪弟兄的带领，我们被带进一种光景，学习在凡事上不信靠我们自己，只相信我们的神是一切。\n我盼望主回来时，祂能找到你我都是相信的人，是一直信靠祂，不信靠自己，对自己没有确信的人。我们的确信完全在祂身上。这是联结的信。这信是得胜者的资格，这是神圣的要求，使你我作为得胜者，可以在基督凯旋回来时与祂相见。……最终，主会找到一些人，就是少数的得胜者，他们在主回来时，是凭联结的信而活。……基督盼望找着我们作祂隐藏的得胜者。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_6.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;，在那里进攻，要把基督所建造的召会，拖到死亡里去。但你在那里也看见，召会有权柄，有诸天之国的钥匙，能在那里捆绑天上所捆绑的，释放天上所释放的。召会是有权柄的，召会也是争战而得胜的（李常受文集一九五七年第二册，八七至八八页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_h_3.htm&#39;, &#39;title&#39;: &#39;第九周&#39;}),
 Document(page_content=&#39;信息选读\n这男孩子并不是个人的，乃是团体的。……这团体的男孩子包括作他元首、中心、实际、生命和本质的主耶稣。……诗篇二篇八至九节预言主耶稣，神的受膏者，要用铁杖辖管列国；启示录二章二十六至二十七节说，召会中的得胜者要用铁杖辖管列国；而十二章五节告诉我们，男孩子要用铁杖辖管万国。因此，……主耶稣自己和祂的得胜者都要用铁杖辖管万国。所以，十二章五节的男孩子，包括主耶稣和召会中的得胜者。此外，二十章四节说，基督和复活的得胜者要作王掌权一千年。因此，启示录十二章的男孩子，既不是指个人的主耶稣，也不是指与祂分开的得胜者，乃是指主耶稣连同得胜者。基督自己是头一位得胜者（三21）。祂这位领头的得胜者，乃是众得胜者的元首、中心、实际、生命和本质。在地上属神的人中间，有一部分是刚强的，包括主耶稣和得胜者。因此，男孩子是由主耶稣和祂的得胜者组成的。\n主耶稣是男孩子，却从女人而生。……这件事属灵的意义是说，主耶稣是从信靠神的源头而生。……男孩子的源头是女人，不是男人。……男孩子是信靠神、倚靠神之女人的后裔。主耶稣就是从这样的源头而出的后裔。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/7_h_2.htm&#39;, &#39;title&#39;: &#39;第七周&#39;}),
 Document(page_content=&#39;信息选读\n撒迦利亚四章十二节说到……枝子“流出金”。这里的“金”是指油。油和金乃是一。油是指那灵，那灵乃是神。不仅如此，按预表，金表征神。那充满油碗的金乃是那灵，那灵就是神；神是由金所表征的。我们将这事应用到今天的经历时，就看见从我们里面流出来的那灵就是神，而神就是金。因此，我们将基督供应给别人，用油供应他们的时候，实际上就是用神供应他们。神从我们流出来，流到他们里面。我们都该是橄榄树，从我们自己里面流出神来，流到别人里面（撒迦利亚书生命读经，四一三至四一四页）。\n在出埃及记，灯台是基督作神的具体化身；在新约末了，灯台是众召会作三一神具体化身的繁增。……这灯台只有两个基本元素—金和油。金是具体的形状，油是燃烧的元素。当这二者放在一起，就有灯台照耀，在神的三一里彰显祂，有父的性情和素质、子的形像和样子以及灵的彰显。……撒迦利亚四章十二节告诉我们，灯台的油乃是金油。……召会作为灯台，乃是三一神扎实的具体化身，有七倍的灵作为油。事实上，油的素质就是金的元素。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/4_h_6.htm&#39;, &#39;title&#39;: &#39;第四周&#39;}),
 Document(page_content=&#39;自隐的神默默却强有力地在我们里面运行\n自隐的神默默却强有力地在我们里面运行（腓二13）。这是在我们与主的关系中，一件非常个人的事。“默默”指明不只是隐藏的，更是安静的，甚至是沉默的。我们通常不会将“安静”和“沉默”这二辞，联于有活力的行动。但神的确是默默却强有力地在我们里面运行。神之所以能强有力地运行，指明我们所是的某些部分被主征服、对付、变化了。主在这个内里的争战中征服了我们，祂正在强有力地摸着我们内里核心的部分。这也就是祂对我们美妙的照顾。祂知道我们愿意作敞开的器皿。当我们愿意对祂说，“主啊，我不知道自己的光景如何，也不知道自己需要什么；但是你知道。无论你想要到哪里，摸着什么，求你自己来作。”祂就会进到我们的深处，以一种隐藏的方式来对付那些抵触祂的事物，并以包罗万有的基督来顶替。你自己可能不会察觉，但别人会感觉得到。最近我听见一位中年姊妹在聚会中简短的说话，我里面满了感谢和敬拜。她自己也许没有察觉，但基督从她照耀出来了。隐藏的神在她里面作工，使基督在她里面长大并扩展。这位隐藏的神也正在我们每一位里面默默地作工。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_ts.htm&#39;, &#39;title&#39;: &#39;第十二篇&#39;}),
 Document(page_content=&#39;信息选读\n当〔主的〕恢复是圣别的，我们就会看见主的祝福。在一些地方祝福受到拦阻，原因乃是因着背景而引起的混杂。我们曾多次被定罪，说我们不邀请别人来我们的聚会中说话。我们不是骄傲，但我们的确谨慎。……已过我们曾经试过，却只引起麻烦；所以我们学了功课。这不是说我们狭窄，乃是说，这个恢复是如此纯净、单纯、圣别。我们的确需要以斯拉来作洁净的工作。主不喜欢任何的混杂。在主的创造里，凡物“各从其类”。……我们需要纯净、严谨、单纯并归从我们的种类！我们若是公会，就该单单是公会。我们若是自由团体，就该单单是自由团体。我们不该说我们是别的。我们若是地方召会，就该单单是地方召会。我们必须如此单纯、单一、纯净，真正归从我们的种类。我们必须是绝对的。主从不尊重任何的混杂，必须是各从其类。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_h_1.htm&#39;, &#39;title&#39;: &#39;第六周&#39;}),
 Document(page_content=&#39;保罗在以弗所六章十二节也提到“诸天界里那邪恶的属灵势力”。这里的诸天界，指空中（二2）。撒但和他邪恶的属灵势力是在空中；但我们是坐在第三层天上，超过他们（6）。打仗的时候，凌驾仇敌之上的地位，在战略上是非常重要的。撒但和他邪恶的势力是在我们之下，他们注定是要被击败的。\n我们的争战不是抵挡人，乃是抵挡邪灵，就是诸天界里的属灵势力。背叛的天使是撒但国度里的邪灵。因此，召会和撒但之间的争战，乃是我们这些爱主并在祂召会中的人，抵挡诸天界里邪恶势力的争战。表面看是血肉之人破坏召会，实际上是撒但和他邪恶的天使在那些造成破坏的人背后作工。所以，我们必须争战，抵挡这些属灵的势力（以弗所书生命读经，六四二至六四三页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_h_4.htm&#39;, &#39;title&#39;: &#39;第九周&#39;}),
 Document(page_content=&#39;第二周\u3000周二\n晨兴喂养\n代上十六8\u3000你们要称谢耶和华，呼求祂的名，在万民中传扬祂的作为。\n出三14\u3000神对摩西说，我是那我是；又说，你要对以色列人这样说，那我是差我到你们这里来。\n神是普通的名字，耶和华是亲近的名字。神是指着神的能力说的，耶和华是指着神的爱心说的。神是指着创造方面说的，耶和华是指着神的亲近说的。创世记一章没有耶和华。因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。二章是神和人亲密，有了关系，所以说耶和华神。……这……证明二章的耶和华，就是一章里的神。耶和华神不只是有能力的，也是和人亲近的（倪柝声文集第一辑第九册，六四页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_2.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;对付灵并不是对付灵的本身，乃是对付灵的经过，也就是对付我们的存心、动机、目的、用意等等。我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。\n信息选读\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。……对付灵，乃是重在对付我们里面不纯的存心、动机等杂质；而对付良心，乃是重在对付良心对那些杂质的感觉。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_h_2.htm&#39;, &#39;title&#39;: &#39;第六周&#39;}),
 Document(page_content=&#39;我们所要注意的是第三—我们怎样把神的旨意回头祷告神。……一切有价值的祷告都是回头的。如果我们的祷告只是为要成功我们所打算、所盼望的，这在属灵的世界中是没有多大价值的。必须是从神起头，我们响应，这才是有价值的祷告。神的工作是被这样的祷告所支配的。多少事，神愿意作，但是因为神的子民不祷告的缘故，祂宁可不作。神必须等人同意以后祂才去作，这是神作工的一个大原则，是圣经中最要紧的原则之一。\n当神创造人的时候，就给人有一个自由意志。这样，在宇宙之中就有了三个不同的意志：一个是神的意志，一个是仇敌撒但的意志，一个就是人的意志。按着人的想法，神为什么不在一分钟之内把撒但消灭了。但是神没有这样作。神要与人合起来去对付撒但。神有神的意志，撒但有撒但的意志，人也有人的意志。神就是要得着人的意志与祂合起来。……神不单独作，神要人与祂合作。这就是召会在地上的责任。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_5.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;撒迦利亚九章九节……启示基督将要公义地带着给我们的救恩而来，并且祂要骑着驴，甚至骑着驴驹而来。这一节在四福音，在耶稣基督末次进入耶路撒冷时得了应验。祂来作王，乃是卑微的王、降卑的王，不是骑着骏马，乃是骑着驴驹（撒迦利亚书生命读经，四五五、四四○页）。\n信息选读\n撒迦利亚十一章十二至十三节启示，弥赛亚这位以色列合式的牧人被憎嫌、攻击、弃绝，并以三十锭银子，就是以一个奴仆的价值（出二一32）被卖。这里所预言的，在福音书里得着应验。主耶稣在罗马帝国统治的时候被卖，又为罗马的官长所审判。……撒迦利亚十一章十二节说，“我对他们说，你们若以为美，就给我工价；……于是他们称了三十锭银子作为我的工价。”这清楚指明基督被憎嫌、攻击、弃绝并被卖。我们若要明白这……经文，并要知道谁给了银子，谁将银子丢在耶和华的殿中（13），就需要研读四福音书。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_2.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;“战兢”与“不忠信”\n我要强调两个辞。第一个辞是“战兢”。以赛亚六十六章一至二节说，“耶和华如此说，天是我的座位，地是我的脚凳；你们要在哪里为我建造殿宇？哪里是我安息的地方？……但我所看顾的，就是灵里贫穷痛悔、因我话战兢的人。”通常没有太多人留意到“战兢”这辞。我们多数时候强调要享受主的话，要吃主的话。的确，我们要恢复吃主的话。然而，圣经也告诉我们要惧怕神的话，因主的话战兢。我们来到主的话前，应当有一种郑重、认真的态度，甚至带着敬畏来接受主的话。我们要在主的话前谦卑自己。我们的回应，应当能配得上主的话。\n原谅我说，现今在神的子民中间，有一种错误的思想，以为圣经里有些话只是为着古时，今天已经不合时宜。我要告诉圣徒们：神的话是永远的。我们需要享受，我们需要吃，但我们也需要重看神的话，敬重神的话，我们要对主的话举起手说阿们，正如诗篇一百一十九篇四十八节所说的：“我要向你的诫命举手。”我们需要因主的话战兢。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_ts.htm&#39;, &#39;title&#39;: &#39;第六篇&#39;}),
 Document(page_content=&#39;请记得，每一位圣徒都是一个“小新耶路撒冷”。这意思是，在我们全人的中心，该有神和羔羊的宝座。我们要如何行事或生活，不该凭自己作决定，也不必凭自己作决定，因为在我们里面有宝座。我们在日常生活中该操练自己，在每件事上服从里面的宝座。启示录二十二章一节说，“城内街道当中一道生命水的河，明亮如水晶，从神和羔羊的宝座流出来。”如果我们在宝座的管制之下，就会得着生命水河的滋润和供应。我们如果拒绝宝座的管制，这道生命水的流就会停止。相信我们都曾有这样的经历，因为我们每一个人都是一个小新耶路撒冷。二节说，“在河这边与那边有生命树。”这宝座在我们全人的中心该是得胜的，然后生命水就会从宝座流出来供应我们，并将生命树带给我们，终日滋养我们。圣城的街道是纯金（二一21），金象征神圣的性情。有时我们会发觉里面生命的供应停止了，这是因为我们没有活在神圣的性情里。在新耶路撒冷里，只有一条纯金的街道。我们应该行走在其中，以神圣的性情为我们的道路。这神圣的性情是在我们的灵里，并且要从我们的灵往外扩展到我们全人的三部分。神圣的性情里有一种自然而然的本能，使我们摸到世俗的、不圣别的事物时，会觉得不对劲；神圣的性情会拒绝这些事物。另一面，我们若走在&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/11_ts.htm&#39;, &#39;title&#39;: &#39;第十一篇&#39;}),
 Document(page_content=&#39;第一周\u3000周六\n晨兴喂养\n亚十二1\u3000耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说。\n十8\u3000我要向他们发哨声，聚集他们，因我已经救赎他们；他们的人数必增多，如从前增多一样。\n诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一。何等奇妙，在旧约这卷揭示基督与人类历史和政治息息相关的书里，有这样的一节〔亚十二1〕。这指明在神的经纶里，神计划要使基督作祂在地上行动的中心与普及。祂是神，几千年来，在一个接一个的世代中，一直掌管全人类，管理世界的局势。为使祂所拣选的人能关心祂这位创造主并救赎主，祂需要为人创造一个接受的器官，使人能接受神计划里之基督一切的所是。基督是奇妙的，但我们若没有灵，怎能接受祂？……我们若忽略我们人的灵，就没有路可以接触神了（撒迦利亚书生命读经，四五六页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_6.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;撒迦利亚十二章一节说，“耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说”\n撒迦利亚十二章一节说，“耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说。”这里所说的，乃是关系到人类历史中的神圣历史。\n神在祂的创造里，造了三样极其关键、同等重要的东西—诸天、地和人的灵；诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一\n神在祂的创造里，造了三样极其关键、同等重要的东西—诸天、地和人的灵。诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一（1）。神给我们造了一个灵。因为祂是灵，如今我们能用我们的灵质实祂。我们能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一。\n人里面的中央政府并最重要的部分应当是他的灵；一个受他的灵管治并支配的人就是属灵的人&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;五十二年过去了，至今我一点也不懊悔。在这五十二年中，我看见故事一再重演，人来了又去了，一幕又一幕。从台湾岛上的工作开始至今，三十几年中有几次重大的事情发生，甚至我带得救、一手造就出来的弟兄，也离开了主的恢复。异象不变，但人会变，跟从人的也会变。所以我愿语重心长地劝勉诸位：我蒙主怜悯，今天能在这里，把这个异象带给你们；我乃是盼望你们跟随的，不是我这个人，而是我蒙主怜悯所给你们看见的这异象。\n我只告诉你们一个事实，是主怜悯我，启示给我看见异象。所以我劝你们，不要跟随我，乃要跟随我蒙主怜悯，承继倪弟兄和历代主的仆人所留下，传承给你们看见的这个异象。这实在是从亚当头一幕的异象，直到新耶路撒冷末了一幕的异象（五一至五四页）。\n在这段话里我们实在看见主仆人的纯洁；他不要我们跟随他这个人，乃要我们跟随时代的异象。我们的“清明上河图”是从亚当和生命树开始，一路延展到新耶路撒冷。我们需要看见整幅图画，这异象就是主恢复里的领导。当你有了这样宽广的异象，你还能到哪里去？这异象约束我们生活的每一面，包括我们的事奉、行动、家庭生活和召会生活。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;})]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;第八周讲了什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get context related to the question from the embedding model</span>
<span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[Document(page_content=&#39;神在人里之行动的五个步骤&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;第十篇\n历代志、以斯拉记、尼希米记、以斯帖记结晶读经\n第十篇\u3000以斯拉记和尼希米记这两卷恢复的书中心并重要的点—主恢复中正确并适当的领导\n调速 \u3000\n本篇信息，我们来到另一个结晶，题目是“以斯拉记和尼希米记这两卷恢复的书中心并重要的点—主恢复中正确并适当的领导”。许多人可能对以斯拉记和尼希米记有这样的结晶，感到意外。相信很少有人能读出这两卷书中心并重要的点，是主恢复中正确并适当的领导。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;}),
 Document(page_content=&#39;因为这爱是在基督里、同着基督、借着基督并为着基督的。”神在人里之行动的五个步骤，就是这“慈绳”（人的绳）；每一步骤都与基督的人性有关。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;经历：属灵人乃是一个受他的灵管治并支配的人。\n应用：我们需要操练灵，全心转向主。\n一句话：基督乃是神经纶的中心与普及。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_6.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。那是因为神在以色列人中间，在以色列人身上，作了许许多多的事，但神却把自己藏在一边，藏在以色列人的旁边，藏在以色列人的背后。不错，祂是一直在那里作事，但另一面祂却一直把自己隐藏起来。一大堆的事都是祂作的，但以色列人却看不出来那一位作这些事者到底是谁。所以当申言者以赛亚发现了这件事，他就在那里说，“……你实在是自隐的神。”&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_1.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;因着己是最大的仇敌，所以我们需要经历神话语的杀死能力。当我们祷读时，我们一面得着滋养，一面某些元素就被杀死。也许你受到疑惑、忌恨、嫉妒、骄傲以及自私的困扰。你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。借着祷读，里面的对头就被除灭。我们祷读主话一段时间后，就会发觉攻击我们的对头消失了。就着非常实际的意义说，我们的对头被接受到我们里面的话杀死了。\n在以弗所五章，话是为着滋养，使新妇美丽。但在六章，话是为着杀死，使召会能作团体的战士，从事属灵的争战（以弗所书生命读经，九八一、九八八、九九○页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_5.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;第九篇\n历代志、以斯拉记、尼希米记、以斯帖记结晶读经\n第九篇\u3000建造与争战—为着召会的建造，需要从事属灵的争战\n调速 \u3000\n本篇信息的篇题是“建造与争战—为着召会的建造，需要从事属灵的争战”。这信息是直接向着基督团体的身体，然后间接向着基督身体上所有肢体说的。属灵的争战乃是基督身体的事，我们必须在身体里争战。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_ts.htm&#39;, &#39;title&#39;: &#39;第九篇&#39;}),
 Document(page_content=&#39;圣经的最后两章讲到这个宇宙的建造，就是神性与人性的调和。我们可以说，那就是神在已过的永远里渴望得着的。在将来的永远，祂要得着这样一个相互的住处。盼望我们众人能对建造有一个新鲜、更新的异象。遗憾地说，今天在基督徒中间，即便是热心的基督徒，也少有人看见并在乎这件事。但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。我们为此被预定、蒙救赎、得重生，我们也为此正在被变化，好成为石头来为着这个建造。所以我们今天要实行召会生活，好在这个时代完成建造的工作。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/4_ts.htm&#39;, &#39;title&#39;: &#39;第四篇&#39;}),
 Document(page_content=&#39;确定的话 定住的光\n启示：主的生命就是人的光。\n经历：正确的教训总是释放生命的光。\n应用：借着传福音和牧养把人带到神圣的光中。\n一句话：出黑暗并进入祂奇妙之光。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/5_h_4.htm&#39;, &#39;title&#39;: &#39;第五周&#39;}),
 Document(page_content=&#39;告诉我不该祷告。相反的，你嘱咐我祷告。因此，主，我现在祷告，求你表白。”……这个比喻的意义很深奥，我们都需要认识这里所启示的神（路加福音生命读经，四○二至四○四页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_5.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;确定的话 定住的光\n启示：“耶和华”的意思是“我是那我是”。\n经历：今天在主的恢复里，我们乃是在应验的阶段。\n应用：当你遭遇试验、试炼和难处时，倚靠耶和华神。\n一句话：你们要称谢耶和华，呼求祂的名。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_2.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;当反对我们的人逼迫我们的时候，我们的神似乎是不义的，因为祂允许祂的儿女遭受不义的逼迫。比方，施浸者约翰被斩，彼得殉道，保罗下监，约翰被放逐。历世历代以来，千千万万诚实、忠信跟从人救主的人都遭受过不义的逼迫，甚至今天我们仍遭受不义的错待。我们的神似乎不公平，因为祂不来审判并表白。\n活神、公义的神在哪里？祂为什么容忍这种光景？祂为什么不审判那些逼迫我们的人？因着这种光景，人救主在路加十八章一至八节用一个不义的审判官，来表征那似乎不为祂受逼迫的子民作些什么的神。……从这比喻我们要学习作个烦扰的寡妇， 一个恒切向神祷告的人（路加福音生命读经，四○一至四○二页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_5.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;当神对某一件事的态度改变时，祂就有一个时代的行动。……神最重要的时代行动是在启示录十二章。祂要结束这个时代，带进国度时代。祂的定旨不是笼统和一般的。祂怎样才能结束这个时代，带进另一个时代？祂必须得着祂时代的凭借（译自《圣洁没有瑕疵》英文版附录）。\n信息选读\n男孩子的被提结束召会时代并引进国度时代。男孩子使神能有所行动。……我们绝不该忘记，神是能被限制的。在祂一切的行动中，祂等候人。神在天上的捆绑是基于我们在地上的捆绑；神在天上的释放是基于我们在地上的释放。每一件事都在于召会。\n作得胜者主要不是为着逃避大灾难。我们需要看见被提对主的价值，不是对我们的价值。\n在所有时代的行动中，男孩子是最大的，因为这除去人的能力和魔鬼的能力，并带进国度。我们活在这时代是最享特权的，我们能为神作得最多。光要使我们看见道路，而力量和能力要使我们能行走这道路。现今要被神使用，就必须付极大的代价。\n神的心意是要受造之物来对付堕落的受造之物。照着祂的定旨，全召会都该对付撒但；然而，召会堕落了……。神的定旨得以在得胜者身上成就，是因为他们与祂同工。……神总是得着一班得胜者，来进行时代的行动。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/7_h_1.htm&#39;, &#39;title&#39;: &#39;第七周&#39;}),
 Document(page_content=&#39;带领的人乃是奴仆\n在神子民中间的领导这件事，非常重大。神对领导的观念，与我们天然的观念迥然不同。我们需要看三处经文：马太二十三章八至十节，希伯来十三章七节和十七节，以及马太二十章二十五至二十八节。乍看之下，马太二十三章和希伯来十三章这两处经文似乎互相矛盾。在马太二十三章八至十节，主说，“但你们不要受拉比的称呼，因为只有一位是你们的夫子，你们都是弟兄；也不要称地上的人为父，因为只有一位是你们的父，就是那天上的；也不要受师尊的称呼，因为只有一位是你们的师尊，就是基督。”主的意思是，没有人是你们的师尊，只有基督是，甚至不该有师尊的称呼，或父的称呼，因为只有一位领头人，就是基督。然而，希伯来十三章七节说，“要记念那些带领你们……的人。”十七节说，“你们要信从那些带领你们的，且要服从。”那么，到底有没有带领的人呢？&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;}),
 Document(page_content=&#39;信息选读\n联结的信使得胜者有资格在基督凯旋回来时与祂相见，这是对得胜者的神圣要求。这是根据路加十八章八节。……今天，整个世界都是不信的。今天不仅在外邦人、异教徒中间，甚至在犹太人、天主教徒、更正教徒和灵恩派的人中间，何处找得到信心？如果主今天来了，祂在哪里找得到信心？地上几乎没有一个人是相信的。但因着祂的怜悯，在已过年间，借着倪弟兄的带领，我们被带进一种光景，学习在凡事上不信靠我们自己，只相信我们的神是一切。\n我盼望主回来时，祂能找到你我都是相信的人，是一直信靠祂，不信靠自己，对自己没有确信的人。我们的确信完全在祂身上。这是联结的信。这信是得胜者的资格，这是神圣的要求，使你我作为得胜者，可以在基督凯旋回来时与祂相见。……最终，主会找到一些人，就是少数的得胜者，他们在主回来时，是凭联结的信而活。……基督盼望找着我们作祂隐藏的得胜者。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_6.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;，在那里进攻，要把基督所建造的召会，拖到死亡里去。但你在那里也看见，召会有权柄，有诸天之国的钥匙，能在那里捆绑天上所捆绑的，释放天上所释放的。召会是有权柄的，召会也是争战而得胜的（李常受文集一九五七年第二册，八七至八八页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_h_3.htm&#39;, &#39;title&#39;: &#39;第九周&#39;}),
 Document(page_content=&#39;信息选读\n这男孩子并不是个人的，乃是团体的。……这团体的男孩子包括作他元首、中心、实际、生命和本质的主耶稣。……诗篇二篇八至九节预言主耶稣，神的受膏者，要用铁杖辖管列国；启示录二章二十六至二十七节说，召会中的得胜者要用铁杖辖管列国；而十二章五节告诉我们，男孩子要用铁杖辖管万国。因此，……主耶稣自己和祂的得胜者都要用铁杖辖管万国。所以，十二章五节的男孩子，包括主耶稣和召会中的得胜者。此外，二十章四节说，基督和复活的得胜者要作王掌权一千年。因此，启示录十二章的男孩子，既不是指个人的主耶稣，也不是指与祂分开的得胜者，乃是指主耶稣连同得胜者。基督自己是头一位得胜者（三21）。祂这位领头的得胜者，乃是众得胜者的元首、中心、实际、生命和本质。在地上属神的人中间，有一部分是刚强的，包括主耶稣和得胜者。因此，男孩子是由主耶稣和祂的得胜者组成的。\n主耶稣是男孩子，却从女人而生。……这件事属灵的意义是说，主耶稣是从信靠神的源头而生。……男孩子的源头是女人，不是男人。……男孩子是信靠神、倚靠神之女人的后裔。主耶稣就是从这样的源头而出的后裔。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/7_h_2.htm&#39;, &#39;title&#39;: &#39;第七周&#39;}),
 Document(page_content=&#39;信息选读\n撒迦利亚四章十二节说到……枝子“流出金”。这里的“金”是指油。油和金乃是一。油是指那灵，那灵乃是神。不仅如此，按预表，金表征神。那充满油碗的金乃是那灵，那灵就是神；神是由金所表征的。我们将这事应用到今天的经历时，就看见从我们里面流出来的那灵就是神，而神就是金。因此，我们将基督供应给别人，用油供应他们的时候，实际上就是用神供应他们。神从我们流出来，流到他们里面。我们都该是橄榄树，从我们自己里面流出神来，流到别人里面（撒迦利亚书生命读经，四一三至四一四页）。\n在出埃及记，灯台是基督作神的具体化身；在新约末了，灯台是众召会作三一神具体化身的繁增。……这灯台只有两个基本元素—金和油。金是具体的形状，油是燃烧的元素。当这二者放在一起，就有灯台照耀，在神的三一里彰显祂，有父的性情和素质、子的形像和样子以及灵的彰显。……撒迦利亚四章十二节告诉我们，灯台的油乃是金油。……召会作为灯台，乃是三一神扎实的具体化身，有七倍的灵作为油。事实上，油的素质就是金的元素。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/4_h_6.htm&#39;, &#39;title&#39;: &#39;第四周&#39;}),
 Document(page_content=&#39;自隐的神默默却强有力地在我们里面运行\n自隐的神默默却强有力地在我们里面运行（腓二13）。这是在我们与主的关系中，一件非常个人的事。“默默”指明不只是隐藏的，更是安静的，甚至是沉默的。我们通常不会将“安静”和“沉默”这二辞，联于有活力的行动。但神的确是默默却强有力地在我们里面运行。神之所以能强有力地运行，指明我们所是的某些部分被主征服、对付、变化了。主在这个内里的争战中征服了我们，祂正在强有力地摸着我们内里核心的部分。这也就是祂对我们美妙的照顾。祂知道我们愿意作敞开的器皿。当我们愿意对祂说，“主啊，我不知道自己的光景如何，也不知道自己需要什么；但是你知道。无论你想要到哪里，摸着什么，求你自己来作。”祂就会进到我们的深处，以一种隐藏的方式来对付那些抵触祂的事物，并以包罗万有的基督来顶替。你自己可能不会察觉，但别人会感觉得到。最近我听见一位中年姊妹在聚会中简短的说话，我里面满了感谢和敬拜。她自己也许没有察觉，但基督从她照耀出来了。隐藏的神在她里面作工，使基督在她里面长大并扩展。这位隐藏的神也正在我们每一位里面默默地作工。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_ts.htm&#39;, &#39;title&#39;: &#39;第十二篇&#39;}),
 Document(page_content=&#39;信息选读\n当〔主的〕恢复是圣别的，我们就会看见主的祝福。在一些地方祝福受到拦阻，原因乃是因着背景而引起的混杂。我们曾多次被定罪，说我们不邀请别人来我们的聚会中说话。我们不是骄傲，但我们的确谨慎。……已过我们曾经试过，却只引起麻烦；所以我们学了功课。这不是说我们狭窄，乃是说，这个恢复是如此纯净、单纯、圣别。我们的确需要以斯拉来作洁净的工作。主不喜欢任何的混杂。在主的创造里，凡物“各从其类”。……我们需要纯净、严谨、单纯并归从我们的种类！我们若是公会，就该单单是公会。我们若是自由团体，就该单单是自由团体。我们不该说我们是别的。我们若是地方召会，就该单单是地方召会。我们必须如此单纯、单一、纯净，真正归从我们的种类。我们必须是绝对的。主从不尊重任何的混杂，必须是各从其类。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_h_1.htm&#39;, &#39;title&#39;: &#39;第六周&#39;}),
 Document(page_content=&#39;保罗在以弗所六章十二节也提到“诸天界里那邪恶的属灵势力”。这里的诸天界，指空中（二2）。撒但和他邪恶的属灵势力是在空中；但我们是坐在第三层天上，超过他们（6）。打仗的时候，凌驾仇敌之上的地位，在战略上是非常重要的。撒但和他邪恶的势力是在我们之下，他们注定是要被击败的。\n我们的争战不是抵挡人，乃是抵挡邪灵，就是诸天界里的属灵势力。背叛的天使是撒但国度里的邪灵。因此，召会和撒但之间的争战，乃是我们这些爱主并在祂召会中的人，抵挡诸天界里邪恶势力的争战。表面看是血肉之人破坏召会，实际上是撒但和他邪恶的天使在那些造成破坏的人背后作工。所以，我们必须争战，抵挡这些属灵的势力（以弗所书生命读经，六四二至六四三页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_h_4.htm&#39;, &#39;title&#39;: &#39;第九周&#39;}),
 Document(page_content=&#39;第二周\u3000周二\n晨兴喂养\n代上十六8\u3000你们要称谢耶和华，呼求祂的名，在万民中传扬祂的作为。\n出三14\u3000神对摩西说，我是那我是；又说，你要对以色列人这样说，那我是差我到你们这里来。\n神是普通的名字，耶和华是亲近的名字。神是指着神的能力说的，耶和华是指着神的爱心说的。神是指着创造方面说的，耶和华是指着神的亲近说的。创世记一章没有耶和华。因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。二章是神和人亲密，有了关系，所以说耶和华神。……这……证明二章的耶和华，就是一章里的神。耶和华神不只是有能力的，也是和人亲近的（倪柝声文集第一辑第九册，六四页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_2.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;对付灵并不是对付灵的本身，乃是对付灵的经过，也就是对付我们的存心、动机、目的、用意等等。我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。\n信息选读\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。……对付灵，乃是重在对付我们里面不纯的存心、动机等杂质；而对付良心，乃是重在对付良心对那些杂质的感觉。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_h_2.htm&#39;, &#39;title&#39;: &#39;第六周&#39;}),
 Document(page_content=&#39;我们所要注意的是第三—我们怎样把神的旨意回头祷告神。……一切有价值的祷告都是回头的。如果我们的祷告只是为要成功我们所打算、所盼望的，这在属灵的世界中是没有多大价值的。必须是从神起头，我们响应，这才是有价值的祷告。神的工作是被这样的祷告所支配的。多少事，神愿意作，但是因为神的子民不祷告的缘故，祂宁可不作。神必须等人同意以后祂才去作，这是神作工的一个大原则，是圣经中最要紧的原则之一。\n当神创造人的时候，就给人有一个自由意志。这样，在宇宙之中就有了三个不同的意志：一个是神的意志，一个是仇敌撒但的意志，一个就是人的意志。按着人的想法，神为什么不在一分钟之内把撒但消灭了。但是神没有这样作。神要与人合起来去对付撒但。神有神的意志，撒但有撒但的意志，人也有人的意志。神就是要得着人的意志与祂合起来。……神不单独作，神要人与祂合作。这就是召会在地上的责任。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_5.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;撒迦利亚九章九节……启示基督将要公义地带着给我们的救恩而来，并且祂要骑着驴，甚至骑着驴驹而来。这一节在四福音，在耶稣基督末次进入耶路撒冷时得了应验。祂来作王，乃是卑微的王、降卑的王，不是骑着骏马，乃是骑着驴驹（撒迦利亚书生命读经，四五五、四四○页）。\n信息选读\n撒迦利亚十一章十二至十三节启示，弥赛亚这位以色列合式的牧人被憎嫌、攻击、弃绝，并以三十锭银子，就是以一个奴仆的价值（出二一32）被卖。这里所预言的，在福音书里得着应验。主耶稣在罗马帝国统治的时候被卖，又为罗马的官长所审判。……撒迦利亚十一章十二节说，“我对他们说，你们若以为美，就给我工价；……于是他们称了三十锭银子作为我的工价。”这清楚指明基督被憎嫌、攻击、弃绝并被卖。我们若要明白这……经文，并要知道谁给了银子，谁将银子丢在耶和华的殿中（13），就需要研读四福音书。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_2.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;“战兢”与“不忠信”\n我要强调两个辞。第一个辞是“战兢”。以赛亚六十六章一至二节说，“耶和华如此说，天是我的座位，地是我的脚凳；你们要在哪里为我建造殿宇？哪里是我安息的地方？……但我所看顾的，就是灵里贫穷痛悔、因我话战兢的人。”通常没有太多人留意到“战兢”这辞。我们多数时候强调要享受主的话，要吃主的话。的确，我们要恢复吃主的话。然而，圣经也告诉我们要惧怕神的话，因主的话战兢。我们来到主的话前，应当有一种郑重、认真的态度，甚至带着敬畏来接受主的话。我们要在主的话前谦卑自己。我们的回应，应当能配得上主的话。\n原谅我说，现今在神的子民中间，有一种错误的思想，以为圣经里有些话只是为着古时，今天已经不合时宜。我要告诉圣徒们：神的话是永远的。我们需要享受，我们需要吃，但我们也需要重看神的话，敬重神的话，我们要对主的话举起手说阿们，正如诗篇一百一十九篇四十八节所说的：“我要向你的诫命举手。”我们需要因主的话战兢。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_ts.htm&#39;, &#39;title&#39;: &#39;第六篇&#39;}),
 Document(page_content=&#39;请记得，每一位圣徒都是一个“小新耶路撒冷”。这意思是，在我们全人的中心，该有神和羔羊的宝座。我们要如何行事或生活，不该凭自己作决定，也不必凭自己作决定，因为在我们里面有宝座。我们在日常生活中该操练自己，在每件事上服从里面的宝座。启示录二十二章一节说，“城内街道当中一道生命水的河，明亮如水晶，从神和羔羊的宝座流出来。”如果我们在宝座的管制之下，就会得着生命水河的滋润和供应。我们如果拒绝宝座的管制，这道生命水的流就会停止。相信我们都曾有这样的经历，因为我们每一个人都是一个小新耶路撒冷。二节说，“在河这边与那边有生命树。”这宝座在我们全人的中心该是得胜的，然后生命水就会从宝座流出来供应我们，并将生命树带给我们，终日滋养我们。圣城的街道是纯金（二一21），金象征神圣的性情。有时我们会发觉里面生命的供应停止了，这是因为我们没有活在神圣的性情里。在新耶路撒冷里，只有一条纯金的街道。我们应该行走在其中，以神圣的性情为我们的道路。这神圣的性情是在我们的灵里，并且要从我们的灵往外扩展到我们全人的三部分。神圣的性情里有一种自然而然的本能，使我们摸到世俗的、不圣别的事物时，会觉得不对劲；神圣的性情会拒绝这些事物。另一面，我们若走在&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/11_ts.htm&#39;, &#39;title&#39;: &#39;第十一篇&#39;}),
 Document(page_content=&#39;第一周\u3000周六\n晨兴喂养\n亚十二1\u3000耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说。\n十8\u3000我要向他们发哨声，聚集他们，因我已经救赎他们；他们的人数必增多，如从前增多一样。\n诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一。何等奇妙，在旧约这卷揭示基督与人类历史和政治息息相关的书里，有这样的一节〔亚十二1〕。这指明在神的经纶里，神计划要使基督作祂在地上行动的中心与普及。祂是神，几千年来，在一个接一个的世代中，一直掌管全人类，管理世界的局势。为使祂所拣选的人能关心祂这位创造主并救赎主，祂需要为人创造一个接受的器官，使人能接受神计划里之基督一切的所是。基督是奇妙的，但我们若没有灵，怎能接受祂？……我们若忽略我们人的灵，就没有路可以接触神了（撒迦利亚书生命读经，四五六页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_6.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;撒迦利亚十二章一节说，“耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说”\n撒迦利亚十二章一节说，“耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说。”这里所说的，乃是关系到人类历史中的神圣历史。\n神在祂的创造里，造了三样极其关键、同等重要的东西—诸天、地和人的灵；诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一\n神在祂的创造里，造了三样极其关键、同等重要的东西—诸天、地和人的灵。诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一（1）。神给我们造了一个灵。因为祂是灵，如今我们能用我们的灵质实祂。我们能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一。\n人里面的中央政府并最重要的部分应当是他的灵；一个受他的灵管治并支配的人就是属灵的人&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;五十二年过去了，至今我一点也不懊悔。在这五十二年中，我看见故事一再重演，人来了又去了，一幕又一幕。从台湾岛上的工作开始至今，三十几年中有几次重大的事情发生，甚至我带得救、一手造就出来的弟兄，也离开了主的恢复。异象不变，但人会变，跟从人的也会变。所以我愿语重心长地劝勉诸位：我蒙主怜悯，今天能在这里，把这个异象带给你们；我乃是盼望你们跟随的，不是我这个人，而是我蒙主怜悯所给你们看见的这异象。\n我只告诉你们一个事实，是主怜悯我，启示给我看见异象。所以我劝你们，不要跟随我，乃要跟随我蒙主怜悯，承继倪弟兄和历代主的仆人所留下，传承给你们看见的这个异象。这实在是从亚当头一幕的异象，直到新耶路撒冷末了一幕的异象（五一至五四页）。\n在这段话里我们实在看见主仆人的纯洁；他不要我们跟随他这个人，乃要我们跟随时代的异象。我们的“清明上河图”是从亚当和生命树开始，一路延展到新耶路撒冷。我们需要看见整幅图画，这异象就是主恢复里的领导。当你有了这样宽广的异象，你还能到哪里去？这异象约束我们生活的每一面，包括我们的事奉、行动、家庭生活和召会生活。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;})]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;七倍加强的灵是什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get context related to the question from the embedding model</span>
<span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[Document(page_content=&#39;神在人里之行动的五个步骤&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;第十篇\n历代志、以斯拉记、尼希米记、以斯帖记结晶读经\n第十篇\u3000以斯拉记和尼希米记这两卷恢复的书中心并重要的点—主恢复中正确并适当的领导\n调速 \u3000\n本篇信息，我们来到另一个结晶，题目是“以斯拉记和尼希米记这两卷恢复的书中心并重要的点—主恢复中正确并适当的领导”。许多人可能对以斯拉记和尼希米记有这样的结晶，感到意外。相信很少有人能读出这两卷书中心并重要的点，是主恢复中正确并适当的领导。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;}),
 Document(page_content=&#39;因为这爱是在基督里、同着基督、借着基督并为着基督的。”神在人里之行动的五个步骤，就是这“慈绳”（人的绳）；每一步骤都与基督的人性有关。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;经历：属灵人乃是一个受他的灵管治并支配的人。\n应用：我们需要操练灵，全心转向主。\n一句话：基督乃是神经纶的中心与普及。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_6.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;以赛亚为什么会得到这一个结论？又怎么根据这一个结论，而有了这一个说法？如果你把整卷以赛亚书都读过，你就能读出那一个原因。那是因为神在以色列人中间，在以色列人身上，作了许许多多的事，但神却把自己藏在一边，藏在以色列人的旁边，藏在以色列人的背后。不错，祂是一直在那里作事，但另一面祂却一直把自己隐藏起来。一大堆的事都是祂作的，但以色列人却看不出来那一位作这些事者到底是谁。所以当申言者以赛亚发现了这件事，他就在那里说，“……你实在是自隐的神。”&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_1.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;因着己是最大的仇敌，所以我们需要经历神话语的杀死能力。当我们祷读时，我们一面得着滋养，一面某些元素就被杀死。也许你受到疑惑、忌恨、嫉妒、骄傲以及自私的困扰。你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。借着祷读，里面的对头就被除灭。我们祷读主话一段时间后，就会发觉攻击我们的对头消失了。就着非常实际的意义说，我们的对头被接受到我们里面的话杀死了。\n在以弗所五章，话是为着滋养，使新妇美丽。但在六章，话是为着杀死，使召会能作团体的战士，从事属灵的争战（以弗所书生命读经，九八一、九八八、九九○页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_5.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;第九篇\n历代志、以斯拉记、尼希米记、以斯帖记结晶读经\n第九篇\u3000建造与争战—为着召会的建造，需要从事属灵的争战\n调速 \u3000\n本篇信息的篇题是“建造与争战—为着召会的建造，需要从事属灵的争战”。这信息是直接向着基督团体的身体，然后间接向着基督身体上所有肢体说的。属灵的争战乃是基督身体的事，我们必须在身体里争战。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_ts.htm&#39;, &#39;title&#39;: &#39;第九篇&#39;}),
 Document(page_content=&#39;圣经的最后两章讲到这个宇宙的建造，就是神性与人性的调和。我们可以说，那就是神在已过的永远里渴望得着的。在将来的永远，祂要得着这样一个相互的住处。盼望我们众人能对建造有一个新鲜、更新的异象。遗憾地说，今天在基督徒中间，即便是热心的基督徒，也少有人看见并在乎这件事。但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。我们为此被预定、蒙救赎、得重生，我们也为此正在被变化，好成为石头来为着这个建造。所以我们今天要实行召会生活，好在这个时代完成建造的工作。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/4_ts.htm&#39;, &#39;title&#39;: &#39;第四篇&#39;}),
 Document(page_content=&#39;确定的话 定住的光\n启示：主的生命就是人的光。\n经历：正确的教训总是释放生命的光。\n应用：借着传福音和牧养把人带到神圣的光中。\n一句话：出黑暗并进入祂奇妙之光。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/5_h_4.htm&#39;, &#39;title&#39;: &#39;第五周&#39;}),
 Document(page_content=&#39;告诉我不该祷告。相反的，你嘱咐我祷告。因此，主，我现在祷告，求你表白。”……这个比喻的意义很深奥，我们都需要认识这里所启示的神（路加福音生命读经，四○二至四○四页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_5.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;确定的话 定住的光\n启示：“耶和华”的意思是“我是那我是”。\n经历：今天在主的恢复里，我们乃是在应验的阶段。\n应用：当你遭遇试验、试炼和难处时，倚靠耶和华神。\n一句话：你们要称谢耶和华，呼求祂的名。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_2.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;当反对我们的人逼迫我们的时候，我们的神似乎是不义的，因为祂允许祂的儿女遭受不义的逼迫。比方，施浸者约翰被斩，彼得殉道，保罗下监，约翰被放逐。历世历代以来，千千万万诚实、忠信跟从人救主的人都遭受过不义的逼迫，甚至今天我们仍遭受不义的错待。我们的神似乎不公平，因为祂不来审判并表白。\n活神、公义的神在哪里？祂为什么容忍这种光景？祂为什么不审判那些逼迫我们的人？因着这种光景，人救主在路加十八章一至八节用一个不义的审判官，来表征那似乎不为祂受逼迫的子民作些什么的神。……从这比喻我们要学习作个烦扰的寡妇， 一个恒切向神祷告的人（路加福音生命读经，四○一至四○二页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_5.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;当神对某一件事的态度改变时，祂就有一个时代的行动。……神最重要的时代行动是在启示录十二章。祂要结束这个时代，带进国度时代。祂的定旨不是笼统和一般的。祂怎样才能结束这个时代，带进另一个时代？祂必须得着祂时代的凭借（译自《圣洁没有瑕疵》英文版附录）。\n信息选读\n男孩子的被提结束召会时代并引进国度时代。男孩子使神能有所行动。……我们绝不该忘记，神是能被限制的。在祂一切的行动中，祂等候人。神在天上的捆绑是基于我们在地上的捆绑；神在天上的释放是基于我们在地上的释放。每一件事都在于召会。\n作得胜者主要不是为着逃避大灾难。我们需要看见被提对主的价值，不是对我们的价值。\n在所有时代的行动中，男孩子是最大的，因为这除去人的能力和魔鬼的能力，并带进国度。我们活在这时代是最享特权的，我们能为神作得最多。光要使我们看见道路，而力量和能力要使我们能行走这道路。现今要被神使用，就必须付极大的代价。\n神的心意是要受造之物来对付堕落的受造之物。照着祂的定旨，全召会都该对付撒但；然而，召会堕落了……。神的定旨得以在得胜者身上成就，是因为他们与祂同工。……神总是得着一班得胜者，来进行时代的行动。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/7_h_1.htm&#39;, &#39;title&#39;: &#39;第七周&#39;}),
 Document(page_content=&#39;带领的人乃是奴仆\n在神子民中间的领导这件事，非常重大。神对领导的观念，与我们天然的观念迥然不同。我们需要看三处经文：马太二十三章八至十节，希伯来十三章七节和十七节，以及马太二十章二十五至二十八节。乍看之下，马太二十三章和希伯来十三章这两处经文似乎互相矛盾。在马太二十三章八至十节，主说，“但你们不要受拉比的称呼，因为只有一位是你们的夫子，你们都是弟兄；也不要称地上的人为父，因为只有一位是你们的父，就是那天上的；也不要受师尊的称呼，因为只有一位是你们的师尊，就是基督。”主的意思是，没有人是你们的师尊，只有基督是，甚至不该有师尊的称呼，或父的称呼，因为只有一位领头人，就是基督。然而，希伯来十三章七节说，“要记念那些带领你们……的人。”十七节说，“你们要信从那些带领你们的，且要服从。”那么，到底有没有带领的人呢？&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;}),
 Document(page_content=&#39;信息选读\n联结的信使得胜者有资格在基督凯旋回来时与祂相见，这是对得胜者的神圣要求。这是根据路加十八章八节。……今天，整个世界都是不信的。今天不仅在外邦人、异教徒中间，甚至在犹太人、天主教徒、更正教徒和灵恩派的人中间，何处找得到信心？如果主今天来了，祂在哪里找得到信心？地上几乎没有一个人是相信的。但因着祂的怜悯，在已过年间，借着倪弟兄的带领，我们被带进一种光景，学习在凡事上不信靠我们自己，只相信我们的神是一切。\n我盼望主回来时，祂能找到你我都是相信的人，是一直信靠祂，不信靠自己，对自己没有确信的人。我们的确信完全在祂身上。这是联结的信。这信是得胜者的资格，这是神圣的要求，使你我作为得胜者，可以在基督凯旋回来时与祂相见。……最终，主会找到一些人，就是少数的得胜者，他们在主回来时，是凭联结的信而活。……基督盼望找着我们作祂隐藏的得胜者。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_h_6.htm&#39;, &#39;title&#39;: &#39;第十二周&#39;}),
 Document(page_content=&#39;，在那里进攻，要把基督所建造的召会，拖到死亡里去。但你在那里也看见，召会有权柄，有诸天之国的钥匙，能在那里捆绑天上所捆绑的，释放天上所释放的。召会是有权柄的，召会也是争战而得胜的（李常受文集一九五七年第二册，八七至八八页）。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_h_3.htm&#39;, &#39;title&#39;: &#39;第九周&#39;}),
 Document(page_content=&#39;信息选读\n这男孩子并不是个人的，乃是团体的。……这团体的男孩子包括作他元首、中心、实际、生命和本质的主耶稣。……诗篇二篇八至九节预言主耶稣，神的受膏者，要用铁杖辖管列国；启示录二章二十六至二十七节说，召会中的得胜者要用铁杖辖管列国；而十二章五节告诉我们，男孩子要用铁杖辖管万国。因此，……主耶稣自己和祂的得胜者都要用铁杖辖管万国。所以，十二章五节的男孩子，包括主耶稣和召会中的得胜者。此外，二十章四节说，基督和复活的得胜者要作王掌权一千年。因此，启示录十二章的男孩子，既不是指个人的主耶稣，也不是指与祂分开的得胜者，乃是指主耶稣连同得胜者。基督自己是头一位得胜者（三21）。祂这位领头的得胜者，乃是众得胜者的元首、中心、实际、生命和本质。在地上属神的人中间，有一部分是刚强的，包括主耶稣和得胜者。因此，男孩子是由主耶稣和祂的得胜者组成的。\n主耶稣是男孩子，却从女人而生。……这件事属灵的意义是说，主耶稣是从信靠神的源头而生。……男孩子的源头是女人，不是男人。……男孩子是信靠神、倚靠神之女人的后裔。主耶稣就是从这样的源头而出的后裔。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/7_h_2.htm&#39;, &#39;title&#39;: &#39;第七周&#39;}),
 Document(page_content=&#39;信息选读\n撒迦利亚四章十二节说到……枝子“流出金”。这里的“金”是指油。油和金乃是一。油是指那灵，那灵乃是神。不仅如此，按预表，金表征神。那充满油碗的金乃是那灵，那灵就是神；神是由金所表征的。我们将这事应用到今天的经历时，就看见从我们里面流出来的那灵就是神，而神就是金。因此，我们将基督供应给别人，用油供应他们的时候，实际上就是用神供应他们。神从我们流出来，流到他们里面。我们都该是橄榄树，从我们自己里面流出神来，流到别人里面（撒迦利亚书生命读经，四一三至四一四页）。\n在出埃及记，灯台是基督作神的具体化身；在新约末了，灯台是众召会作三一神具体化身的繁增。……这灯台只有两个基本元素—金和油。金是具体的形状，油是燃烧的元素。当这二者放在一起，就有灯台照耀，在神的三一里彰显祂，有父的性情和素质、子的形像和样子以及灵的彰显。……撒迦利亚四章十二节告诉我们，灯台的油乃是金油。……召会作为灯台，乃是三一神扎实的具体化身，有七倍的灵作为油。事实上，油的素质就是金的元素。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/4_h_6.htm&#39;, &#39;title&#39;: &#39;第四周&#39;}),
 Document(page_content=&#39;自隐的神默默却强有力地在我们里面运行\n自隐的神默默却强有力地在我们里面运行（腓二13）。这是在我们与主的关系中，一件非常个人的事。“默默”指明不只是隐藏的，更是安静的，甚至是沉默的。我们通常不会将“安静”和“沉默”这二辞，联于有活力的行动。但神的确是默默却强有力地在我们里面运行。神之所以能强有力地运行，指明我们所是的某些部分被主征服、对付、变化了。主在这个内里的争战中征服了我们，祂正在强有力地摸着我们内里核心的部分。这也就是祂对我们美妙的照顾。祂知道我们愿意作敞开的器皿。当我们愿意对祂说，“主啊，我不知道自己的光景如何，也不知道自己需要什么；但是你知道。无论你想要到哪里，摸着什么，求你自己来作。”祂就会进到我们的深处，以一种隐藏的方式来对付那些抵触祂的事物，并以包罗万有的基督来顶替。你自己可能不会察觉，但别人会感觉得到。最近我听见一位中年姊妹在聚会中简短的说话，我里面满了感谢和敬拜。她自己也许没有察觉，但基督从她照耀出来了。隐藏的神在她里面作工，使基督在她里面长大并扩展。这位隐藏的神也正在我们每一位里面默默地作工。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/12_ts.htm&#39;, &#39;title&#39;: &#39;第十二篇&#39;}),
 Document(page_content=&#39;信息选读\n当〔主的〕恢复是圣别的，我们就会看见主的祝福。在一些地方祝福受到拦阻，原因乃是因着背景而引起的混杂。我们曾多次被定罪，说我们不邀请别人来我们的聚会中说话。我们不是骄傲，但我们的确谨慎。……已过我们曾经试过，却只引起麻烦；所以我们学了功课。这不是说我们狭窄，乃是说，这个恢复是如此纯净、单纯、圣别。我们的确需要以斯拉来作洁净的工作。主不喜欢任何的混杂。在主的创造里，凡物“各从其类”。……我们需要纯净、严谨、单纯并归从我们的种类！我们若是公会，就该单单是公会。我们若是自由团体，就该单单是自由团体。我们不该说我们是别的。我们若是地方召会，就该单单是地方召会。我们必须如此单纯、单一、纯净，真正归从我们的种类。我们必须是绝对的。主从不尊重任何的混杂，必须是各从其类。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_h_1.htm&#39;, &#39;title&#39;: &#39;第六周&#39;}),
 Document(page_content=&#39;保罗在以弗所六章十二节也提到“诸天界里那邪恶的属灵势力”。这里的诸天界，指空中（二2）。撒但和他邪恶的属灵势力是在空中；但我们是坐在第三层天上，超过他们（6）。打仗的时候，凌驾仇敌之上的地位，在战略上是非常重要的。撒但和他邪恶的势力是在我们之下，他们注定是要被击败的。\n我们的争战不是抵挡人，乃是抵挡邪灵，就是诸天界里的属灵势力。背叛的天使是撒但国度里的邪灵。因此，召会和撒但之间的争战，乃是我们这些爱主并在祂召会中的人，抵挡诸天界里邪恶势力的争战。表面看是血肉之人破坏召会，实际上是撒但和他邪恶的天使在那些造成破坏的人背后作工。所以，我们必须争战，抵挡这些属灵的势力（以弗所书生命读经，六四二至六四三页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/9_h_4.htm&#39;, &#39;title&#39;: &#39;第九周&#39;}),
 Document(page_content=&#39;第二周\u3000周二\n晨兴喂养\n代上十六8\u3000你们要称谢耶和华，呼求祂的名，在万民中传扬祂的作为。\n出三14\u3000神对摩西说，我是那我是；又说，你要对以色列人这样说，那我是差我到你们这里来。\n神是普通的名字，耶和华是亲近的名字。神是指着神的能力说的，耶和华是指着神的爱心说的。神是指着创造方面说的，耶和华是指着神的亲近说的。创世记一章没有耶和华。因为是讲关乎创造方面的事，就是一章里提到人，也是关乎创造方面、能力方面的。二章是神和人亲密，有了关系，所以说耶和华神。……这……证明二章的耶和华，就是一章里的神。耶和华神不只是有能力的，也是和人亲近的（倪柝声文集第一辑第九册，六四页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_2.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;对付灵并不是对付灵的本身，乃是对付灵的经过，也就是对付我们的存心、动机、目的、用意等等。我们每有一个行动，或者要说一句话，不只要问对不对，好不好，还要追查里面的存心清洁么？动机单纯么？目的专为着神么？有什么自私的用意么？有我们自己的倾向么？（李常受文集一九五三年第三册，六一四至六一六、六一九页）。\n信息选读\n我们……还要进一步的，把一切不好的存心，不该有的用意，不单纯的倾向，不正当的意志，有搀杂的情感等等，也都对付干净，然后灵才不只能出来，并且出来了，还能是正直的、纯净的。……对付灵，乃是重在对付我们里面不纯的存心、动机等杂质；而对付良心，乃是重在对付良心对那些杂质的感觉。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_h_2.htm&#39;, &#39;title&#39;: &#39;第六周&#39;}),
 Document(page_content=&#39;我们所要注意的是第三—我们怎样把神的旨意回头祷告神。……一切有价值的祷告都是回头的。如果我们的祷告只是为要成功我们所打算、所盼望的，这在属灵的世界中是没有多大价值的。必须是从神起头，我们响应，这才是有价值的祷告。神的工作是被这样的祷告所支配的。多少事，神愿意作，但是因为神的子民不祷告的缘故，祂宁可不作。神必须等人同意以后祂才去作，这是神作工的一个大原则，是圣经中最要紧的原则之一。\n当神创造人的时候，就给人有一个自由意志。这样，在宇宙之中就有了三个不同的意志：一个是神的意志，一个是仇敌撒但的意志，一个就是人的意志。按着人的想法，神为什么不在一分钟之内把撒但消灭了。但是神没有这样作。神要与人合起来去对付撒但。神有神的意志，撒但有撒但的意志，人也有人的意志。神就是要得着人的意志与祂合起来。……神不单独作，神要人与祂合作。这就是召会在地上的责任。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/2_h_5.htm&#39;, &#39;title&#39;: &#39;第二周&#39;}),
 Document(page_content=&#39;撒迦利亚九章九节……启示基督将要公义地带着给我们的救恩而来，并且祂要骑着驴，甚至骑着驴驹而来。这一节在四福音，在耶稣基督末次进入耶路撒冷时得了应验。祂来作王，乃是卑微的王、降卑的王，不是骑着骏马，乃是骑着驴驹（撒迦利亚书生命读经，四五五、四四○页）。\n信息选读\n撒迦利亚十一章十二至十三节启示，弥赛亚这位以色列合式的牧人被憎嫌、攻击、弃绝，并以三十锭银子，就是以一个奴仆的价值（出二一32）被卖。这里所预言的，在福音书里得着应验。主耶稣在罗马帝国统治的时候被卖，又为罗马的官长所审判。……撒迦利亚十一章十二节说，“我对他们说，你们若以为美，就给我工价；……于是他们称了三十锭银子作为我的工价。”这清楚指明基督被憎嫌、攻击、弃绝并被卖。我们若要明白这……经文，并要知道谁给了银子，谁将银子丢在耶和华的殿中（13），就需要研读四福音书。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_2.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;“战兢”与“不忠信”\n我要强调两个辞。第一个辞是“战兢”。以赛亚六十六章一至二节说，“耶和华如此说，天是我的座位，地是我的脚凳；你们要在哪里为我建造殿宇？哪里是我安息的地方？……但我所看顾的，就是灵里贫穷痛悔、因我话战兢的人。”通常没有太多人留意到“战兢”这辞。我们多数时候强调要享受主的话，要吃主的话。的确，我们要恢复吃主的话。然而，圣经也告诉我们要惧怕神的话，因主的话战兢。我们来到主的话前，应当有一种郑重、认真的态度，甚至带着敬畏来接受主的话。我们要在主的话前谦卑自己。我们的回应，应当能配得上主的话。\n原谅我说，现今在神的子民中间，有一种错误的思想，以为圣经里有些话只是为着古时，今天已经不合时宜。我要告诉圣徒们：神的话是永远的。我们需要享受，我们需要吃，但我们也需要重看神的话，敬重神的话，我们要对主的话举起手说阿们，正如诗篇一百一十九篇四十八节所说的：“我要向你的诫命举手。”我们需要因主的话战兢。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/6_ts.htm&#39;, &#39;title&#39;: &#39;第六篇&#39;}),
 Document(page_content=&#39;请记得，每一位圣徒都是一个“小新耶路撒冷”。这意思是，在我们全人的中心，该有神和羔羊的宝座。我们要如何行事或生活，不该凭自己作决定，也不必凭自己作决定，因为在我们里面有宝座。我们在日常生活中该操练自己，在每件事上服从里面的宝座。启示录二十二章一节说，“城内街道当中一道生命水的河，明亮如水晶，从神和羔羊的宝座流出来。”如果我们在宝座的管制之下，就会得着生命水河的滋润和供应。我们如果拒绝宝座的管制，这道生命水的流就会停止。相信我们都曾有这样的经历，因为我们每一个人都是一个小新耶路撒冷。二节说，“在河这边与那边有生命树。”这宝座在我们全人的中心该是得胜的，然后生命水就会从宝座流出来供应我们，并将生命树带给我们，终日滋养我们。圣城的街道是纯金（二一21），金象征神圣的性情。有时我们会发觉里面生命的供应停止了，这是因为我们没有活在神圣的性情里。在新耶路撒冷里，只有一条纯金的街道。我们应该行走在其中，以神圣的性情为我们的道路。这神圣的性情是在我们的灵里，并且要从我们的灵往外扩展到我们全人的三部分。神圣的性情里有一种自然而然的本能，使我们摸到世俗的、不圣别的事物时，会觉得不对劲；神圣的性情会拒绝这些事物。另一面，我们若走在&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/11_ts.htm&#39;, &#39;title&#39;: &#39;第十一篇&#39;}),
 Document(page_content=&#39;第一周\u3000周六\n晨兴喂养\n亚十二1\u3000耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说。\n十8\u3000我要向他们发哨声，聚集他们，因我已经救赎他们；他们的人数必增多，如从前增多一样。\n诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一。何等奇妙，在旧约这卷揭示基督与人类历史和政治息息相关的书里，有这样的一节〔亚十二1〕。这指明在神的经纶里，神计划要使基督作祂在地上行动的中心与普及。祂是神，几千年来，在一个接一个的世代中，一直掌管全人类，管理世界的局势。为使祂所拣选的人能关心祂这位创造主并救赎主，祂需要为人创造一个接受的器官，使人能接受神计划里之基督一切的所是。基督是奇妙的，但我们若没有灵，怎能接受祂？……我们若忽略我们人的灵，就没有路可以接触神了（撒迦利亚书生命读经，四五六页）。\n信息选读&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_h_6.htm&#39;, &#39;title&#39;: &#39;第一周&#39;}),
 Document(page_content=&#39;撒迦利亚十二章一节说，“耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说”\n撒迦利亚十二章一节说，“耶和华论以色列之话语的默示。铺张诸天、建立地基、造人里面之灵的耶和华说。”这里所说的，乃是关系到人类历史中的神圣历史。\n神在祂的创造里，造了三样极其关键、同等重要的东西—诸天、地和人的灵；诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一\n神在祂的创造里，造了三样极其关键、同等重要的东西—诸天、地和人的灵。诸天是为着地，地是为着人，神给人造了灵，使人能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一（1）。神给我们造了一个灵。因为祂是灵，如今我们能用我们的灵质实祂。我们能接触神，接受神，敬拜神，活神，为神完成神的定旨，并与神成为一。\n人里面的中央政府并最重要的部分应当是他的灵；一个受他的灵管治并支配的人就是属灵的人&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/1_ts.htm&#39;, &#39;title&#39;: &#39;第一篇&#39;}),
 Document(page_content=&#39;五十二年过去了，至今我一点也不懊悔。在这五十二年中，我看见故事一再重演，人来了又去了，一幕又一幕。从台湾岛上的工作开始至今，三十几年中有几次重大的事情发生，甚至我带得救、一手造就出来的弟兄，也离开了主的恢复。异象不变，但人会变，跟从人的也会变。所以我愿语重心长地劝勉诸位：我蒙主怜悯，今天能在这里，把这个异象带给你们；我乃是盼望你们跟随的，不是我这个人，而是我蒙主怜悯所给你们看见的这异象。\n我只告诉你们一个事实，是主怜悯我，启示给我看见异象。所以我劝你们，不要跟随我，乃要跟随我蒙主怜悯，承继倪弟兄和历代主的仆人所留下，传承给你们看见的这个异象。这实在是从亚当头一幕的异象，直到新耶路撒冷末了一幕的异象（五一至五四页）。\n在这段话里我们实在看见主仆人的纯洁；他不要我们跟随他这个人，乃要我们跟随时代的异象。我们的“清明上河图”是从亚当和生命树开始，一路延展到新耶路撒冷。我们需要看见整幅图画，这异象就是主恢复里的领导。当你有了这样宽广的异象，你还能到哪里去？这异象约束我们生活的每一面，包括我们的事奉、行动、家庭生活和召会生活。&#39;, metadata={&#39;source&#39;: &#39;_morning/htm/ailingmusheng.ren/7/2022djth/10_ts.htm&#39;, &#39;title&#39;: &#39;第十篇&#39;})]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Mock OpenAI</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">revChatGPT.V1</span> <span class="kn">import</span> <span class="n">Chatbot</span><span class="p">,</span> <span class="n">configure</span>

<span class="c1"># open the JSON file and read the conversation_id</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/.config/revChatGPT/config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;conversation_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">bot</span> <span class="o">=</span> <span class="n">Chatbot</span><span class="p">(</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">configure</span><span class="p">(),</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="n">conversation_id</span><span class="p">,</span>
    <span class="n">lazy_loading</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">attrdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">attributize</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Add attributes to a dictionary and its sub-dictionaries.&#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
            <span class="n">obj</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">attributize</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">attrdict</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">attributize</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">obj</span>

<span class="k">def</span> <span class="nf">delta</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">attributize</span><span class="p">({</span>
            <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="s1">&#39;delta&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">):],</span>
                    <span class="p">}</span>
                <span class="p">}</span>
            <span class="p">],</span>
        <span class="p">})</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">mock_create</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">summarized_prompt</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;messages&#39;</span><span class="p">]:</span>
        <span class="n">summarized_prompt</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">message</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">:</span><span class="se">\n\n</span><span class="si">{</span><span class="n">message</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n\n\n</span><span class="s2">&quot;</span>
    <span class="n">summarized_prompt</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;stream&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">delta</span><span class="p">(</span><span class="n">summarized_prompt</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="n">summarized_prompt</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">return</span> <span class="n">attributize</span><span class="p">({</span>
        <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;finish_reason&#39;</span><span class="p">:</span> <span class="s1">&#39;stop&#39;</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;message&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;assistant&#39;</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">],</span>
    <span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span><span class="o">,</span> <span class="nn">pytest</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">mock_openai</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="p">,</span> <span class="s1">&#39;create&#39;</span><span class="p">,</span> <span class="n">mock_create</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>QA with Similarity Searching</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="n">CONDENSE_QUESTION_PROMPT</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;chat_history&#39;</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">],</span>
    <span class="n">output_parser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partial_variables</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">template</span><span class="o">=</span><span class="s1">&#39;给定以下对话和后续问题，请重新表述后续问题以成为一个独立问题。</span><span class="se">\n\n</span><span class="s1">聊天记录：</span><span class="se">\n</span><span class="si">{chat_history}</span><span class="se">\n</span><span class="s1">后续问题：</span><span class="si">{question}</span><span class="se">\n</span><span class="s1">独立问题：&#39;</span><span class="p">,</span>
    <span class="n">template_format</span><span class="o">=</span><span class="s1">&#39;f-string&#39;</span><span class="p">,</span>
    <span class="n">validate_template</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">QA_PROMPT</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">],</span>
    <span class="n">output_parser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partial_variables</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">template</span><span class="o">=</span><span class="s1">&#39;使用下面的背景信息回答最后的问题。如果您不知道答案，请直接说您不知道，不要试图编造一个答案。</span><span class="se">\n\n</span><span class="s1">背景信息：</span><span class="se">\n</span><span class="si">{context}</span><span class="se">\n\n</span><span class="s1">问题：</span><span class="si">{question}</span><span class="se">\n</span><span class="s1">有用的答案：&#39;</span><span class="p">,</span>
    <span class="n">template_format</span><span class="o">=</span><span class="s1">&#39;f-string&#39;</span><span class="p">,</span>
    <span class="n">validate_template</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains.llm</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.callbacks.base</span> <span class="kn">import</span> <span class="n">CallbackManager</span>
<span class="kn">from</span> <span class="nn">langchain.callbacks.streaming_stdout</span> <span class="kn">import</span> <span class="n">StreamingStdOutCallbackHandler</span>
<span class="kn">from</span> <span class="nn">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.base</span> <span class="kn">import</span> <span class="n">VectorStore</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationalRetrievalChain</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Callback function to stream answers to stdout.</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">CallbackManager</span><span class="p">([</span><span class="n">StreamingStdOutCallbackHandler</span><span class="p">()])</span>

<span class="n">streaming_llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">manager</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">question_gen_llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">manager</span><span class="p">)</span>
<span class="c1"># Prompt to generate independent questions by incorporating chat history and a new question.</span>
<span class="n">question_generator</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">question_gen_llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">CONDENSE_QUESTION_PROMPT</span><span class="p">)</span>
<span class="c1"># Pass in documents and a standalone prompt to answer questions.</span>
<span class="n">doc_chain</span> <span class="o">=</span> <span class="n">load_qa_chain</span><span class="p">(</span><span class="n">streaming_llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s1">&#39;stuff&#39;</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">QA_PROMPT</span><span class="p">)</span>
<span class="c1"># Generate prompts from embedding model.</span>
<span class="n">qa</span> <span class="o">=</span> <span class="n">ConversationalRetrievalChain</span><span class="p">(</span><span class="n">retriever</span><span class="o">=</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span> <span class="n">combine_docs_chain</span><span class="o">=</span><span class="n">doc_chain</span><span class="p">,</span> <span class="n">question_generator</span><span class="o">=</span><span class="n">question_generator</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;七倍加强的灵是什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">answer</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_qa</span><span class="p">(</span><span class="n">mock_openai</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">answer</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">qa</span><span class="p">({</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;chat_history&#39;</span><span class="p">:</span> <span class="p">[]})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ipymock</span> <span class="kn">import</span> <span class="n">do</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do</span><span class="p">(</span>
    <span class="n">mock_openai</span><span class="o">=</span><span class="n">mock_openai</span><span class="p">,</span>
    <span class="n">test_qa</span><span class="o">=</span><span class="n">test_qa</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
=&gt; no.0  ::tools::test_qa  setup  passed

很抱歉，我无法回答这个问题。在所提供的背景信息中没有提及“七倍加强的灵”，也没有足够的上下文信息可以确定它指的是什么。如果您有更多的背景信息或上下文，请提供给我，我将尽力回答您的问题。

=&gt; no.0  ::tools::test_qa  runtest  passed

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">answer</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;question&#39;: &#39;七倍加强的灵是什么？&#39;,
 &#39;chat_history&#39;: [],
 &#39;answer&#39;: &#39;很抱歉，我无法回答这个问题。在所提供的背景信息中没有提及“七倍加强的灵”，也没有足够的上下文信息可以确定它指的是什么。如果您有更多的背景信息或上下文，请提供给我，我将尽力回答您的问题。&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Instructor Transformer</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">InstructorEmbedding</span> <span class="kn">import</span> <span class="n">INSTRUCTOR</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">INSTRUCTOR</span><span class="p">(</span><span class="s1">&#39;hkunlp/instructor-large&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>load INSTRUCTOR_Transformer
max_seq_length  512
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Faiss Indexer</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">faiss</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="mi">768</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Embedding and Indexing</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">instruction</span> <span class="o">=</span> <span class="s1">&#39;Represent the query for retrieval:&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">instruction</span> <span class="o">=</span> <span class="s1">&#39;表示用于检索的查询：&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">index_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">sentences</span>

    <span class="c1"># words = extra_text.split(&#39; &#39;)</span>
    <span class="c1"># sentences = [words[i: i+num_words] for i in range(0, len(words), num_words)]</span>
    <span class="c1"># sentences = [&#39; &#39;.join(word_list) for word_list in sentences]</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;。&#39;</span><span class="p">,</span> <span class="s1">&#39;。</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))):</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">sentence</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Number of Sentences:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
    <span class="c1"># print(sentences)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Building the index...&#39;</span><span class="p">)</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([[</span><span class="n">instruction</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">])</span>
    <span class="n">index</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">index.ntotal:&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">ntotal</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index_embeddings</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">raw_document</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">raw_document</span> <span class="ow">in</span> <span class="n">raw_documents</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Number of Sentences: 13960

Building the index...

index.ntotal: 13960
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Faiss Search</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">retrieve_extra_info</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Retrieving extra information...&#39;</span><span class="p">)</span>
    <span class="n">xq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([[</span><span class="n">instruction</span><span class="p">,</span> <span class="n">text</span><span class="p">]])</span>
    <span class="n">D</span><span class="p">,</span> <span class="n">I</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">xq</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">D</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">extra_info</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">extra_info</span> <span class="o">+=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">extra_info:&#39;</span><span class="p">,</span> <span class="n">extra_info</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">extra_info</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">retrieve_extra_info</span><span class="p">(</span><span class="s1">&#39;你知道什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve_extra_info</span><span class="p">(</span><span class="s1">&#39;第八周讲了什么？&#39;</span><span class="p">)</span>
<span class="n">retrieve_extra_info</span><span class="p">(</span><span class="s1">&#39;七倍加强的灵是什么？&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Retrieving extra information...
[5.4066086e-14 1.1163864e-02 1.1163864e-02 1.1163864e-02 1.1163864e-02
 1.1163864e-02 1.1163864e-02 1.1163864e-02 1.1163864e-02 3.0758277e-02
 4.8185803e-02 4.8678309e-02 4.8678320e-02 4.8678324e-02 4.8678324e-02
 4.8678324e-02 4.8678324e-02 4.9394563e-02 4.9731985e-02 5.5326112e-02]
[ 5745    20  2756  4925  6154  9841  9866 10484 12664  4078  2048 13937
  6191   159  2695  7559 11518 12666  9761  2050]

extra_info: 那时你为你的大名要怎样行呢？
谁经历最大量的变化？就是向主完全敞开的人。
你会被这样的事搅扰么？但愿不会。
你晓得误会是从哪里来的么？它的根源常常是不纯净。
在宇宙中需要得满足的是谁呢？就是神自己。
但为什么万国所羡慕的这一位还没有回来？因为召会还没有建造起来。
我们难道不想要有神的荣耀么？得着神荣耀充满的路就是建造祂的殿。
岂不知你们有耶稣基督在你们里面么？除非你们是经不起试验的。
我们是否愿意学习有这样的祷告？这是主心头的渴望。
”你们在经上从来没有念过么？
神要如何得着祂所渴望的彰显呢？这需要神子民有属天神圣的构成和活出；这个构成乃是从主的话并从那灵而来。
你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。
我们能完全为着神么？因着我们爱主，我们会立志要绝对为神而活。
摩西有说过这话么？没有，乃是撒迦利亚第一个说的。
是谁在拦阻人接待弟兄呢？乃是带领的人在拦阻，而不是一般的圣徒。
你是绝对地为着神么？一方面说是为着神，另一方面说并不为着神。
为什么是一个谜？就是因为这些都是出于神，而神却隐藏起来了。
我要问主恢复中每一位同工、每一位全时间服事者、每一位长老、每一位负责弟兄：你是否愿意学习有这样的祷告？我们要祷告，求主给我们一条路来学习这样祷告。
但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。
教导什么？……他必须能一卷一卷地教导圣经。


Retrieving extra information...
[5.4066086e-14 1.1163864e-02 1.1163864e-02 1.1163864e-02 1.1163864e-02
 1.1163864e-02 1.1163864e-02 1.1163864e-02 1.1163864e-02 3.0758277e-02
 4.8185803e-02 4.8678309e-02 4.8678320e-02 4.8678324e-02 4.8678324e-02
 4.8678324e-02 4.8678324e-02 4.9394563e-02 4.9731985e-02 5.5326112e-02]
[ 5745    20  2756  4925  6154  9841  9866 10484 12664  4078  2048 13937
  6191   159  2695  7559 11518 12666  9761  2050]

extra_info: 那时你为你的大名要怎样行呢？
谁经历最大量的变化？就是向主完全敞开的人。
你会被这样的事搅扰么？但愿不会。
你晓得误会是从哪里来的么？它的根源常常是不纯净。
在宇宙中需要得满足的是谁呢？就是神自己。
但为什么万国所羡慕的这一位还没有回来？因为召会还没有建造起来。
我们难道不想要有神的荣耀么？得着神荣耀充满的路就是建造祂的殿。
岂不知你们有耶稣基督在你们里面么？除非你们是经不起试验的。
我们是否愿意学习有这样的祷告？这是主心头的渴望。
”你们在经上从来没有念过么？
神要如何得着祂所渴望的彰显呢？这需要神子民有属天神圣的构成和活出；这个构成乃是从主的话并从那灵而来。
你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。
我们能完全为着神么？因着我们爱主，我们会立志要绝对为神而活。
摩西有说过这话么？没有，乃是撒迦利亚第一个说的。
是谁在拦阻人接待弟兄呢？乃是带领的人在拦阻，而不是一般的圣徒。
你是绝对地为着神么？一方面说是为着神，另一方面说并不为着神。
为什么是一个谜？就是因为这些都是出于神，而神却隐藏起来了。
我要问主恢复中每一位同工、每一位全时间服事者、每一位长老、每一位负责弟兄：你是否愿意学习有这样的祷告？我们要祷告，求主给我们一条路来学习这样祷告。
但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。
教导什么？……他必须能一卷一卷地教导圣经。


Retrieving extra information...
[5.4066086e-14 1.1163864e-02 1.1163864e-02 1.1163864e-02 1.1163864e-02
 1.1163864e-02 1.1163864e-02 1.1163864e-02 1.1163864e-02 3.0758277e-02
 4.8185803e-02 4.8678309e-02 4.8678320e-02 4.8678324e-02 4.8678324e-02
 4.8678324e-02 4.8678324e-02 4.9394563e-02 4.9731985e-02 5.5326112e-02]
[ 5745    20  2756  4925  6154  9841  9866 10484 12664  4078  2048 13937
  6191   159  2695  7559 11518 12666  9761  2050]

extra_info: 那时你为你的大名要怎样行呢？
谁经历最大量的变化？就是向主完全敞开的人。
你会被这样的事搅扰么？但愿不会。
你晓得误会是从哪里来的么？它的根源常常是不纯净。
在宇宙中需要得满足的是谁呢？就是神自己。
但为什么万国所羡慕的这一位还没有回来？因为召会还没有建造起来。
我们难道不想要有神的荣耀么？得着神荣耀充满的路就是建造祂的殿。
岂不知你们有耶稣基督在你们里面么？除非你们是经不起试验的。
我们是否愿意学习有这样的祷告？这是主心头的渴望。
”你们在经上从来没有念过么？
神要如何得着祂所渴望的彰显呢？这需要神子民有属天神圣的构成和活出；这个构成乃是从主的话并从那灵而来。
你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。
我们能完全为着神么？因着我们爱主，我们会立志要绝对为神而活。
摩西有说过这话么？没有，乃是撒迦利亚第一个说的。
是谁在拦阻人接待弟兄呢？乃是带领的人在拦阻，而不是一般的圣徒。
你是绝对地为着神么？一方面说是为着神，另一方面说并不为着神。
为什么是一个谜？就是因为这些都是出于神，而神却隐藏起来了。
我要问主恢复中每一位同工、每一位全时间服事者、每一位长老、每一位负责弟兄：你是否愿意学习有这样的祷告？我们要祷告，求主给我们一条路来学习这样祷告。
但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。
教导什么？……他必须能一卷一卷地教导圣经。

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;那时你为你的大名要怎样行呢？\n谁经历最大量的变化？就是向主完全敞开的人。\n你会被这样的事搅扰么？但愿不会。\n你晓得误会是从哪里来的么？它的根源常常是不纯净。\n在宇宙中需要得满足的是谁呢？就是神自己。\n但为什么万国所羡慕的这一位还没有回来？因为召会还没有建造起来。\n我们难道不想要有神的荣耀么？得着神荣耀充满的路就是建造祂的殿。\n岂不知你们有耶稣基督在你们里面么？除非你们是经不起试验的。\n我们是否愿意学习有这样的祷告？这是主心头的渴望。\n”你们在经上从来没有念过么？\n神要如何得着祂所渴望的彰显呢？这需要神子民有属天神圣的构成和活出；这个构成乃是从主的话并从那灵而来。\n你知道这些东西能借着祷读主话而杀死么？我们越接受主的话连同其杀死的能力，我们的骄傲以及里面一切消极的元素就越被治死。\n我们能完全为着神么？因着我们爱主，我们会立志要绝对为神而活。\n摩西有说过这话么？没有，乃是撒迦利亚第一个说的。\n是谁在拦阻人接待弟兄呢？乃是带领的人在拦阻，而不是一般的圣徒。\n你是绝对地为着神么？一方面说是为着神，另一方面说并不为着神。\n为什么是一个谜？就是因为这些都是出于神，而神却隐藏起来了。\n我要问主恢复中每一位同工、每一位全时间服事者、每一位长老、每一位负责弟兄：你是否愿意学习有这样的祷告？我们要祷告，求主给我们一条路来学习这样祷告。\n但我要问弟兄姊妹：我们在这里是为着什么？我们在这里有什么负担？我们在这里是为着什么而活？我们乃是为着神殿的建造。\n教导什么？……他必须能一卷一卷地教导圣经。\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Chat with PDF</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">CRITICAL</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_in_english</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;You are an AI agent that summarizes chat in less than three setences.&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_in_chinese</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;系统&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">chats_in_english</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;You are an AI assistant providing helpful advice.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;You are given the following extracted parts of a long document and a question.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;Provide a conversational answer based on the context provided.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;You should only provide hyperlinks that reference the context below.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;Do NOT make up hyperlinks.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;If you can</span><span class="se">\&#39;</span><span class="s1">t find the answer in the context below, use your prior knowledge,</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;but in most of the cases the answer will be in the context.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="c1"># &#39;If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\n&#39; + \</span>
    <span class="s1">&#39;Answer in Markdown format.</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">chats_in_chinese</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;系统&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;你是一个提供有用建议的 AI 助手。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;你被提供了一份长文档的一部分（额外信息）和一个问题。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;请根据我所提供的文本提供会话式的回答。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;你只应该提供与下面的文本相关的超链接。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;**不要**编造超链接。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;如果在下面的文本中找不到答案，可以使用你先前所知道的知识，</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="s1">&#39;但在大多数情况下，答案是在文本中的。</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> \
    <span class="c1"># &#39;如果问题与上下文不相关，请礼貌地回复您只回答与上下文相关的问题。\n&#39; + \</span>
    <span class="s1">&#39;请用中文以 Markdown 格式回答。</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>PyPDF2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully installed PyPDF2-3.0.1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">PyPDF2</span>

<span class="k">def</span> <span class="nf">extract_text</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Extract text from a PDF file.&#39;&#39;&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">pdf_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">page</span><span class="o">.</span><span class="n">extract_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">PyPDF2</span><span class="o">.</span><span class="n">PdfReader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">pages</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_the_bot</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">,</span> <span class="n">openai_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;split sentences in chinese&#39;&#39;&#39;</span>
    <span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">openai_key</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OpenAI Key:&#39;</span><span class="p">,</span> <span class="n">openai_key</span><span class="p">)</span>

    <span class="n">extra_text</span> <span class="o">=</span> <span class="n">extract_text</span><span class="p">(</span><span class="n">pdf_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Text Length:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_text</span><span class="p">))</span>

    <span class="n">index_embeddings</span><span class="p">(</span><span class="n">extra_text</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">extra_text</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">chat</span><span class="p">(</span><span class="n">chat_history</span><span class="p">,</span> <span class="n">user_input</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;chat in chinese&#39;&#39;&#39;</span>
    <span class="k">global</span> <span class="n">sentences</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">messages_in_chinese:&#39;</span><span class="p">,</span> <span class="n">messages_in_chinese</span><span class="p">)</span>
    <span class="c1"># messages_in_english.append({&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Question:\n&#39; + user_input})</span>
    <span class="c1"># print(&#39;\nmessages_in_english:&#39;, messages_in_english)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Summarizing the chat history...&#39;</span><span class="p">)</span>

    <span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">messages_in_chinese</span>
    <span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Summarized Histoy: </span><span class="si">{</span><span class="n">summary</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">extra_info</span> <span class="o">=</span> <span class="n">retrieve_extra_info</span><span class="p">(</span><span class="n">summary</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;问题：&#39;</span> <span class="o">+</span> <span class="n">user_input</span><span class="p">)</span>

    <span class="n">chats_in_chinese</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;用户&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="s1">&#39;额外信息：</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">extra_info</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;问题：&#39;</span> <span class="o">+</span> <span class="n">user_input</span><span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">chats_in_chinese:&#39;</span><span class="p">,</span> <span class="n">chats_in_chinese</span><span class="p">)</span>
    <span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="n">chats_in_chinese</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">chats_in_chinese</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
    <span class="p">)</span>

    <span class="n">chat_output</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">ChatGPT: </span><span class="si">{</span><span class="n">chat_output</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># messages_in_chinese.append({&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: user_input})</span>
    <span class="c1"># messages_in_chinese.append({&#39;role&#39;: &#39;助手&#39;, &#39;content&#39;: chat_output})</span>
    <span class="k">yield</span> <span class="n">chat_history</span> <span class="o">+</span> <span class="p">[(</span><span class="n">user_input</span><span class="p">,</span> <span class="n">chat_output</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>gradio
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully installed altair-4.2.2 contourpy-1.0.7 cycler-0.11.0 ffmpy-0.3.0 fonttools-4.39.3 fsspec-2023.4.0 gradio-3.26.0 gradio-client-0.1.2 kiwisolver-1.4.4 linkify-it-py-2.0.0 matplotlib-3.7.1 mdit-py-plugins-0.3.3 orjson-3.8.10 pydub-0.25.1 pyparsing-3.0.9 python-multipart-0.0.6 semantic-version-2.10.0 toolz-0.12.0 uc-micro-py-1.0.1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gradio</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_demo</span><span class="p">(</span><span class="n">mock_openai</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Blocks</span><span class="p">()</span> <span class="k">as</span> <span class="n">demo</span><span class="p">:</span>
        <span class="n">gradio</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="s1">&#39;Chat with a PDF document&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Tab</span><span class="p">(</span><span class="s1">&#39;Select PDF&#39;</span><span class="p">):</span>
            <span class="n">pdf</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">File</span><span class="p">()</span>
            <span class="n">openai_key</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;OpenAI API Key&#39;</span><span class="p">,)</span>
            <span class="n">text_output</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;PDF content&#39;</span><span class="p">)</span>
            <span class="n">text_button</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="s1">&#39;Build the Bot!!!&#39;</span><span class="p">)</span>
            <span class="n">text_button</span><span class="o">.</span><span class="n">click</span><span class="p">(</span><span class="n">build_the_bot</span><span class="p">,</span> <span class="p">[</span><span class="n">pdf</span><span class="p">,</span> <span class="n">openai_key</span><span class="p">],</span> <span class="n">text_output</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Tab</span><span class="p">(</span><span class="s1">&#39;Knowledge Bot&#39;</span><span class="p">):</span>
            <span class="n">chatbot</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Chatbot</span><span class="p">()</span>
            <span class="n">message</span> <span class="o">=</span> <span class="n">gradio</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(</span><span class="s1">&#39;What is this document about?&#39;</span><span class="p">)</span>
            <span class="n">message</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="p">[</span><span class="n">chatbot</span><span class="p">,</span> <span class="n">message</span><span class="p">],</span> <span class="n">chatbot</span><span class="p">)</span>
    <span class="n">demo</span><span class="o">.</span><span class="n">queue</span><span class="p">()</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">debug</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">True</span>
    <span class="n">demo</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do</span><span class="p">(</span>
    <span class="n">mock_openai</span><span class="o">=</span><span class="n">mock_openai</span><span class="p">,</span>
    <span class="n">test_demo</span><span class="o">=</span><span class="n">test_demo</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
=&gt; no.0  ::tools::test_demo  setup  passed

Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div><iframe src="http://127.0.0.1:7860/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen></iframe></div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>OpenAI Key: 

Text Length: 4047

Number of Sentences: 157
[&#39;头一次的爱&#39;, &#39;当头一次遇见了你，&#39;, &#39;我的心充满欢喜。&#39;, &#39;阿利路亚，喜乐满溢，&#39;, &#39;主耶穌充满在我里。&#39;, &#39;头一次的爱，&#39;, &#39;最甘甜的爱，&#39;, &#39;耶穌，耶穌，我的爱。&#39;, &#39;超过一切真实的爱，&#39;, &#39;竟然临及我；&#39;, &#39;甘甜的爱，最真实的爱，&#39;, &#39;耶穌，耶穌，我的爱。&#39;, &#39;这孩子将来如何 ——美好的家庭时光，高品的亲子关系&#39;, &#39;第二课  父母与儿女爱的关系&#39;, &#39;读经：帖前二 7~8，太十九 14，罗五 5，7～8，约壹四 7~12，提后一 5，三 15&#39;, &#39;帖前二 7~8 只在你们中间为人温和，如同乳母顾惜自己的孩子。&#39;, &#39;我们这样切慕你们，不但乐意将神的福&#39;, &#39;音分给你们，连自己的性命也愿意分给你们，因你们是我们所爱的。&#39;, &#39;太十九 14 耶稣却说，让小孩子到我这里来，不要禁止他们，因为诸天之国正是这等人的。&#39;, &#39;罗五 5 盼望不至于蒙羞；因为神的爱已经借着所赐给我们的圣灵，浇灌在我们心里。&#39;, &#39;罗五 7～8 为义人死，是少有的；为仁人死，或者有敢作的；惟有基督在我们还作罪人的时候，为我们&#39;, &#39;死，神就在此将 祂自己的爱向我们显明了。&#39;, &#39;约壹四 7~12  亲爱的，我们应当彼此 相爱，因为爱是出于神的；凡爱弟兄的，都是从神生的，并且认识&#39;, &#39;神。&#39;, &#39;不爱弟兄的，未曾认识神，因为神就是爱。&#39;, &#39;神差 祂的独生子到世上来，使我们借着 祂得&#39;, &#39;生并活着，在此神的爱就向我们显明了。&#39;, &#39;不是我们爱神，乃是神爱我们，差 祂的儿子，为我&#39;, &#39;们的罪作了平息的祭物，在此就是爱了。&#39;, &#39;亲爱的，神既是这样爱我们，我们也当彼此相爱。&#39;, &#39;从来没有人见过神；我们若彼此相爱，神就住在我们里面， 祂的爱也在我们里面得了成全。&#39;, &#39;提后一 5 记得你里面无伪的信心，就是先在你外祖母罗以，和你母亲友尼基里面的，我深信也在你里&#39;, &#39;面。&#39;, &#39;提后三 15 并且知道你是从小明白圣经 ；这圣经能使你 借着相信基督耶稣，有得救的智慧。&#39;, &#39;壹 父母与儿女之间爱的关系乃是父神与祂的子民之间爱之关系的图画 ——约&#39;, &#39;壹四7~12：&#39;, &#39;一 儿女们将来的情形如何，和他生长的家庭环境大有关系；他们小的时候必须得着爱的&#39;, &#39;培养，家庭里必须建立爱的关系 ——帖前二 7~8。&#39;, &#39;二 经历来自父母的爱将帮助孩子体会神的爱； 所以， 父母不论多忙， 孩子应该自己来带 。&#39;, &#39;三 父母彼此的关系也应是相爱的体现 —— 7节。&#39;, &#39;四 父母的爱应该引导孩子有积极的回馈，彼此相爱，并影响他们去关爱别人 ——约壹四&#39;, &#39;11。&#39;, &#39;五 爱的关系是由高品质（亲子的互动、共同参与、在灵里）并稳定的陪伴培养的。&#39;, &#39;贰 圣经中母亲的榜样：&#39;, &#39;一 圣经中一位伟大的母亲是摩西的母亲约基别，她为神的子民预备了一位拯救者摩西，&#39;, &#39;一位大祭司亚伦，一位女申言者米利暗，并且在他们非常年幼的时候就作在他们身上&#39;, &#39;——出二 1~12，六 20，民二六 59。&#39;, &#39;二 哈拿的祷告，以及她在爱中的乳养，使神得着一个转移时代的器皿撒母耳 ——撒上一&#39;, &#39;10~20，二 18，19。&#39;, &#39;三 提摩太的母亲友尼基是一个平凡的女子；但她作为母亲，却是非凡的，因她栽培了一&#39;, &#39;个基督的工人 ——提摩太；她传承了无伪的信心，并默默地支持儿子的摆上 ——提后&#39;, &#39;一5，三 15。&#39;, &#39;叁 我们爱，因为神先爱我们 ——约壹四 19:&#39;, &#39;一 父母对儿女的爱是神对人爱的一幅照片，是与生俱来的。&#39;, &#39;有神生命的父母，不只有爱&#39;, &#39;的愿望，更有爱的能力，因为我们里面神的生命是爱的生命 ——约壹四 8，16。&#39;, &#39;二 父母需要操练自己，与神接触，被神的爱充满，被神的喜乐充满，操练用神性调着人&#39;, &#39;性的爱爱孩子们 ——提前四 7-8:&#39;, &#39;1 我们常常有爱的愿望，却缺少爱的能力；常感到 “立志为善由得我，只是行出来由不&#39;, &#39;得我”——参罗七 18。&#39;, &#39;2 有相同的爱（腓二 2），不但爱那聪明、漂亮的，也能爱那愚笨、丑陋的。&#39;, &#39;“我们的&#39;, &#39;神叫祂的日头上升照恶人，也照好人；降雨给义人，也给不义的人 ”（太五 45）。&#39;, &#39;父&#39;, &#39;母天然的爱常会有偏心。&#39;, &#39;3 不会溺爱孩子。&#39;, &#39;比如有的父母溺爱孩子，不希望孩子受苦，不让孩子练习做家务，&#39;, &#39;怕孩子吃苦，（其实苦难才能培养刚强的意志）；怕孩子吃亏，孩子的玩具被拿走&#39;, &#39;了妈妈受不了；孩子和同伴吵架了，妈妈想帮孩子吵：爱宴的时候，好吃的东西给&#39;, &#39;孩子盛很多，不顾到别人。&#39;, &#39;4 不会照着肉体、天然，不会仅仅照着自己的情感爱孩子。&#39;, &#39;三 父母对儿女神性调着人性的爱是属灵的爱， 是智慧的爱， 为着孩子生命的成长和成全：&#39;, &#39;1 牧养孩子的魂，启迪孩子的灵，作孩子魂的牧人和监督，把孩子引向我们的大牧人，&#39;, &#39;我们众人魂的牧人和监督 ——彼前二 25，五 4，来十三 20。&#39;, &#39;2 引导孩子敬畏神， 使孩子的行事为人不光是照着律法和规则， 更是照着良心的感觉，&#39;, &#39;更是照着对神的感觉（爱神，怕得罪神） ——彼前二 19-20。&#39;, &#39;3 引导孩子顾到别人的感觉，知道在神的家中当怎样行 ——提前三 15。&#39;, &#39;4 引导孩子，为了顾到别人、牧养别人，宁可放弃自己的权利、宁可吃亏，经历神舍&#39;, &#39;己的爱——罗五 7~8。&#39;, &#39;四 “主所爱的， 祂必管教 ......只是你们若不受众子所共受的管教，就是私生子，不是儿子&#39;, &#39;了”——来十二 6~8。&#39;, &#39;肆 父母和孩子的爱的关系满足孩子不同阶段发展的需要：&#39;, &#39;一 母爱（ 0-3岁）：&#39;, &#39;1 依恋关系：从出生甚至从怀孕开始。&#39;, &#39;是孩子第一个爱的关系，第一个对爱的理解，&#39;, &#39;是孩子情商社会性发展的基础，影响孩子将来的幸福 。&#39;, &#39;2 母爱的种子是神放到人里面的，但爱的关系的建立是需要后天培养的 。&#39;, &#39;3 孩子自己生要自己养。&#39;, &#39;一出生就要把孩子抱在怀里 。&#39;, &#39;4 在生活中满足孩子的需要（饿了，困了，尿片湿了，无聊了），一来一往生活中建&#39;, &#39;立和加强。&#39;, &#39;5 当孩子需要得到满足时就会在孩子心中产生基本的信任感。&#39;, &#39;孩子不会说话，只能用&#39;, &#39;哭声和肢体语言和照顾他的人交流，他的需要得到满足会产生基本能信任感，这帮&#39;, &#39;助他们建立积极的人生态度。&#39;, &#39;二 父母成为孩子的安全港湾  （两岁以上）：&#39;, &#39;1 两岁以后，孩子一面独立意识加强，一面确定母亲（他所爱的人）在他的身后；孩&#39;, &#39;子时不时回到妈妈这里停一下，再继续探索。&#39;, &#39;我们要成为孩子一生的安全港湾；孩&#39;, &#39;子遇到难处，遇到问题时能回来找父母交通。&#39;, &#39;2 陪孩子一起唱诗歌，讲圣经故事，和孩子谈论幼儿园发生的事情。&#39;, &#39;当孩子在家、在&#39;, &#39;外遇到难处时，父母和孩子一起讨论、一起交通、一起祷告，一起经历主。&#39;, &#39;3 父母带着孩子一起去聚会、探望，一起服事，一起做家务，与孩子及孩子的朋友一&#39;, &#39;起运动。&#39;, &#39;4 在真实的生活中过丰富多彩，生机勃勃的生活。&#39;, &#39;三 父母成为孩子的好朋友，属灵同伴（ 6-12岁）：&#39;, &#39;父母不但要花时间成为孩子的朋友， 还要成为属灵同伴： 和孩子建立读经祷告的生活，&#39;, &#39;孩子在家在外遇到难处时家长和孩子一起来讨论，一起经历主 。&#39;, &#39;父母与孩子一同过一&#39;, &#39;套的生活（服事和生活是一体的）。&#39;, &#39;四 成为孩子人生的辅助者、帮助者，成为孩子魂的牧人和监督 ，成为一起经营神事业的&#39;, &#39;同伙（12-18岁）：&#39;, &#39;孩子人生中不同阶段有不同的需要，不同的难处和问题。&#39;, &#39;我们不能替他们生活，不能&#39;, &#39;替他们做决定，而是照着神来牧养他们；多倾听孩子，与他们表同情，和他们一起祷&#39;, &#39;告寻求，一同经历神的大能，甚至神的管教。&#39;, &#39;伍 借建立“家庭时光 ”，建立并发展与孩子爱的关系：&#39;, &#39;一 “家庭时光 ”的实行指引：&#39;, &#39;1 成员：家中所有人，父母、儿女、爷爷、奶奶（外公、外婆）；&#39;, &#39;2 频率：最好天天，至少每周一次；&#39;, &#39;3 时间：周末，周中，晚上，白天都可以；最好每周固定时间；时长： 10-30分钟；&#39;, &#39;4 地点：家里，安静的餐厅，海边，户外均可；&#39;, &#39;5 内容：呼求主、祷告、唱诗歌，读圣经、背经节，讲故事；话题讨论，生活感悟，&#39;, &#39;对主的特别经历等等。&#39;, &#39;6 特点：温馨、甜美、有爱、有光（严肃），有神的元素。&#39;, &#39;二 “家庭时光 ”的益处：&#39;, &#39;1 加强家人爱的关系，增进感情，分赐生命；&#39;, &#39;2 促进孩子灵魂体的发展；促进孩子智商、情商、灵商的发展：&#39;, &#39;A  唱诗歌、享受诗歌，有助孩子情商发展；&#39;, &#39;B  话题讨论，有助于孩子分析问题、解决问题能力的培养，应付孩子各阶段成长的需&#39;, &#39;要，加强孩子社会性，与人交往的能力；&#39;, &#39;C  读圣经帮助孩子认识神、认识神的旨意、神的性情、神的法则；&#39;, &#39;D  讲圣经故事、 话题讨论， 帮助孩子增加智慧， 培养孩子的语言表达能力， 写作能力，&#39;, &#39;发展孩子智商；&#39;, &#39;E  父母的见证及其他圣徒的见证，供应孩子生命，有助于他们属灵生命的长大，预备&#39;, &#39;孩子尽生机的功用。&#39;, &#39;三 “家庭时光 ”的目的：使我们的家成为生命的园子；成为神的家、神的彰显；成为新&#39;, &#39;耶路撒冷的小影。&#39;, &#39;作业：&#39;, &#39;群组： 0岁以下、 0-12岁父母群、有信仰的妈妈群&#39;, &#39;1 分享本堂课的心得，以及收获。&#39;, &#39;（字数不限）&#39;, &#39;2 建立“家庭时光 ”：（a）已有家庭时光的，请简述你们是如何开始的，并列出时间、地点、内容，&#39;, &#39;孩子们反应如何？（建议每次家庭时光有个简要记录）（ b）尚未有 “家庭时光 ”的，  请本周开&#39;, &#39;始建立，并列出时间、地点。&#39;, &#39;3 建立定时为孩子的祷告，请列出祷告时间（个人或夫妇的祷告）。&#39;, &#39;4 您有任何问题，欢迎写在下面，之后会有问题解答。&#39;, &#39;群组：儿童服事者群&#39;, &#39;1 分享本堂课的心得，以及收获。&#39;, &#39;（字数不限）&#39;, &#39;2 请传输负担，并帮助圣徒建立 “家庭时光 ”，请列出具体的实行过程，时间、地点、内容。&#39;, &#39;已有&#39;, &#39;建立的，请简述你们是如何开始的，并列出时间、地点、内容，孩子们反应如何？（建议每次&#39;, &#39;家庭时光有个简要记录）&#39;, &#39;3 建立儿童服事者间的祷告。&#39;, &#39;4 您有任何问题，欢迎写在下面，之后会有问题解答。&#39;]

Building the index...

index.ntotal: 471

messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 用户提供了一段文本片段，但没有明确说明文档的主题。

Retrieving extra information...
[0.22384945 0.22384945 0.22384945 0.22384945 0.22384945 0.22384945
 0.22445944 0.22445944 0.22445944 0.22445944 0.22445944 0.22445944
 0.22445944 0.22445944 0.22445944 0.22445944 0.22445944 0.22445944
 0.22445944 0.22445944]
[ 43  81 200 238 357 395   0   2   4  23  32  63  64  90  94 101 104 109
 124 136]
157 200
157 238
157 357
157 395

extra_info: 贰 圣经中母亲的榜样：
肆 父母和孩子的爱的关系满足孩子不同阶段发展的需要：
头一次的爱
我的心充满欢喜。
主耶穌充满在我里。
神。
面。
父
母天然的爱常会有偏心。
立和加强。
助他们建立积极的人生态度。
当孩子在家、在
起运动。
父母与孩子一同过一
对主的特别经历等等。
孩子尽生机的功用。


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n贰 圣经中母亲的榜样：\n肆 父母和孩子的爱的关系满足孩子不同阶段发展的需要：\n头一次的爱\n我的心充满欢喜。\n主耶穌充满在我里。\n神。\n面。\n父\n母天然的爱常会有偏心。\n立和加强。\n助他们建立积极的人生态度。\n当孩子在家、在\n起运动。\n父母与孩子一同过一\n对主的特别经历等等。\n孩子尽生机的功用。\n\n\n问题：What is this document about?&#39;}]

ChatGPT: 这份文档似乎是关于圣经中母亲的榜样和父母如何满足孩子不同阶段发展需要的话题。它提到了头一次的爱、天然的爱可能有偏心、助孩子建立积极人生态度以及与孩子一同度过时刻等内容。

messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 用户提供了一段圣经和关于父母与孩子之间爱的关系的信息，但并没有具体提问。

Retrieving extra information...
[0.02490797 0.02490797 0.02490797 0.08932048 0.08932048 0.08932048
 0.08960854 0.08960854 0.08960854 0.09182282 0.09182282 0.09182282
 0.09209618 0.09209618 0.09209618 0.09309858 0.09309858 0.09309858
 0.09309858 0.09309858]
[153 310 467 107 264 421  44 201 358 111 268 425  53 210 367  40  47 197
 204 354]
157 310
157 467
157 264
157 421
157 201
157 358
157 268
157 425
157 210
157 367
157 197
157 204
157 354

extra_info: 建立的，请简述你们是如何开始的，并列出时间、地点、内容，孩子们反应如何？（建议每次
父母不但要花时间成为孩子的朋友， 还要成为属灵同伴： 和孩子建立读经祷告的生活，
一 圣经中一位伟大的母亲是摩西的母亲约基别，她为神的子民预备了一位拯救者摩西，
四 成为孩子人生的辅助者、帮助者，成为孩子魂的牧人和监督 ，成为一起经营神事业的
一 父母对儿女的爱是神对人爱的一幅照片，是与生俱来的。
四 父母的爱应该引导孩子有积极的回馈，彼此相爱，并影响他们去关爱别人 ——约壹四
二 哈拿的祷告，以及她在爱中的乳养，使神得着一个转移时代的器皿撒母耳 ——撒上一


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n贰 圣经中母亲的榜样：\n肆 父母和孩子的爱的关系满足孩子不同阶段发展的需要：\n头一次的爱\n我的心充满欢喜。\n主耶穌充满在我里。\n神。\n面。\n父\n母天然的爱常会有偏心。\n立和加强。\n助他们建立积极的人生态度。\n当孩子在家、在\n起运动。\n父母与孩子一同过一\n对主的特别经历等等。\n孩子尽生机的功用。\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n建立的，请简述你们是如何开始的，并列出时间、地点、内容，孩子们反应如何？（建议每次\n父母不但要花时间成为孩子的朋友， 还要成为属灵同伴： 和孩子建立读经祷告的生活，\n一 圣经中一位伟大的母亲是摩西的母亲约基别，她为神的子民预备了一位拯救者摩西，\n四 成为孩子人生的辅助者、帮助者，成为孩子魂的牧人和监督 ，成为一起经营神事业的\n一 父母对儿女的爱是神对人爱的一幅照片，是与生俱来的。\n四 父母的爱应该引导孩子有积极的回馈，彼此相爱，并影响他们去关爱别人 ——约壹四\n二 哈拿的祷告，以及她在爱中的乳养，使神得着一个转移时代的器皿撒母耳 ——撒上一\n\n\n问题：这个文档是关于什么的？&#39;}]

ChatGPT: 这份文档似乎是关于父母如何成为孩子的灵性导师和引导他们成长的指南。文中提到了许多圣经中母亲和父亲的榜样，以及父母应该如何满足孩子不同阶段发展的需要。其中包括建立读经祷告的生活，成为孩子魂的牧人和监督，引导孩子有积极的回馈和去关爱别人等。

messages_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个 AI 代理。请用中文在三句话之内概括聊天内容。&#39;}]

Summarizing the chat history...

Summarized Histoy: 用户询问了一份长文档的主题，并提供了一些额外信息。我使用超链接回答了他们的问题，并提供了相关的信息和文章的概述。

Retrieving extra information...
[0.00558901 0.00558901 0.00558901 0.00583334 0.00583334 0.00583334
 0.00816433 0.00816433 0.00816433 0.00816433 0.00816433 0.00816433
 0.00878926 0.00878926 0.00878926 0.00878926 0.00878926 0.00878926
 0.00878926 0.00878926]
[ 27 184 341 111 268 425  40  47 197 204 354 361   7  11 164 168 321 325
  17  24]
157 184
157 341
157 268
157 425
157 197
157 204
157 354
157 361
157 164
157 168
157 321
157 325

extra_info: 不是我们爱神，乃是神爱我们，差 祂的儿子，为我
四 成为孩子人生的辅助者、帮助者，成为孩子魂的牧人和监督 ，成为一起经营神事业的
四 父母的爱应该引导孩子有积极的回馈，彼此相爱，并影响他们去关爱别人 ——约壹四
二 哈拿的祷告，以及她在爱中的乳养，使神得着一个转移时代的器皿撒母耳 ——撒上一
耶穌，耶穌，我的爱。
耶穌，耶穌，我的爱。
音分给你们，连自己的性命也愿意分给你们，因你们是我们所爱的。
不爱弟兄的，未曾认识神，因为神就是爱。


chats_in_chinese: [{&#39;role&#39;: &#39;系统&#39;, &#39;content&#39;: &#39;你是一个提供有用建议的 AI 助手。\n你被提供了一份长文档的一部分（额外信息）和一个问题。\n请根据我所提供的文本提供会话式的回答。\n你只应该提供与下面的文本相关的超链接。\n**不要**编造超链接。\n如果在下面的文本中找不到答案，可以使用你先前所知道的知识，\n但在大多数情况下，答案是在文本中的。\n请用中文以 Markdown 格式回答。\n&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n贰 圣经中母亲的榜样：\n肆 父母和孩子的爱的关系满足孩子不同阶段发展的需要：\n头一次的爱\n我的心充满欢喜。\n主耶穌充满在我里。\n神。\n面。\n父\n母天然的爱常会有偏心。\n立和加强。\n助他们建立积极的人生态度。\n当孩子在家、在\n起运动。\n父母与孩子一同过一\n对主的特别经历等等。\n孩子尽生机的功用。\n\n\n问题：What is this document about?&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n建立的，请简述你们是如何开始的，并列出时间、地点、内容，孩子们反应如何？（建议每次\n父母不但要花时间成为孩子的朋友， 还要成为属灵同伴： 和孩子建立读经祷告的生活，\n一 圣经中一位伟大的母亲是摩西的母亲约基别，她为神的子民预备了一位拯救者摩西，\n四 成为孩子人生的辅助者、帮助者，成为孩子魂的牧人和监督 ，成为一起经营神事业的\n一 父母对儿女的爱是神对人爱的一幅照片，是与生俱来的。\n四 父母的爱应该引导孩子有积极的回馈，彼此相爱，并影响他们去关爱别人 ——约壹四\n二 哈拿的祷告，以及她在爱中的乳养，使神得着一个转移时代的器皿撒母耳 ——撒上一\n\n\n问题：这个文档是关于什么的？&#39;}, {&#39;role&#39;: &#39;用户&#39;, &#39;content&#39;: &#39;额外信息：\n不是我们爱神，乃是神爱我们，差 祂的儿子，为我\n四 成为孩子人生的辅助者、帮助者，成为孩子魂的牧人和监督 ，成为一起经营神事业的\n四 父母的爱应该引导孩子有积极的回馈，彼此相爱，并影响他们去关爱别人 ——约壹四\n二 哈拿的祷告，以及她在爱中的乳养，使神得着一个转移时代的器皿撒母耳 ——撒上一\n耶穌，耶穌，我的爱。\n耶穌，耶穌，我的爱。\n音分给你们，连自己的性命也愿意分给你们，因你们是我们所爱的。\n不爱弟兄的，未曾认识神，因为神就是爱。\n\n\n问题：头一次的爱&#39;}]

ChatGPT: 很抱歉，根据您提供的额外信息和问题，我无法找到足够的上下文来回答您的问题。可以提供更多的信息或具体引用文档中的哪一部分吗？
Keyboard interruption in main thread... closing server.
Closing server running on port: 7860
=&gt; no.0  ::tools::test_demo  runtest  passed

</pre>
</div>
</div>

</div>
</div>

</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/12/LangChain-Embeddings/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-12 </div>
			<div class="article-title"><a href="/2023/04/12/Text-Embeddings/" >Text Embedding</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Text-Embeddings">Text Embeddings<a class="anchor-link" href="#Text-Embeddings">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://openai.com/blog/new-and-improved-embedding-model">OpenAI Embedding Model</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">EdgeGPT</span> <span class="kn">import</span> <span class="n">Chatbot</span> <span class="k">as</span> <span class="n">Bing</span><span class="p">,</span> <span class="n">ConversationStyle</span>

<span class="n">bing</span> <span class="o">=</span> <span class="n">Bing</span><span class="p">(</span><span class="n">cookiePath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/.config/EdgeGPT/cookies.json&#39;</span><span class="p">))</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">ask</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="k">await</span> <span class="n">bing</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">,</span>
        <span class="n">conversation_style</span> <span class="o">=</span> <span class="n">ConversationStyle</span><span class="o">.</span><span class="n">balanced</span><span class="p">,</span>
    <span class="p">))[</span><span class="s1">&#39;item&#39;</span><span class="p">][</span><span class="s1">&#39;messages&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">---</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;adaptiveCards&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;body&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;text&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">text-embedding-ada-002 是什么？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>text-embedding-ada-002 是 OpenAI 提供的一种嵌入模型，用于将文本转换为向量表示。[^1^] 你可以将文本字符串发送到嵌入 API 端点，同时选择嵌入模型 ID（例如 text-embedding-ada-002），响应将包含一个嵌入，你可以提取、保存和使用。[^1^] 

text-embedding-ada-002 模型是 OpenAI 提供的第二代嵌入模型之一，它比第一代模型更好、更便宜、更简单易用。[^5^] 

如果你想了解更多关于 text-embedding-ada-002 的信息，可以参考 OpenAI 的官方文档。[^5^]

---

[1]: https://platform.openai.com/docs/guides/embeddings/second-generation-models &#34;Embeddings - OpenAI API&#34;
[2]: https://juejin.cn/post/7216319218505220151 &#34;OpenAI的Embedding - 掘金 - 稀土掘金&#34;
[3]: https://cloud.tencent.com/developer/article/2222888 &#34;GPT-3 vs Bert vs GloVe vs Word2vec 文本嵌入技术的性能对比测试 - 腾讯云开发者社区-腾讯云&#34;
[4]: https://openai.com/blog/new-and-improved-embedding-model/ &#34;New and improved embedding model - openai.com&#34;
[5]: https://platform.openai.com/docs/guides/embeddings &#34;Embeddings - OpenAI API&#34;

text-embedding-ada-002 是 OpenAI 提供的一种嵌入模型，用于将文本转换为向量表示。[^1^][1] 你可以将文本字符串发送到嵌入 API 端点，同时选择嵌入模型 ID（例如 text-embedding-ada-002），响应将包含一个嵌入，你可以提取、保存和使用。[^1^][1] 

text-embedding-ada-002 模型是 OpenAI 提供的第二代嵌入模型之一，它比第一代模型更好、更便宜、更简单易用。[^2^][5] 

如果你想了解更多关于 text-embedding-ada-002 的信息，可以参考 OpenAI 的官方文档。[^2^][5]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">比较 GPT-3 嵌入、GloVe 嵌入、Word2vec 嵌入、MPNet 嵌入</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>GPT-3 嵌入、GloVe 嵌入、Word2vec 嵌入和 MPNet 嵌入都是常见的文本嵌入模型。其中，GPT-3 是 OpenAI 开发的一种大型语言模型，可以生成自然语言文本[^1^]。GloVe 和 Word2vec 都是基于神经网络的词向量模型，用于将单词转换为向量表示，以便计算机可以更好地理解自然语言[^1^] [^2^]。MPNet 是一种基于多任务学习的预训练语言模型，可以用于各种自然语言处理任务[^1^] [^4^]。

据腾讯云开发者社区的一篇文章所述，该作者使用了 text-embedding-ada-002（GPT-3 的一个 Embeddings）与三种传统文本嵌入技术生成的嵌入进行比较，即 GloVe、Word2vec 和 MPNet。结果显示，GPT-3 嵌入在所有模型中获得了最高的精度[^1^]。但是，这些模型的性能可能会因应用场景而异。如果你需要更多信息，请告诉我！

---

[1]: https://cloud.tencent.com/developer/article/2222888 &#34;GPT-3 vs Bert vs GloVe vs Word2vec 文本嵌入技术的性能对比测试 - 腾讯云开发者社区-腾讯云&#34;
[2]: https://developer.aliyun.com/article/1159268 &#34;GPT-3 vs Bert vs GloVe vs Word2vec 文本嵌入技术的性能对比测试-阿里云开发者社区&#34;
[3]: https://new.qq.com/rain/a/20230212A01IWP00 &#34;GPT-3 vs Bert vs GloVe vs Word2vec 文本嵌入技术的性能对比测试_腾讯新闻&#34;
[4]: https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/129153025 &#34;GPT-3 vs Bert vs GloVe vs Word2vec 文本嵌入技术的性能对比测试&#34;
[5]: https://zhuanlan.zhihu.com/p/605603003 &#34;GPT-3 vs Bert vs GloVe 文本嵌入技术的性能对比测试 - 知乎&#34;

GPT-3 嵌入、GloVe 嵌入、Word2vec 嵌入和 MPNet 嵌入都是常见的文本嵌入模型。其中，GPT-3 是 OpenAI 开发的一种大型语言模型，可以生成自然语言文本[^1^][1]。GloVe 和 Word2vec 都是基于神经网络的词向量模型，用于将单词转换为向量表示，以便计算机可以更好地理解自然语言[^1^][1] [^2^][2]。MPNet 是一种基于多任务学习的预训练语言模型，可以用于各种自然语言处理任务[^1^][1] [^3^][4]。

据腾讯云开发者社区的一篇文章所述，该作者使用了 text-embedding-ada-002（GPT-3 的一个 Embeddings）与三种传统文本嵌入技术生成的嵌入进行比较，即 GloVe、Word2vec 和 MPNet。结果显示，GPT-3 嵌入在所有模型中获得了最高的精度[^1^][1]。但是，这些模型的性能可能会因应用场景而异。如果你需要更多信息，请告诉我！

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">还有哪些文本嵌入模型？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>除了 GPT-3 嵌入、GloVe 嵌入、Word2vec 嵌入和 MPNet 嵌入之外，还有许多其他文本嵌入模型。例如，ELMo、Skip-Thoughts、Quick-Thoughts、InferSent、MILA/MSR 的通用句子表示和 Google 的通用句子编码器等模型都是最先进的模型之一[^1^]。这些模型的性能可能会因应用场景而异。如果你需要更多信息，请告诉我！

---

[1]: https://cloud.tencent.com/developer/article/1167972 &#34;干货 | 文本嵌入的经典模型与最新进展 - 腾讯云开发者社区-腾讯云&#34;
[2]: https://blog.csdn.net/lingpy/article/details/80809926 &#34;文本嵌入的经典模型与最新进展 - CSDN博客&#34;
[3]: https://zhuanlan.zhihu.com/p/459295186 &#34;5分钟 NLP系列—— 11 个词嵌入模型总结 - 知乎 - 知乎专栏&#34;

除了 GPT-3 嵌入、GloVe 嵌入、Word2vec 嵌入和 MPNet 嵌入之外，还有许多其他文本嵌入模型。例如，ELMo、Skip-Thoughts、Quick-Thoughts、InferSent、MILA/MSR 的通用句子表示和 Google 的通用句子编码器等模型都是最先进的模型之一[^1^][1]。这些模型的性能可能会因应用场景而异。如果你需要更多信息，请告诉我！

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">文本嵌入模型的英文？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The English term for &#34;文本嵌入模型&#34; is &#34;text embedding models&#34;. Some of the most common text embedding models include Word2Vec, GloVe, FastText and Embeddings from Language Models (ELMo)[^1^] [^2^]. If you need more information about these models or any other text embedding models, please let me know!

---

[1]: https://techblog.ezra.com/different-embedding-models-7874197dc410 &#34;What are the common word embeddings? | The Ezra Tech Blog - Medium&#34;
[2]: https://openai.com/blog/introducing-text-and-code-embeddings/ &#34;Introducing text and code embeddings - OpenAI&#34;
[3]: https://www.deepset.ai/blog/the-beginners-guide-to-text-embeddings &#34;The Beginner’s Guide to Text Embeddings | deepset&#34;
[4]: https://platform.openai.com/docs/guides/embeddings/embedding-models &#34;Embeddings - OpenAI API&#34;

The English term for &#34;文本嵌入模型&#34; is &#34;text embedding models&#34;. Some of the most common text embedding models include Word2Vec, GloVe, FastText and Embeddings from Language Models (ELMo)[^1^][1] [^2^][2]. If you need more information about these models or any other text embedding models, please let me know!

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">InstructorEmbedding 是什么？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>InstructorEmbedding is a text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning[^1^]. It is a single embedder that can generate text embeddings tailored to different downstream tasks and domains[^1^]. InstructorEmbedding is available as a Python package[^2^]. If you need more information about InstructorEmbedding or any other text embedding models, please let me know!

---

[1]: https://instructor-embedding.github.io/ &#34;Instructor Text Embedding&#34;
[2]: https://pypi.org/project/InstructorEmbedding/ &#34;InstructorEmbedding · PyPI&#34;
[3]: https://python.langchain.com/en/latest/_modules/langchain/embeddings/huggingface.html &#34;langchain.embeddings.huggingface — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.135&#34;

InstructorEmbedding is a text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning[^1^][1]. It is a single embedder that can generate text embeddings tailored to different downstream tasks and domains[^1^][1]. InstructorEmbedding is available as a Python package[^2^][2]. If you need more information about InstructorEmbedding or any other text embedding models, please let me know!

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">比较 HuggingFaceInstructEmbeddings 和 HuggingFaceHubEmbeddings</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>HuggingFaceInstructEmbeddings and HuggingFaceHubEmbeddings are both wrappers around sentence_transformers embedding models[^2^] [^3^]. HuggingFaceInstructEmbeddings is a wrapper around InstructorEmbedding[^2^], while HuggingFaceHubEmbeddings is a wrapper around Hugging Face Hub embedding models[^3^]. To use HuggingFaceInstructEmbeddings, you should have the `sentence_transformers` and `InstructorEmbedding` Python packages installed[^2^]. To use HuggingFaceHubEmbeddings, you should have the `huggingface_hub` Python package installed and the environment variable `HUGGINGFACEHUB_API_TOKEN` set with your API token, or pass it as a named parameter to the constructor[^3^]. If you need more information about HuggingFaceInstructEmbeddings or HuggingFaceHubEmbeddings or any other text embedding models, please let me know!

---

[1]: https://huggingface.co/blog/getting-started-with-embeddings &#34;Getting Started With Embeddings - Hugging Face&#34;
[2]: https://python.langchain.com/en/latest/_modules/langchain/embeddings/huggingface.html &#34;langchain.embeddings.huggingface — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.135&#34;
[3]: https://sj-langchain.readthedocs.io/en/latest/reference/modules/embeddings.html &#34;Embeddings — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.94&#34;
[4]: https://stackoverflow.com/questions/64685243/getting-sentence-embedding-from-huggingface-feature-extraction-pipeline &#34;machine learning - Getting sentence embedding from huggingface Feature ...&#34;

HuggingFaceInstructEmbeddings and HuggingFaceHubEmbeddings are both wrappers around sentence_transformers embedding models[^1^][2] [^2^][3]. HuggingFaceInstructEmbeddings is a wrapper around InstructorEmbedding[^1^][2], while HuggingFaceHubEmbeddings is a wrapper around Hugging Face Hub embedding models[^2^][3]. To use HuggingFaceInstructEmbeddings, you should have the `sentence_transformers` and `InstructorEmbedding` Python packages installed[^1^][2]. To use HuggingFaceHubEmbeddings, you should have the `huggingface_hub` Python package installed and the environment variable `HUGGINGFACEHUB_API_TOKEN` set with your API token, or pass it as a named parameter to the constructor[^2^][3]. If you need more information about HuggingFaceInstructEmbeddings or HuggingFaceHubEmbeddings or any other text embedding models, please let me know!

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">sentence_transformers 的 GitHub 链接？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Here is the GitHub link for sentence_transformers: https://github.com/UKPLab/sentence-transformers [^1^] [^5^]. You can find more information about sentence_transformers and how to use it in your project by visiting this link. Let me know if you have any other questions!

---

[1]: https://github.com/taishan1994/sbert_text_similarity &#34;GitHub - taishan1994/sbert_text_similarity: 使用sentence-transformers ...&#34;
[2]: https://github.com/zhangyi24/sentence_transformer_zh &#34;GitHub - zhangyi24/sentence_transformer_zh&#34;
[3]: https://blog.csdn.net/RinaWong/article/details/122890394 &#34;安装sentence-transformers_竹霖聴雨的博客-CSDN博客&#34;
[4]: https://github.com/UKPLab/sentence-transformers &#34;UKPLab/sentence-transformers - Github&#34;
[5]: https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained_models.md &#34;sentence-transformers/pretrained_models.md at master · UKPLab ... - GitHub&#34;
[6]: https://github.com/huggingface/blog/blob/main/how-to-train-sentence-transformers.md &#34;blog/how-to-train-sentence-transformers.md at main - Github&#34;

Here is the GitHub link for sentence_transformers: https://github.com/UKPLab/sentence-transformers [^1^][1] [^2^][5]. You can find more information about sentence_transformers and how to use it in your project by visiting this link. Let me know if you have any other questions!

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">InstructorEmbedding 的 GitHub 链接？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Here is the GitHub link for InstructorEmbedding: https://github.com/HKUNLP/instructor-embedding [^1^] [^2^]. You can find more information about InstructorEmbedding and how to use it in your project by visiting this link. Let me know if you have any other questions!

---

[1]: https://pypi.org/project/InstructorEmbedding/ &#34;InstructorEmbedding · PyPI&#34;
[2]: https://github.com/HKUNLP/instructor-embedding &#34;GitHub - HKUNLP/instructor-embedding: One Embedder, Any Task ...&#34;
[3]: https://github.com/basujindal/chatPDF &#34;GitHub - basujindal/chatPDF: chat with PDF&#34;

Here is the GitHub link for InstructorEmbedding: https://github.com/HKUNLP/instructor-embedding [^1^][1] [^2^][2]. You can find more information about InstructorEmbedding and how to use it in your project by visiting this link. Let me know if you have any other questions!

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">比较 HuggingFaceInstructEmbeddings 和 LlamaCppEmbeddings</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>HuggingFaceInstructEmbeddings 和 LlamaCppEmbeddings 都是用于自然语言处理的嵌入式模型。HuggingFaceInstructEmbeddings 是 sentence_transformers 的包装器，而 LlamaCppEmbeddings 是 llama.cpp 嵌入式模型的包装器。这两个模型都可以用于生成文本嵌入，但是它们的实现方式和性能可能有所不同。如果您需要更多的信息，请访问它们的 GitHub 页面：https://github.com/HKUNLP/instructor-embedding [^1^] [^2^] 和 https://github.com/ggerganov/llama.cpp [^3^] 。

---

[1]: https://python.langchain.com/en/latest/_modules/langchain/embeddings/llamacpp.html &#34;langchain.embeddings.llamacpp — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.136&#34;
[2]: https://python.langchain.com/en/latest/_modules/langchain/embeddings/huggingface.html &#34;langchain.embeddings.huggingface — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.135&#34;
[3]: https://sj-langchain.readthedocs.io/en/latest/_modules/langchain/embeddings/huggingface.html &#34;langchain.embeddings.huggingface — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.94&#34;

HuggingFaceInstructEmbeddings 和 LlamaCppEmbeddings 都是用于自然语言处理的嵌入式模型。HuggingFaceInstructEmbeddings 是 sentence_transformers 的包装器，而 LlamaCppEmbeddings 是 llama.cpp 嵌入式模型的包装器。这两个模型都可以用于生成文本嵌入，但是它们的实现方式和性能可能有所不同。如果您需要更多的信息，请访问它们的 GitHub 页面：https://github.com/HKUNLP/instructor-embedding [^1^][1] [^2^][2] 和 https://github.com/ggerganov/llama.cpp [^3^][3] 。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">执行下面这段代码之后，HuggingFaceEmbeddings 的模型下载到哪里了？</span>
<span class="s1">```</span>
<span class="s1">from langchain.embeddings import HuggingFaceEmbeddings</span>

<span class="s1"># 准备文本</span>
<span class="s1">text = &#39;这是一个测试文档。&#39;</span>

<span class="s1"># 使用 HuggingFace 生成文本嵌入</span>
<span class="s1">embeddings = HuggingFaceEmbeddings()</span>
<span class="s1">query_result = embeddings.embed_query(text)</span>
<span class="s1">doc_result = embeddings.embed_documents([text])</span>
<span class="s1">```</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>HuggingFaceEmbeddings 的模型下载路径是本地缓存。当您第一次使用该模型时，它会自动缓存在本地。如果您想查看缓存的位置，可以运行以下代码：
```
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
print(tokenizer.cache_dir)
```
如果您想将模型下载到特定的文件夹中，可以使用以下代码：
```
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModel.from_pretrained(&#34;bert-base-uncased&#34;, cache_dir=&#34;my_folder&#34;)
```
希望这可以帮助到您！

---

[1]: https://python.langchain.com/en/latest/_modules/langchain/embeddings/huggingface.html &#34;langchain.embeddings.huggingface — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.135&#34;
[2]: https://stackoverflow.com/questions/67595500/how-to-download-model-from-huggingface &#34;How to download model from huggingface? - Stack Overflow&#34;
[3]: https://github.com/hwchase17/langchain/blob/master/langchain/embeddings/huggingface.py &#34;langchain/huggingface.py at master · hwchase17/langchain&#34;

HuggingFaceEmbeddings 的模型下载路径是本地缓存。当您第一次使用该模型时，它会自动缓存在本地。如果您想查看缓存的位置，可以运行以下代码：
```
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
print(tokenizer.cache_dir)
```
如果您想将模型下载到特定的文件夹中，可以使用以下代码：
```
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModel.from_pretrained(&#34;bert-base-uncased&#34;, cache_dir=&#34;my_folder&#34;)
```
希望这可以帮助到您！

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>
<span class="nb">dir</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">name_or_path</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;bert-base-uncased&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
ls<span class="w"> </span>-lah<span class="w"> </span>~/.cache/huggingface/hub/models--bert-base-uncased
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
total 0
drwxr-xr-x  6 saintway  staff   192B Apr 12 14:43 <span class="ansi-cyan-intense-fg ansi-bold">.</span>
drwxr-xr-x  6 saintway  staff   192B Apr 12 14:43 <span class="ansi-cyan-intense-fg ansi-bold">..</span>
drwxr-xr-x  3 saintway  staff    96B Apr 12 14:43 <span class="ansi-cyan-intense-fg ansi-bold">.no_exist</span>
drwxr-xr-x  6 saintway  staff   192B Apr 12 14:43 <span class="ansi-cyan-intense-fg ansi-bold">blobs</span>
drwxr-xr-x  3 saintway  staff    96B Apr 12 14:43 <span class="ansi-cyan-intense-fg ansi-bold">refs</span>
drwxr-xr-x  3 saintway  staff    96B Apr 12 14:43 <span class="ansi-cyan-intense-fg ansi-bold">snapshots</span>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
du<span class="w"> </span>-sh<span class="w"> </span>~/.cache/huggingface/hub/models--bert-base-uncased
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
696K	/Users/saintway/.cache/huggingface/hub/models--bert-base-uncased
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>If you're talking about vector database embeddings, check out <a target="_blank" rel="noopener" href="https://github.com/chroma-core/chroma">Chroma</a>.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.trychroma.com/">https://www.trychroma.com/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.trychroma.com/embeddings">https://docs.trychroma.com/embeddings</a></li>
</ul>
<hr />
<p>If you're talking about fine tuning, check out <a target="_blank" rel="noopener" href="https://github.com/tloen/alpaca-lora/blob/main/finetune.py">alpaca-lora finetuning</a>.</p>
<p>I recommend using <a target="_blank" rel="noopener" href="https://huggingface.co/Pi3141/gpt4-x-alpaca-native-13B-ggml">gpt4xalpaca</a> as a base model as it doesn't have the same level of censorship as vicuna. However, if you're using it purely for ethical tasks, vicuna is definitely better.</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/chavinlo/gpt4-x-alpaca">GPT4 x Alpaca</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">Chroma Embedding Database 是什么</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Chroma Embedding Database 是一个开源的嵌入式数据库，用于存储人工智能模型的嵌入[^1^]。嵌入是向量的集合。Chroma 的数据库专门用于存储 AI 模型的嵌入[^2^]。它允许您通过最近邻搜索而不是子字符串搜索来搜索嵌入[^3^]。默认情况下，Chroma 使用 Sentence Transformers 进行嵌入，但您也可以使用 OpenAI 嵌入、Cohere（多语言）嵌入或自己的嵌入[^3^]。

希望这可以帮助您了解 Chroma Embedding Database。

---

[1]: https://docs.trychroma.com/ &#34;\uD83C\uDFE1 Home | Chroma&#34;
[2]: https://siliconangle.com/2023/04/06/chroma-bags-18m-speed-ai-models-embedding-database/ &#34;Chroma bags $18M to speed up AI models with its embedding database&#34;
[3]: https://pypi.org/project/chromadb/ &#34;chromadb · PyPI&#34;
[4]: https://www.trychroma.com/ &#34;Chroma - the AI-native open-source embedding database&#34;
[5]: https://github.com/chroma-core/chroma &#34;GitHub - chroma-core/chroma: the open source embedding database&#34;

Chroma Embedding Database 是一个开源的嵌入式数据库，用于存储人工智能模型的嵌入[^1^][1]。嵌入是向量的集合。Chroma 的数据库专门用于存储 AI 模型的嵌入[^2^][2]。它允许您通过最近邻搜索而不是子字符串搜索来搜索嵌入[^3^][3]。默认情况下，Chroma 使用 Sentence Transformers 进行嵌入，但您也可以使用 OpenAI 嵌入、Cohere（多语言）嵌入或自己的嵌入[^3^][3]。

希望这可以帮助您了解 Chroma Embedding Database。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">ggml 是什么</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>ggml 是一个用于机器学习的张量库。该项目正在开发中，尚未准备好用于生产。它是用 C 语言编写的，支持 16 位浮点数和 4 位整数量化。它还支持自动微分（正在进行中）ADAM 和 L ...[^3^]。

希望这可以帮助到您！

---

[1]: https://gitee.com/mirrors/ggml &#34;ggml: ggml 是一个用于机器学习的张量库&#34;
[2]: https://www.oschina.net/p/ggml &#34;ggml首页、文档和下载 - 机器学习的张量库 - OSCHINA - 中文开源技术交流社区&#34;
[3]: https://github.com/ggerganov/ggml &#34;GitHub - ggerganov/ggml: Tensor library for machine learning&#34;
[4]: https://zhuanlan.zhihu.com/p/616037509 &#34;介绍大模型LLaMa及周边 - 知乎 - 知乎专栏&#34;
[5]: https://github.com/ggerganov/whisper.cpp &#34;ggerganov/whisper.cpp: Port of OpenAI&#39;s Whisper model in C/C++ - Github&#34;

ggml 是一个用于机器学习的张量库。该项目正在开发中，尚未准备好用于生产。它是用 C 语言编写的，支持 16 位浮点数和 4 位整数量化。它还支持自动微分（正在进行中）ADAM 和 L ...[^1^][3]。

希望这可以帮助到您！

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">HUGGINGFACEHUB_API_TOKEN 有什么用？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>HUGGINGFACEHUB_API_TOKEN 是一个环境变量，用于验证您的 API 令牌。您可以使用它来访问 Hugging Face Hub API，以便在您的模型中使用预训练模型、上传和下载模型等。[^1^] [^3^]

希望这可以帮助到您！

---

[1]: https://sj-langchain.readthedocs.io/en/latest/ecosystem/huggingface.html &#34;Hugging Face — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.94&#34;
[2]: https://zhuanlan.zhihu.com/p/344173246 &#34;用户身份验证的令牌——Token - 知乎 - 知乎专栏&#34;
[3]: https://github.com/hwchase17/langchain/blob/master/langchain/llms/huggingface_hub.py &#34;langchain/huggingface_hub.py at master · hwchase17/langchain&#34;

HUGGINGFACEHUB_API_TOKEN 是一个环境变量，用于验证您的 API 令牌。您可以使用它来访问 Hugging Face Hub API，以便在您的模型中使用预训练模型、上传和下载模型等。[^1^][1] [^2^][3]

希望这可以帮助到您！

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">Hugging Face Hub API 有什么用？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Hugging Face Hub API 是一个模型和数据集的存储库，可以让您轻松地共享、发现和使用模型和数据集。它提供了一组 API，可以让您从 Python 中上传、下载和管理模型和数据集。您可以使用 Hugging Face Hub API 来存储、共享和管理您的模型和数据集，也可以使用它来发现其他人共享的模型和数据集。[^1^]

Hugging Face Hub API 还提供了一些端点，您可以使用这些端点从 Hub 中检索信息，也可以执行某些操作，例如创建模型、数据集或 Space 存储库。[^1^]

---

[1]: https://huggingface.co/docs/hub/api &#34;https://\uE000huggingface\uE001.co/docs/\uE000hub\uE001/\uE000api\uE001&#34;

Hugging Face Hub API 是一个模型和数据集的存储库，可以让您轻松地共享、发现和使用模型和数据集。它提供了一组 API，可以让您从 Python 中上传、下载和管理模型和数据集。您可以使用 Hugging Face Hub API 来存储、共享和管理您的模型和数据集，也可以使用它来发现其他人共享的模型和数据集。[^1^][1]

Hugging Face Hub API 还提供了一些端点，您可以使用这些端点从 Hub 中检索信息，也可以执行某些操作，例如创建模型、数据集或 Space 存储库。[^1^][1]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">没有 HUGGINGFACEHUB_API_TOKEN 就不能使用 Hugging Face Hub API 吗？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>是的，Hugging Face Hub API 需要 HUGGINGFACEHUB_API_TOKEN。您需要在 Hugging Face 帐户设置中获取用户访问或 API 令牌。如果您在发送请求到 API 时不提交 API 令牌，则无法在私有模型上运行推理。[^1^] [^3^]

---

[1]: https://api-inference.huggingface.co/docs/python/html/quicktour.html &#34;Overview - Hugging Face&#34;
[2]: https://huggingface.co/docs/huggingface_hub/how-to-inference &#34;Access the Inference API - Hugging Face&#34;
[3]: https://python.langchain.com/en/latest/ecosystem/huggingface.html &#34;Hugging Face — \uD83E\uDD9C\uD83D\uDD17 LangChain 0.0.137&#34;
[4]: https://docs.fast.ai/huggingface.html &#34;fastai - Hugging Face Hub&#34;
[5]: https://zhuanlan.zhihu.com/p/619763221 &#34;HuggingGPT： 用ChatGPT和它的朋友在HuggingFace中解决AI任务 - 知乎&#34;

是的，Hugging Face Hub API 需要 HUGGINGFACEHUB_API_TOKEN。您需要在 Hugging Face 帐户设置中获取用户访问或 API 令牌。如果您在发送请求到 API 时不提交 API 令牌，则无法在私有模型上运行推理。[^1^][1] [^2^][3]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">没有 HUGGINGFACEHUB_API_TOKEN 就不能在 HuggingFace 下载模型吗？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>是的，您需要 HUGGINGFACEHUB_API_TOKEN 才能在 HuggingFace 下载模型。如果您在发送请求到 API 时不提交 API 令牌，则无法在私有模型上运行推理。[^1^] [^3^]

---

[1]: https://huggingface.co/docs/hub/security-tokens &#34;User access tokens - Hugging Face&#34;
[2]: https://blog.csdn.net/qq_41895747/article/details/125232359 &#34;解决ValueError: You need to pass a valid `token` or login by using ...&#34;
[3]: https://stackoverflow.com/questions/67595500/how-to-download-model-from-huggingface &#34;How to download model from huggingface? - Stack Overflow&#34;
[4]: https://zhuanlan.zhihu.com/p/475260268 &#34;如何优雅的下载huggingface-transformers模型 - 知乎 - 知乎专栏&#34;
[5]: https://juejin.cn/post/7220623225775095869 &#34;ILLA Cloud- 调用 Hugging Face Inference Endpoints，开启大模型世界之门 - 掘金&#34;

是的，您需要 HUGGINGFACEHUB_API_TOKEN 才能在 HuggingFace 下载模型。如果您在发送请求到 API 时不提交 API 令牌，则无法在私有模型上运行推理。[^1^][1] [^2^][3]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">在模型上运行推理是什么意思？训练模型是什么意思？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>在机器学习中，训练模型是指使用大量数据来训练模型，以便它可以自动地从新数据中进行预测。在训练期间，模型会根据输入数据进行调整，以便它可以更好地预测输出。训练完成后，模型就可以用于推理，也就是使用新数据进行预测。

推理是指使用训练好的模型来进行预测。在推理期间，模型会接收新的输入数据，并输出预测结果。推理通常比训练快得多，因为它不需要对模型进行调整。

希望这可以帮到你。如果你有其他问题，请随时问我。

---

在机器学习中，训练模型是指使用大量数据来训练模型，以便它可以自动地从新数据中进行预测。在训练期间，模型会根据输入数据进行调整，以便它可以更好地预测输出。训练完成后，模型就可以用于推理，也就是使用新数据进行预测。

推理是指使用训练好的模型来进行预测。在推理期间，模型会接收新的输入数据，并输出预测结果。推理通常比训练快得多，因为它不需要对模型进行调整。

希望这可以帮到你。如果你有其他问题，请随时问我。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">没有 HUGGINGFACEHUB_API_TOKEN 可以在 HuggingFace 下载他人公开的模型吗？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>HuggingFace 下载他人公开的模型不需要 HUGGINGFACEHUB_API_TOKEN。你可以通过以下方式下载他人公开的模型：

1. 通过 Hugging Face 官网下载，例如：https://huggingface.co/models
2. 通过 Transformers 库中的 from_pretrained 方法下载，例如：

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModelForSequenceClassification.from_pretrained(&#34;bert-base-uncased&#34;)
```

希望这可以帮到你。如果你有其他问题，请随时问我。

---

[1]: https://zhuanlan.zhihu.com/p/475260268 &#34;如何优雅的下载huggingface-transformers模型 - 知乎 - 知乎专栏&#34;
[2]: https://huggingface.co/inference-api &#34;Inference API - Hugging Face&#34;
[3]: https://zhuanlan.zhihu.com/p/448852278 &#34;【Huggingface Transformers】保姆级使用教程—上 - 知乎&#34;
[4]: https://pypi.org/project/huggingface-hub/ &#34;huggingface-hub · PyPI&#34;
[5]: https://stackoverflow.com/questions/67595500/how-to-download-model-from-huggingface &#34;How to download model from huggingface? - Stack Overflow&#34;

HuggingFace 下载他人公开的模型不需要 HUGGINGFACEHUB_API_TOKEN。你可以通过以下方式下载他人公开的模型：

1. 通过 Hugging Face 官网下载，例如：https://huggingface.co/models
2. 通过 Transformers 库中的 from_pretrained 方法下载，例如：

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModelForSequenceClassification.from_pretrained(&#34;bert-base-uncased&#34;)
```

希望这可以帮到你。如果你有其他问题，请随时问我。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">怎么用 Python 在 HuggingFace 下载模型？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>您可以使用以下代码在 HuggingFace 中下载模型：
```
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModelForSequenceClassification.from_pretrained(&#34;bert-base-uncased&#34;)
```
这将下载 BERT 模型和 tokenizer。

---

您可以使用以下代码在 HuggingFace 中下载模型：
```
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModelForSequenceClassification.from_pretrained(&#34;bert-base-uncased&#34;)
```
这将下载 BERT 模型和 tokenizer。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">在 HuggingFace 下载模型，如何断点续传？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>您可以使用以下代码在 HuggingFace 中断点续传下载模型：
```
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModelForSequenceClassification.from_pretrained(&#34;bert-base-uncased&#34;, resume_download=True)
```
这将下载 BERT 模型和 tokenizer，并在下载过程中断点续传。

---

[1]: https://zhuanlan.zhihu.com/p/475260268 &#34;https://zhuanlan.zhihu.com/p/475260268&#34;

您可以使用以下代码在 HuggingFace 中断点续传下载模型：
```
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(&#34;bert-base-uncased&#34;)
model = AutoModelForSequenceClassification.from_pretrained(&#34;bert-base-uncased&#34;, resume_download=True)
```
这将下载 BERT 模型和 tokenizer，并在下载过程中断点续传。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">await</span> <span class="n">ask</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">PyTorch 模型可以分成好几个 bin 文件吗？</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>PyTorch 模型可以分成多个文件，其中包括模型权重和其他模型参数。如果您的模型是由多个子模型组成的，则可以将每个子模型的权重和参数保存在单独的文件中。这些文件可以使用 PyTorch 的 state_dict 和 optimizer 保存在同一个文件中[^9^]. 

您可以使用以下代码将模型保存到多个文件中：

```python
torch.save(model.state_dict(), PATH)
```

其中，`model` 是您要保存的 PyTorch 模型，`PATH` 是您要保存的文件路径。这将会把模型权重和其他参数保存到一个名为 `PATH` 的文件中。

如果您想要加载这些文件并恢复模型，则可以使用以下代码：

```python
model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH))
```

其中，`TheModelClass` 是您要恢复的 PyTorch 模型类，`*args` 和 `**kwargs` 是用于初始化模型的参数。这将会从名为 `PATH` 的文件中加载模型权重和其他参数，并将它们加载到新创建的模型实例中。

希望这可以帮助您！请让我知道是否还有其他问题需要解答。

---

[1]: https://blog.csdn.net/qq_39686950/article/details/116090826 &#34;Windows系统下把PyTorch模型转为ncnn模型流程 - CSDN博客&#34;
[2]: https://blog.csdn.net/season77us/article/details/104311195 &#34;如何下载Hugging Face 模型（pytorch_model.bin, config.json, vocab.txt）以及如何在 ...&#34;
[3]: https://www.cnblogs.com/cxq1126/p/14277134.html &#34;将tensorflow版本的.ckpt模型转成pytorch的.bin模型 - 最咸的鱼 - 博客园&#34;
[4]: https://zhuanlan.zhihu.com/p/620688513 &#34;Pytorch格式 .pt .pth .bin 详解 - 知乎 - 知乎专栏&#34;
[5]: https://blog.csdn.net/znevegiveup1/article/details/118093294 &#34;读取pytorch.bin权重文件解读_pytorch_model.bin_唐僧爱吃唐僧肉的博客-CSDN博客&#34;
[6]: https://blog.csdn.net/A_water_/article/details/128197563 &#34;Pytorch框架的模型pth文件转换成C++ OpenVINO框架的bin和xml文件并运行_pth转bin_A_water_的博客-CSDN博客&#34;
[7]: https://zhuanlan.zhihu.com/p/113694038 &#34;PyTorch分布式训练简明教程(2022更新版) - 知乎 - 知乎专栏&#34;
[8]: https://zhuanlan.zhihu.com/p/82038049 &#34;PyTorch | 保存和加载模型 - 知乎&#34;
[9]: https://pytorch.org/tutorials/recipes/recipes/saving_multiple_models_in_one_file.html &#34;Saving and loading multiple models in one file using PyTorch&#34;

PyTorch 模型可以分成多个文件，其中包括模型权重和其他模型参数。如果您的模型是由多个子模型组成的，则可以将每个子模型的权重和参数保存在单独的文件中。这些文件可以使用 PyTorch 的 state_dict 和 optimizer 保存在同一个文件中[^1^][9]. 

您可以使用以下代码将模型保存到多个文件中：

```python
torch.save(model.state_dict(), PATH)
```

其中，`model` 是您要保存的 PyTorch 模型，`PATH` 是您要保存的文件路径。这将会把模型权重和其他参数保存到一个名为 `PATH` 的文件中。

如果您想要加载这些文件并恢复模型，则可以使用以下代码：

```python
model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH))
```

其中，`TheModelClass` 是您要恢复的 PyTorch 模型类，`*args` 和 `**kwargs` 是用于初始化模型的参数。这将会从名为 `PATH` 的文件中加载模型权重和其他参数，并将它们加载到新创建的模型实例中。

希望这可以帮助您！请让我知道是否还有其他问题需要解答。

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.faiss</span> <span class="kn">import</span> <span class="n">FAISS</span>

<span class="k">def</span> <span class="nf">get_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="c1"># (1) Import a series of documents.</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">TextLoader</span><span class="p">,</span> <span class="n">silent_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">raw_documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="c1"># (2) Split them into small chunks.</span>
    <span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
        <span class="n">chunk_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ingest_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">get_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
    <span class="c1"># (3) Create embeddings for each document (using text-embedding-ada-002).</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/ggml-model-q4_1.bin&#39;</span><span class="p">),</span> <span class="n">n_ctx</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">ingest_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 1024
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 3216.00 MB per state)
llama_init_from_file: kv self size  = 1600.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 58231.14 ms /   136 tokens (  428.17 ms per token)
llama_print_timings:        eval time =  1743.42 ms /     1 runs   ( 1743.42 ms per run)
llama_print_timings:       total time = 60005.23 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 178540.67 ms /   472 tokens (  378.26 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 178591.84 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 41458.73 ms /   139 tokens (  298.26 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 41490.46 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 13792.71 ms /    51 tokens (  270.45 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 13806.36 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 64205.43 ms /   192 tokens (  334.40 ms per token)
llama_print_timings:        eval time =   393.32 ms /     1 runs   (  393.32 ms per run)
llama_print_timings:       total time = 64615.16 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 312641.94 ms /   458 tokens (  682.62 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 312700.26 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 428699.27 ms /   478 tokens (  896.86 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 428799.03 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 268943.46 ms /   309 tokens (  870.37 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 268984.75 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 428036.12 ms /   648 tokens (  660.55 ms per token)
llama_print_timings:        eval time =   426.99 ms /     1 runs   (  426.99 ms per run)
llama_print_timings:       total time = 428658.90 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 10771.61 ms /    30 tokens (  359.05 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 10808.14 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 77845.98 ms /   109 tokens (  714.18 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 77920.76 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 31191.36 ms /   103 tokens (  302.83 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 31233.61 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 125583.51 ms /   111 tokens ( 1131.38 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 125624.03 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 26138.27 ms /    68 tokens (  384.39 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 26169.78 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 12869.16 ms /    35 tokens (  367.69 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 12877.02 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 349920.02 ms /   504 tokens (  694.29 ms per token)
llama_print_timings:        eval time =  1198.45 ms /     1 runs   ( 1198.45 ms per run)
llama_print_timings:       total time = 351175.09 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 235384.79 ms /   158 tokens ( 1489.78 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 235445.03 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 540504.96 ms /   542 tokens (  997.24 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 540623.58 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 351235.10 ms /   719 tokens (  488.51 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 351388.48 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 50923.63 ms /   165 tokens (  308.63 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 51015.38 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 184992.04 ms /   272 tokens (  680.12 ms per token)
llama_print_timings:        eval time =   411.72 ms /     1 runs   (  411.72 ms per run)
llama_print_timings:       total time = 185451.72 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 194429.41 ms /   622 tokens (  312.59 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 194464.86 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 113118.77 ms /   366 tokens (  309.07 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 113145.92 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 687028.24 ms /   728 tokens (  943.72 ms per token)
llama_print_timings:        eval time =   439.94 ms /     1 runs   (  439.94 ms per run)
llama_print_timings:       total time = 687586.24 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 189149.69 ms /   533 tokens (  354.88 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 189193.56 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 191291.91 ms /   560 tokens (  341.59 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 191325.52 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 262665.41 ms /   725 tokens (  362.30 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 262699.98 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 446825.63 ms /   744 tokens (  600.57 ms per token)
llama_print_timings:        eval time =  2820.09 ms /     1 runs   ( 2820.09 ms per run)
llama_print_timings:       total time = 449699.31 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 370878.55 ms /   717 tokens (  517.26 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 370985.32 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 316657.40 ms /   647 tokens (  489.42 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 316701.04 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 355381.24 ms /   504 tokens (  705.12 ms per token)
llama_print_timings:        eval time =   426.32 ms /     1 runs   (  426.32 ms per run)
llama_print_timings:       total time = 355866.70 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 306588.42 ms /   559 tokens (  548.46 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 306644.46 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 388570.23 ms /   565 tokens (  687.73 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 388642.65 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 123319.83 ms /   318 tokens (  387.80 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 123356.07 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 329182.49 ms /   811 tokens (  405.90 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 329242.86 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 210174.59 ms /   584 tokens (  359.89 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 210206.57 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 81113.52 ms /   286 tokens (  283.61 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 81134.54 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 439253.03 ms /   727 tokens (  604.20 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 439387.22 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 286354.39 ms /   751 tokens (  381.30 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 286420.33 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 444201.68 ms /   675 tokens (  658.08 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 444267.37 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 607155.44 ms /   620 tokens (  979.28 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 607229.15 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 674110.08 ms /   708 tokens (  952.13 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 674200.48 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 329078.28 ms /   470 tokens (  700.17 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 329136.29 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 774982.77 ms /   734 tokens ( 1055.83 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 775084.90 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1736656.90 ms /   767 tokens ( 2264.22 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1736891.33 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1348035.02 ms /   608 tokens ( 2217.16 ms per token)
llama_print_timings:        eval time = 24584.54 ms /     1 runs   (24584.54 ms per run)
llama_print_timings:       total time = 1372887.22 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1395140.63 ms /   472 tokens ( 2955.81 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1395354.86 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2404735.92 ms /   808 tokens ( 2976.16 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2405157.08 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1788561.84 ms /   640 tokens ( 2794.63 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1788744.43 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2043317.53 ms /   690 tokens ( 2961.33 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2043549.39 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1295899.29 ms /   402 tokens ( 3223.63 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1296069.46 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1882245.78 ms /   592 tokens ( 3179.47 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1882491.04 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 2343689.96 ms /   741 tokens ( 3162.87 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 2343993.29 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 1234739.82 ms /   490 tokens ( 2519.88 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 1234957.50 ms

llama_print_timings:        load time =  8850.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 86554.06 ms /    53 tokens ( 1633.10 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 86652.29 ms
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="c1"># Save vectorstore</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vectorstore_13B_1024.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vectorstore</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="c1"># Load vectorstore</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vectorstore_13B_1024.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 1024
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 3216.00 MB per state)
llama_init_from_file: kv self size  = 1600.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;你知道什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get context related to the question from the embedding model</span>
<span class="k">for</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>page_content=&#39;&gt; 现在我们知道，事实上应当承认在主观的质和推断出来的客观世界之间有一种确切规定的、一义的配列关系。大量的经验材料告诉我们，我们可以发现，至少必须假设与所有经验唯一地联系着的“物理的”过程的存在。没有什么意识的质不可能受到作用于身体的力的影响。的确，我们甚至能够用一种简单的物理方法，例如吸进一种气体，就把意识全部消除掉。我们的行动与我们的意志经验相联系，幻觉与身体的疲惫相联系，抑郁症的发作与消化的紊乱相联系。为了研究这类相互联系，心的理论必须抛弃纯粹内省的方法而成为**生理的**心理学。只有这个学科才能在理论上达到对心理的东西的完全的知识。借助于这样一种心理学，我们就可以用概念和所与的主观的质相配列，正如我们能够用概念与推论出来的客观的质相配列一样。这样，主观的质就像客观的质一样成为可知的了。&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

page_content=&#39;态度：认同、欣赏、尊重、重视、轻视、忽视、鄙视、反对\n客体所做：我对你的态度、你对我的态度、你对他的态度\n主体所想：我对你的态度、你对我的态度\n主体所说：我对他的态度、他对我的态度、他对你的态度\n对于某些次态度的记忆、拟构；怀疑、与、确信；\n你对我的态度、有正有误；作为某种主体效果的客体态度，对于客体态度的目标、意向；对于态度的态度、有正有误；\n渴望被重视、被认可、被理解、被公正地对待；\n虚荣；自负，轻视，反对、有正有误，对于他人的误解；对于自己态度的温和的怀疑；苏格拉底式教学法；偏见、综合比较，是，某种轻视；\n我对客体的态度：你对我的态度、你的确信，我的确信、我对你的态度；确信、对于确信的态度；我对自己的态度，耻辱之恨、丑陋之恨\n对于某种经历的认同。对于某种人生概括的认同。省略主语、所有格。怕丑。\n注意，是，自由的。？我是谁？&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/终极真实.md&#39;}

page_content=&#39;&gt; 我们刚刚知道自然科学借以掌握质的方法––形成量的概念的方法。我们必须提出的问题是，这种方法是不是也能够适用于主观的意识的质。按照我们前面所说，为了使这种方法能够加以运用，必须有与这些质充分确定地、唯一地联系着的空间变化。如果情况真的如此，那么这个问题就可以通过空间–时间的重合方法来解决，因而**测量**便是可能的。但是，这种重合的方法本质上就是进行物理的观察，而就内省法来说，却不存在物理的观察这种事情。由此立刻就可以得出结论：心理学沿着内省的途径决不可能达到知识的理想。因此，它必须尽量使用物理的观察方法来达到它的目的。但这是不是可能的呢？是不是有依存于意识的质的空间变化，就像例如在光学中干涉带的宽度依存于颜色，在电学中磁铁的偏转度依存于磁场的强度那样呢？&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

page_content=&#39;---\n\n&gt; \u3000\u3000有些权威认为，有必要把意识的内容 (content) 与“有意识状态的特性” (quality of being conscious) 或“意识本身” (consciousness as such) 区分开来²。这一划分与我的分类异曲同工。\n\u3000\u3000要想产生意识，必须先具备某些神经前提条件。我把这些条件称为 NCC_e。任一特定知觉的 NCC 都是局部作用的、高度特化的、转瞬即逝的，相比起来，NCC_e 的作用方式更全局化也更持久。要是没有相关的 NCC_e 的话，机体或许也还能有简单的行为，但在这样做时绝不会有意识（可能发生这种情形的某些病理条件将在第13章讨论）。根据定义可知，如果没有 NCC_e，就不可能形成任何 NCC。\n\u3000\u3000会不会有这样一种状态，即生物体虽然有意识，却意识不到任何具体内容？换句话说，NCC_e 能否脱离 NCC 而单独存在呢？某些冥想的目标就是要进入这种没有具体内容的意识形式³。但是在目前，还很难对它进行严格的分析。&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 15863.30 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 15862.61 ms /     8 tokens ( 1982.83 ms per token)
llama_print_timings:        eval time = 23200.83 ms /     1 runs   (23200.83 ms per run)
llama_print_timings:       total time = 39067.66 ms
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains.llm</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.callbacks.base</span> <span class="kn">import</span> <span class="n">CallbackManager</span>
<span class="kn">from</span> <span class="nn">langchain.callbacks.streaming_stdout</span> <span class="kn">import</span> <span class="n">StreamingStdOutCallbackHandler</span>
<span class="kn">from</span> <span class="nn">langchain.chains.chat_vector_db.prompts</span> <span class="kn">import</span> <span class="n">CONDENSE_QUESTION_PROMPT</span><span class="p">,</span> <span class="n">QA_PROMPT</span>
<span class="kn">from</span> <span class="nn">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.base</span> <span class="kn">import</span> <span class="n">VectorStore</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationalRetrievalChain</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Callback function to stream answers to stdout.</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">CallbackManager</span><span class="p">([</span><span class="n">StreamingStdOutCallbackHandler</span><span class="p">()])</span>

<span class="n">streaming_llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">manager</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">question_gen_llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">manager</span><span class="p">)</span>
<span class="c1"># Prompt to generate independent questions by incorporating chat history and a new question.</span>
<span class="n">question_generator</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">question_gen_llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">CONDENSE_QUESTION_PROMPT</span><span class="p">)</span>
<span class="c1"># Pass in documents and a standalone prompt to answer questions.</span>
<span class="n">doc_chain</span> <span class="o">=</span> <span class="n">load_qa_chain</span><span class="p">(</span><span class="n">streaming_llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s1">&#39;stuff&#39;</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">QA_PROMPT</span><span class="p">)</span>
<span class="c1"># Generate prompts from embedding model.</span>
<span class="n">qa</span> <span class="o">=</span> <span class="n">ConversationalRetrievalChain</span><span class="p">(</span><span class="n">retriever</span><span class="o">=</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span> <span class="n">combine_docs_chain</span><span class="o">=</span><span class="n">doc_chain</span><span class="p">,</span> <span class="n">question_generator</span><span class="o">=</span><span class="n">question_generator</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">QA_PROMPT</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>PromptTemplate(input_variables=[&#39;context&#39;, &#39;question&#39;], output_parser=None, partial_variables={}, template=&#34;Use the following pieces of context to answer the question at the end. If you don&#39;t know the answer, just say that you don&#39;t know, don&#39;t try to make up an answer.\n\n{context}\n\nQuestion: {question}\nHelpful Answer:&#34;, template_format=&#39;f-string&#39;, validate_template=True)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>Utilizing <a target="_blank" rel="noopener" href="https://github.com/seii-saintway/ipymock">iPyMock</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在 PyTest 中，可以使用 <code>monkeypatch</code> 来替换导入的库，从而进行测试。 <code>monkeypatch</code> 是一个 pytest 内置的 fixture，用于替换运行时的变量和对象，以便在测试期间使用自定义值。</p>
<p>对于要替换的库，可以使用 <code>pytest_mock</code> fixture 来自动将其传递给 <code>monkeypatch</code>。如果没有使用 <code>pytest_mock</code>，则需要手动使用 <code>monkeypatch.setattr()</code> 方法来替换导入的库。</p>
<p>以下是一个示例，假设我们有一个名为 <code>example.py</code> 的模块，它导入了 <code>requests</code> 库，并使用了该库的 <code>get()</code> 方法发送网络请求：</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">get_example_data</span><span class="p">():</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://example.com&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span>
</pre></div>
<p>要测试这个函数，我们需要使用 Dummy 对象替换 requests 库，以便我们可以模拟网络请求的响应。可以使用以下代码进行测试：</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">example</span>

<span class="k">class</span> <span class="nc">DummyResponse</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">content</span> <span class="o">=</span> <span class="n">content</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">mock_requests</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">mock_get</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DummyResponse</span><span class="p">(</span><span class="sa">b</span><span class="s1">&#39;Test data&#39;</span><span class="p">)</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="n">requests</span><span class="p">,</span> <span class="s1">&#39;get&#39;</span><span class="p">,</span> <span class="n">mock_get</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_get_example_data</span><span class="p">(</span><span class="n">mock_requests</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">example</span><span class="o">.</span><span class="n">get_example_data</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">data</span> <span class="o">==</span> <span class="sa">b</span><span class="s1">&#39;Test data&#39;</span>
</pre></div>
<p>在这个示例中，我们首先定义了一个名为 <code>DummyResponse</code> 的类，它代表了一个虚拟的 requests 库的响应。然后我们定义了一个名为 <code>mock_requests</code> 的 fixture，它使用 <code>monkeypatch.setattr()</code> 方法替换了 requests 库的 <code>get()</code> 方法，使其返回我们定义的 DummyResponse 对象。</p>
<p>最后，我们定义了一个测试函数 <code>test_get_example_data</code>，并将 <code>mock_requests</code> fixture 作为参数传递给它。在测试函数内部，我们调用 <code>example.get_example_data()</code>，这将调用我们已经用 Dummy 对象替换的 requests 库的 <code>get()</code> 方法，最终返回我们定义的虚拟响应。</p>
<p>这样我们就可以在测试中使用 Dummy 对象替换任何库，以便更好地控制测试环境。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Help on method create in module openai.api_resources.chat_completion:

create(*args, **kwargs) method of builtins.type instance
    Creates a new chat completion for the provided messages and parameters.
    
    See https://platform.openai.com/docs/api-reference/chat-completions/create
    for a list of valid parameters.

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">revChatGPT.V1</span> <span class="kn">import</span> <span class="n">Chatbot</span><span class="p">,</span> <span class="n">configure</span>

<span class="c1"># Open the JSON file and read the conversation_id</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/.config/revChatGPT/config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;conversation_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">bot</span> <span class="o">=</span> <span class="n">Chatbot</span><span class="p">(</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">configure</span><span class="p">(),</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="n">conversation_id</span><span class="p">,</span>
    <span class="n">lazy_loading</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>git+https://github.com/seii-saintway/ipymock
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">markdown</span>
<span class="kn">import</span> <span class="nn">IPython</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb">How to stream completions?</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">delta</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="c1"># IPython.display.display(IPython.core.display.Markdown(response[&#39;message&#39;]))</span>
        <span class="c1"># IPython.display.clear_output(wait=True)</span>
        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="s1">&#39;delta&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">):],</span>
                    <span class="p">}</span>
                <span class="p">}</span>
            <span class="p">],</span>
        <span class="p">}</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">mock_create</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;messages&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">message</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[{}],</span>
        <span class="p">}</span>

    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;stream&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">delta</span><span class="p">(</span><span class="n">message</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="n">message</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]):</span>
        <span class="c1"># IPython.display.display(IPython.core.display.Markdown(response[&#39;message&#39;]))</span>
        <span class="c1"># IPython.display.clear_output(wait=True)</span>
        <span class="k">pass</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;finish_reason&#39;</span><span class="p">:</span> <span class="s1">&#39;stop&#39;</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;message&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;assistant&#39;</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">],</span>
    <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">mock_openai</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="p">,</span> <span class="s1">&#39;create&#39;</span><span class="p">,</span> <span class="n">mock_create</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;终极真实是什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">answer</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_qa</span><span class="p">(</span><span class="n">mock_openai</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">answer</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">qa</span><span class="p">({</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;chat_history&#39;</span><span class="p">:</span> <span class="p">[]})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ipymock</span> <span class="kn">import</span> <span class="n">do</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do</span><span class="p">(</span>
    <span class="n">mock_openai</span><span class="o">=</span><span class="n">mock_openai</span><span class="p">,</span>
    <span class="n">test_qa</span><span class="o">=</span><span class="n">test_qa</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
=&gt; no.0  ::source::test_qa  setup  passed

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 14550.38 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 23539.97 ms /    15 tokens ( 1569.33 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 23551.68 ms
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The author argues that to study the interconnections between subjective experiences and physical processes, we need to move away from purely introspective methods and embrace physiological psychology. Only through this approach can we achieve a complete understanding of psychological phenomena. The author also suggests that consciousness is inextricably linked to physical processes and can be affected by them.

=&gt; no.0  ::source::test_qa  runtest  passed

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">answer</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;question&#39;: &#39;终极真实是什么？&#39;,
 &#39;chat_history&#39;: [],
 &#39;answer&#39;: &#39;The author argues that to study the interconnections between subjective experiences and physical processes, we need to move away from purely introspective methods and embrace physiological psychology. Only through this approach can we achieve a complete understanding of psychological phenomena. The author also suggests that consciousness is inextricably linked to physical processes and can be affected by them.&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
 




<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/C9b_oZu9jpw0oObEuDmd9w">ColossalAI</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hpcaitech/ColossalAI">https://github.com/hpcaitech/ColossalAI</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/LCGQyNA6sHcdfIIARSNlww">LMFlow</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/OptimalScale/LMFlow">https://github.com/OptimalScale/LMFlow</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://chat.lmsys.org/">Chat with Open Large Language Models</a><ul>
<li>Vicuna: a chat assistant fine-tuned from LLaMA on user-shared conversations. This one is expected to perform best according to our evaluation.</li>
<li>Koala: a chatbot fine-tuned from LLaMA on user-shared conversations and open-source datasets. This one performs similarly to Vicuna.</li>
<li>ChatGLM: an open bilingual dialogue language model | 开源双语对话语言模型</li>
<li>Alpaca: a model fine-tuned from LLaMA on 52K instruction-following demonstrations.</li>
<li>LLaMA: open and efficient foundation language models</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.13971">LLaMA: Open and Efficient Foundation Language Models</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/llama">Inference code for LLaMA models</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp">LLaMA Cpp</a><ul>
<li><a target="_blank" rel="noopener" href="https://til.simonwillison.net/llms/llama-7b-m2">Running LLaMA 7B and 13B on a 64GB M2 MacBook Pro with llama.cpp</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/modules/models/llms/integrations/llamacpp.html">Streaming with llama.cpp</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://vicuna.lmsys.org/">Vicuna: An Open-Source Chatbot</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/lmsys">Vicuna Models: 7b-delta-v0 and 13b-delta-v0</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/lm-sys/FastChat">FastChat: An open platform for training, serving, and evaluating large language model based chatbots.</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong, Replicable Instruction-Following Model</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/stanford_alpaca">Train Stanford's Alpaca Models</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/tloen/alpaca-lora">Instruct-tuned Alpaca-LoRA Models</a><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/tloen/alpaca-lora/blob/main/finetune.py">Alpaca-LoRA Instruct-tuning</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/nomic-ai/gpt4all">GPT4All: an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMA</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I recommend using <a target="_blank" rel="noopener" href="https://huggingface.co/Pi3141/gpt4-x-alpaca-native-13B-ggml">gpt4 x alpaca ggml</a> as a base model as it doesn't have the same level of censorship as vicuna. However, if you're using it purely for ethical tasks, vicuna is definitely better.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/chavinlo/alpaca-native">Stanford Alpaca Model</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/chavinlo/alpaca-13b">Alpaca 13B without LoRA</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/chavinlo/gpt4-x-alpaca">GPT4 x Alpaca without LoRA</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">hf_hub_download</span>
<span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s1">&#39;Pi3141/alpaca-lora-7B-ggml&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;ggml-model-q4_0.bin&#39;</span><span class="p">,</span> <span class="n">resume_download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading ggml-model-q4_0.bin:   0%|          | 0.00/4.21G [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;/Users/saintway/.cache/huggingface/hub/models--Pi3141--alpaca-lora-7B-ggml/snapshots/fec53813efae6495f9b1f14aa4dedffc07bbf2e0/ggml-model-q4_0.bin&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">hf_hub_download</span>
<span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s1">&#39;Pi3141/alpaca-lora-7B-ggml&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;ggml-model-q4_1.bin&#39;</span><span class="p">,</span> <span class="n">resume_download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Downloading ggml-model-q4_1.bin:   0%|          | 0.00/5.06G [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;/Users/saintway/.cache/huggingface/hub/models--Pi3141--alpaca-lora-7B-ggml/snapshots/fec53813efae6495f9b1f14aa4dedffc07bbf2e0/ggml-model-q4_1.bin&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>llama-cpp-python<span class="o">[</span>server<span class="o">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
<span class="nb">export</span><span class="w"> </span><span class="nv">MODEL</span><span class="o">=</span>~/ggml-model-q4_1.bin
python3<span class="w"> </span>-m<span class="w"> </span>llama_cpp.server
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 2048
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 1608.00 MB per state)
llama_init_from_file: kv self size  = 1600.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 
INFO:     Started server process [41176]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:     ::1:61438 - &#34;GET / HTTP/1.1&#34; 404 Not Found
INFO:     ::1:61438 - &#34;GET /docs HTTP/1.1&#34; 200 OK
INFO:     ::1:61438 - &#34;GET /openapi.json HTTP/1.1&#34; 200 OK
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 11679.89 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 240847.82 ms /   478 tokens (  503.87 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 240873.74 ms
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:     ::1:61439 - &#34;POST /v1/embeddings HTTP/1.1&#34; 200 OK
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 11679.89 ms
llama_print_timings:      sample time =    33.43 ms /    16 runs   (    2.09 ms per run)
llama_print_timings: prompt eval time = 255305.21 ms /   478 tokens (  534.11 ms per token)
llama_print_timings:        eval time = 28069.18 ms /    15 runs   ( 1871.28 ms per run)
llama_print_timings:       total time = 283470.31 ms
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:     ::1:61681 - &#34;POST /v1/completions HTTP/1.1&#34; 200 OK
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">llama_cpp</span> <span class="kn">import</span> <span class="n">Llama</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/ggml-model-q4_1.bin&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 5120
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 40
llama_model_load_internal: n_layer    = 40
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 13824
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 13B
llama_model_load_internal: ggml ctx size =  73.73 KB
llama_model_load_internal: mem required  = 11359.03 MB (+ 3216.00 MB per state)
llama_init_from_file: kv self size  =  800.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">llm</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;&gt; 我们刚刚知道自然科学借以掌握质的方法––形成量的概念的方法。我们必须提出的问题是，这种方法是不是也能够适用于主观的意识的质。按照我们前面所说，为了使这种方法能够加以运用，必须有与这些质充分确定地、唯一地联系着的空间变化。如果情况真的如此，那么这个问题就可以通过空间–时间的重合方法来解决，因而**测量**便是可能的。但是，这种重合的方法本质上就是进行物理的观察，而就内省法来说，却不存在物理的观察这种事情。由此立刻就可以得出结论：心理学沿着内省的途径决不可能达到知识的理想。因此，它必须尽量使用物理的观察方法来达到它的目的。但这是不是可能的呢？是不是有依存于意识的质的空间变化，就像例如在光学中干涉带的宽度依存于颜色，在电学中磁铁的偏转度依存于磁场的强度那样呢？&#39;&#39;&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">llm</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;&gt; 现在我们知道，事实上应当承认在主观的质和推断出来的客观世界之间有一种确切规定的、一义的配列关系。大量的经验材料告诉我们，我们可以发现，至少必须假设与所有经验唯一地联系着的“物理的”过程的存在。没有什么意识的质不可能受到作用于身体的力的影响。的确，我们甚至能够用一种简单的物理方法，例如吸进一种气体，就把意识全部消除掉。我们的行动与我们的意志经验相联系，幻觉与身体的疲惫相联系，抑郁症的发作与消化的紊乱相联系。为了研究这类相互联系，心的理论必须抛弃纯粹内省的方法而成为**生理的**心理学。只有这个学科才能在理论上达到对心理的东西的完全的知识。借助于这样一种心理学，我们就可以用概念和所与的主观的质相配列，正如我们能够用概念与推论出来的客观的质相配列一样。这样，主观的质就像客观的质一样成为可知的了。&#39;&#39;&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="c1"># (1) Import a series of documents.</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">TextLoader</span><span class="p">,</span> <span class="n">silent_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">raw_documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="c1"># (2) Split them into small chunks.</span>
    <span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
        <span class="n">chunk_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.faiss</span> <span class="kn">import</span> <span class="n">FAISS</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ingest_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">get_docs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
    <span class="c1"># (3) Create embeddings for each document (using text-embedding-ada-002).</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span>
        <span class="s1">&#39;~/.cache/huggingface/hub/models--Pi3141--alpaca-lora-7B-ggml/snapshots/fec53813efae6495f9b1f14aa4dedffc07bbf2e0/ggml-model-q4_1.bin&#39;</span>
    <span class="p">),</span> <span class="n">n_ctx</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">ingest_docs</span><span class="p">(</span><span class="s1">&#39;_posts/ultimate-facts&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/.cache/huggingface/hub/models--Pi3141--alpaca-lora-7B-ggml/snapshots/fec53813efae6495f9b1f14aa4dedffc07bbf2e0/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 2048
llama_model_load_internal: n_embd     = 4096
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 32
llama_model_load_internal: n_layer    = 32
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 11008
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 7B
llama_model_load_internal: ggml ctx size =  59.11 KB
llama_model_load_internal: mem required  = 6612.57 MB (+ 2052.00 MB per state)
llama_init_from_file: kv self size  = 2048.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 121567.27 ms /   607 tokens (  200.28 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 121578.08 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 55477.99 ms /   384 tokens (  144.47 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 55490.11 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 185983.50 ms /  1245 tokens (  149.38 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 185993.29 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 99895.20 ms /   648 tokens (  154.16 ms per token)
llama_print_timings:        eval time =   274.67 ms /     1 runs   (  274.67 ms per run)
llama_print_timings:       total time = 100174.12 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time =  4480.73 ms /    30 tokens (  149.36 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time =  4483.89 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 34421.56 ms /   208 tokens (  165.49 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 34428.46 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 18916.80 ms /   115 tokens (  164.49 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 18922.95 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 109097.79 ms /   672 tokens (  162.35 ms per token)
llama_print_timings:        eval time =   322.11 ms /     1 runs   (  322.11 ms per run)
llama_print_timings:       total time = 109426.49 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 182994.18 ms /  1131 tokens (  161.80 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 183004.98 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 159320.01 ms /  1040 tokens (  153.19 ms per token)
llama_print_timings:        eval time =   239.12 ms /     1 runs   (  239.12 ms per run)
llama_print_timings:       total time = 159568.61 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 239876.70 ms /  1530 tokens (  156.78 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 239888.82 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 217347.31 ms /  1428 tokens (  152.20 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 217358.50 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 191811.75 ms /  1255 tokens (  152.84 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 191821.81 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 226394.03 ms /  1406 tokens (  161.02 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 226403.94 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 250274.44 ms /  1514 tokens (  165.31 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 250290.90 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 245848.18 ms /  1459 tokens (  168.50 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 245869.09 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 241036.46 ms /  1448 tokens (  166.46 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 241046.69 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 90638.96 ms /   549 tokens (  165.10 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 90648.73 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 243383.44 ms /  1456 tokens (  167.16 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 243395.79 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 66549.32 ms /   407 tokens (  163.51 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 66557.07 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 254780.55 ms /  1524 tokens (  167.18 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 254791.22 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 63349.78 ms /   397 tokens (  159.57 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 63354.36 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 174274.05 ms /  1092 tokens (  159.59 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 174282.70 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 194346.63 ms /  1332 tokens (  145.91 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 194358.84 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 69352.89 ms /   490 tokens (  141.54 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 69357.43 ms

llama_print_timings:        load time =  9764.51 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time =  7361.54 ms /    53 tokens (  138.90 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time =  7371.77 ms
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I need a big memory to accelerate LLM inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Save vectorstore</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vectorstore_7B_2048.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vectorstore</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load vectorstore</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vectorstore_7B_2048.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>llama.cpp: loading model from /Users/saintway/.cache/huggingface/hub/models--Pi3141--alpaca-lora-7B-ggml/snapshots/fec53813efae6495f9b1f14aa4dedffc07bbf2e0/ggml-model-q4_1.bin
llama_model_load_internal: format     = ggjt v1 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 2048
llama_model_load_internal: n_embd     = 4096
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 32
llama_model_load_internal: n_layer    = 32
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: f16        = 3
llama_model_load_internal: n_ff       = 11008
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 7B
llama_model_load_internal: ggml ctx size =  59.11 KB
llama_model_load_internal: mem required  = 6612.57 MB (+ 2052.00 MB per state)
llama_init_from_file: kv self size  = 2048.00 MB
AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;你知道什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get context related to the question from the embedding model</span>
<span class="k">for</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>page_content=&#39;title: Neuroscience\ndate: 2021-10-14 16:30:20\ntags: Neuro\n---\n\nThe [**ventral tegmental area**](https://en.wikipedia.org/wiki/Ventral_tegmental_area) (**VTA**) (**tegmentum** is Latin for covering), also known as the **ventral tegmental area of Tsai**, or simply **ventral tegmentum**, is a group of neurons located close to the midline on the floor of the midbrain.\n\n---\n\n&gt; \u3000\u3000有些权威认为，有必要把意识的内容 (content) 与“有意识状态的特性” (quality of being conscious) 或“意识本身” (consciousness as such) 区分开来²。这一划分与我的分类异曲同工。\n\u3000\u3000要想产生意识，必须先具备某些神经前提条件。我把这些条件称为 NCC_e。任一特定知觉的 NCC 都是局部作用的、高度特化的、转瞬即逝的，相比起来，NCC_e 的作用方式更全局化也更持久。要是没有相关的 NCC_e 的话，机体或许也还能有简单的行为，但在这样做时绝不会有意识（可能发生这种情形的某些病理条件将在第13章讨论）。根据定义可知，如果没有 NCC_e，就不可能形成任何 NCC。\n\u3000\u3000会不会有这样一种状态，即生物体虽然有意识，却意识不到任何具体内容？换句话说，NCC_e 能否脱离 NCC 而单独存在呢？某些冥想的目标就是要进入这种没有具体内容的意识形式³。但是在目前，还很难对它进行严格的分析。&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

page_content=&#39;有意注意，是指，对于某次效果的注意。\n无意注意，是指，对于某次非效果的注意。\n\n目标，是指，对于某种效果的某些次记忆所联结着的对于此种效果的拟构。\n意向，是指，对于某些种效果的某些次记忆所联结着的对于某种效果的拟构。\n\n懊悔，是指，对于某次弊害效果的某次记忆、对于某次功效的某次记忆所联结着的对于某次功效的拟构。\n焦虑，是指，对于某次弊害效果的某次记忆、对于某次功效的某次意向所联结着的对于某次弊害效果的拟构。\n\n对于某次功效的目标，联结着，对于此次功效的原因。\n对于某种功效的概括，联结着，对于此种功效的原因。\n\n兴趣，是指，联结着某次快乐的识。\n荒诞，是指，联结着某次乏味的识。\n苦毒，是指，联结着某次痛苦的识。\n\n慾望，是指，对于某次兴趣的表征。\n妄想，是指，对于某次荒诞的表征。？\n苦观，是指，对于某次苦毒的表征。\n\n苦观，分为，记忆苦观、拟构苦观。弊害，…、…\n\n有趣注意，是指，对于某次兴趣的注意。\n无趣注意，是指，对于某次荒诞的注意。\n\n意义，是指，值得的注意。\n神圣，是指，极其丰富的意义。\n积极的态度，是指，充满对于某种意义的信心。\n消极的态度，是指，缺乏对于某种意义的信心。\n积极的注意，导致着，快乐。\n消极的注意，导致着，乏味。\n对于某种意义的怀疑，是指，对于某种意义的信心的减弱。\n对于某种意义的确定，是指，对于某种意义的信心的增强。\n对于某种意义的静思，是指，对于某种意义的减弱。对于某种意义的静思，导致着，忧郁。\n对于某种意义的禅修，是指，对于某种意义的增强。对于某种意义的禅修，导致着，幸福。\n静思、禅修、祷告，都是，某种定觉练习。\n\n---\n\n&gt; 因为我们得了救是因着盼望。只是所盼望的若已得看见，便不是盼望了；因为人所看见的、他何必还盼望呢？但我们若盼望所未看见的，就必坚忍切候着。\n(罗马书 8:24-25 吕振中)\n\n&gt; 所以青春性的私欲、你总要逃避；你要跟那些用洁净心呼求主的人一同追求正义、忠信、仁爱、和平。\n(提摩太后书 2:22 吕振中)\n\n向内往最深处去：净心、呼求主名、并且、等待回应。&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/终极真实.md&#39;}

page_content=&#39;&gt; 我们刚刚知道自然科学借以掌握质的方法––形成量的概念的方法。我们必须提出的问题是，这种方法是不是也能够适用于主观的意识的质。按照我们前面所说，为了使这种方法能够加以运用，必须有与这些质充分确定地、唯一地联系着的空间变化。如果情况真的如此，那么这个问题就可以通过空间–时间的重合方法来解决，因而**测量**便是可能的。但是，这种重合的方法本质上就是进行物理的观察，而就内省法来说，却不存在物理的观察这种事情。由此立刻就可以得出结论：心理学沿着内省的途径决不可能达到知识的理想。因此，它必须尽量使用物理的观察方法来达到它的目的。但这是不是可能的呢？是不是有依存于意识的质的空间变化，就像例如在光学中干涉带的宽度依存于颜色，在电学中磁铁的偏转度依存于磁场的强度那样呢？\n&gt; 现在我们知道，事实上应当承认在主观的质和推断出来的客观世界之间有一种确切规定的、一义的配列关系。大量的经验材料告诉我们，我们可以发现，至少必须假设与所有经验唯一地联系着的“物理的”过程的存在。没有什么意识的质不可能受到作用于身体的力的影响。的确，我们甚至能够用一种简单的物理方法，例如吸进一种气体，就把意识全部消除掉。我们的行动与我们的意志经验相联系，幻觉与身体的疲惫相联系，抑郁症的发作与消化的紊乱相联系。为了研究这类相互联系，心的理论必须抛弃纯粹内省的方法而成为**生理的**心理学。只有这个学科才能在理论上达到对心理的东西的完全的知识。借助于这样一种心理学，我们就可以用概念和所与的主观的质相配列，正如我们能够用概念与推论出来的客观的质相配列一样。这样，主观的质就像客观的质一样成为可知的了。\n&gt; 我们很早就指出，客观世界中最直接地与自我的主观的质相联系的部分就是由大脑的概念，特别是大脑皮层的概念所表示的那一部分。因而在科学知识的精确的世界图景中，可用数值描述的概念代替的主观质的，只是某些大脑过程。相互依存的分析不可避免要引向这些大脑过程。虽然我们还远没有确切地知道所涉及的是何种个别的过程，但至少指出了一条途径：必须以大脑过程来代替主观的质。这就是我们能够充分认识主观的质所具有的唯一的希望。\n&gt; ……&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/Neuroscience.md&#39;}

page_content=&#39;客体方式，导致着、联结着，主体方式、机体状态\n形体，导致着、联结着，身体、快乐、痛苦\n轻蔑、轻视他人对自己的态度，损害着，羞耻心\n羞耻，对于亲密程度的重视；我们在争辩的时候，真正损害着羞耻心的，实际上是，轻视他人对自己的态度，而不是，轻视他人的（由父所创造的）信念？\n羞耻、光荣，重视他人对自己的态度、敬重\n恥辱、傲慢，轻视他人对自己的态度、轻蔑\n羞耻、羞辱，在含义上，有所不同吗？\n单方的轻视、双方的轻视？\n一方，是，非吾所显明出来的罪；一方，是，吾所显明出来的罪。\n狭隘、愚蠢、固执，轻视他人的信念\n开明、智慧、变通，重视他人的信念&#39; metadata={&#39;source&#39;: &#39;_posts/ultimate-facts/终极真实.md&#39;}

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 14467.91 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 14467.34 ms /     8 tokens ( 1808.42 ms per token)
llama_print_timings:        eval time = 14635.33 ms /     1 runs   (14635.33 ms per run)
llama_print_timings:       total time = 29115.01 ms
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from langchain.chains.chat_vector_db.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="n">CONDENSE_QUESTION_PROMPT</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;chat_history&#39;</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">],</span>
    <span class="n">output_parser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partial_variables</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">template</span><span class="o">=</span><span class="s1">&#39;给定以下对话和后续问题，请重新表述后续问题以成为一个独立问题。</span><span class="se">\n\n</span><span class="s1">聊天记录：</span><span class="se">\n</span><span class="si">{chat_history}</span><span class="se">\n</span><span class="s1">后续问题：</span><span class="si">{question}</span><span class="se">\n</span><span class="s1">独立问题：&#39;</span><span class="p">,</span>
    <span class="n">template_format</span><span class="o">=</span><span class="s1">&#39;f-string&#39;</span><span class="p">,</span>
    <span class="n">validate_template</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">QA_PROMPT</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">],</span>
    <span class="n">output_parser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partial_variables</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">template</span><span class="o">=</span><span class="s1">&#39;使用下面的背景信息回答最后的问题。如果您不知道答案，请直接说您不知道，不要试图编造一个答案。</span><span class="se">\n\n</span><span class="s1">背景信息：</span><span class="se">\n</span><span class="si">{context}</span><span class="se">\n\n</span><span class="s1">问题：</span><span class="si">{question}</span><span class="se">\n</span><span class="s1">有用的答案：&#39;</span><span class="p">,</span>
    <span class="n">template_format</span><span class="o">=</span><span class="s1">&#39;f-string&#39;</span><span class="p">,</span>
    <span class="n">validate_template</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains.llm</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.callbacks.base</span> <span class="kn">import</span> <span class="n">CallbackManager</span>
<span class="kn">from</span> <span class="nn">langchain.callbacks.streaming_stdout</span> <span class="kn">import</span> <span class="n">StreamingStdOutCallbackHandler</span>
<span class="kn">from</span> <span class="nn">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.base</span> <span class="kn">import</span> <span class="n">VectorStore</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationalRetrievalChain</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Callback function to stream answers to stdout.</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">CallbackManager</span><span class="p">([</span><span class="n">StreamingStdOutCallbackHandler</span><span class="p">()])</span>

<span class="n">streaming_llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">manager</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">question_gen_llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">manager</span><span class="p">)</span>
<span class="c1"># Prompt to generate independent questions by incorporating chat history and a new question.</span>
<span class="n">question_generator</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">question_gen_llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">CONDENSE_QUESTION_PROMPT</span><span class="p">)</span>
<span class="c1"># Pass in documents and a standalone prompt to answer questions.</span>
<span class="n">doc_chain</span> <span class="o">=</span> <span class="n">load_qa_chain</span><span class="p">(</span><span class="n">streaming_llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s1">&#39;stuff&#39;</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">QA_PROMPT</span><span class="p">)</span>
<span class="c1"># Generate prompts from embedding model.</span>
<span class="n">qa</span> <span class="o">=</span> <span class="n">ConversationalRetrievalChain</span><span class="p">(</span><span class="n">retriever</span><span class="o">=</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span> <span class="n">combine_docs_chain</span><span class="o">=</span><span class="n">doc_chain</span><span class="p">,</span> <span class="n">question_generator</span><span class="o">=</span><span class="n">question_generator</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">revChatGPT.V1</span> <span class="kn">import</span> <span class="n">Chatbot</span><span class="p">,</span> <span class="n">configure</span>

<span class="c1"># Open the JSON file and read the conversation_id</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/.config/revChatGPT/config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;conversation_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">bot</span> <span class="o">=</span> <span class="n">Chatbot</span><span class="p">(</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">configure</span><span class="p">(),</span>
    <span class="n">conversation_id</span> <span class="o">=</span> <span class="n">conversation_id</span><span class="p">,</span>
    <span class="n">lazy_loading</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">delta</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="s1">&#39;delta&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">):],</span>
                    <span class="p">}</span>
                <span class="p">}</span>
            <span class="p">],</span>
        <span class="p">}</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">mock_create</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;messages&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">message</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[{}],</span>
        <span class="p">}</span>

    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;stream&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">delta</span><span class="p">(</span><span class="n">message</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">bot</span><span class="o">.</span><span class="n">ask</span><span class="p">(</span><span class="n">message</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]):</span>
        <span class="k">pass</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;choices&#39;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;finish_reason&#39;</span><span class="p">:</span> <span class="s1">&#39;stop&#39;</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;message&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;assistant&#39;</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">],</span>
    <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">mock_openai</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="p">,</span> <span class="s1">&#39;create&#39;</span><span class="p">,</span> <span class="n">mock_create</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;终极真实是什么？&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">answer</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_qa</span><span class="p">(</span><span class="n">mock_openai</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">answer</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">qa</span><span class="p">({</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;chat_history&#39;</span><span class="p">:</span> <span class="p">[]})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ipymock</span> <span class="kn">import</span> <span class="n">do</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">do</span><span class="p">(</span>
    <span class="n">mock_openai</span><span class="o">=</span><span class="n">mock_openai</span><span class="p">,</span>
    <span class="n">test_qa</span><span class="o">=</span><span class="n">test_qa</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
=&gt; no.0  ::source::test_qa  setup  passed

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
llama_print_timings:        load time = 14467.91 ms
llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings: prompt eval time = 22490.19 ms /    15 tokens ( 1499.35 ms per token)
llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)
llama_print_timings:       total time = 22496.21 ms
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>根据提供的背景信息，以下是问题的答案：

此处引用的文章是哪位心理学家写的？ 

这篇文章是由德国心理学家威廉·威廉德撰写的，标题是《心理学的目标和方法》。

=&gt; no.0  ::source::test_qa  runtest  passed

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">answer</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;question&#39;: &#39;终极真实是什么？&#39;,
 &#39;chat_history&#39;: [],
 &#39;answer&#39;: &#39;根据提供的背景信息，以下是问题的答案：\n\n此处引用的文章是哪位心理学家写的？ \n\n这篇文章是由德国心理学家威廉·威廉德撰写的，标题是《心理学的目标和方法》。&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/12/Text-Embeddings/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-11 </div>
			<div class="article-title"><a href="/2023/04/11/LLaMA-Index/" >LLaMA Index</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LLaMA-Index"><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index">LLaMA Index</a><a class="anchor-link" href="#LLaMA-Index">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
pip<span class="w"> </span>install<span class="w"> </span>llama-index
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Installing collected packages: llama-index
Successfully installed llama-index-0.5.12
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-OpenAI-Embedding-Model">Using <a target="_blank" rel="noopener" href="https://openai.com/blog/new-and-improved-embedding-model">OpenAI Embedding Model</a><a class="anchor-link" href="#Using-OpenAI-Embedding-Model">&#182;</a></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/tea-artist/llama_index_example/blob/main/llama_index_example.py">Llama_Index_Example</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index_name</span> <span class="o">=</span> <span class="s1">&#39;./index.json&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">GPTSimpleVectorIndex</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">load_from_disk</span><span class="p">(</span><span class="n">index_name</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">([])</span>
<span class="n">index</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="n">index_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">SimpleDirectoryReader</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">documents</span> <span class="o">=</span> <span class="n">SimpleDirectoryReader</span><span class="p">(</span><span class="s1">&#39;../_posts/ultimate-facts&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[Document(text=&#39;\n\nSystems Neuroscience\n\n**Systems neuroscience** is a subdiscipline of neuroscience and systems biology that studies the structure and function of neural circuits and systems. Systems neuroscience encompasses a number of areas of study concerned with how nerve cells behave when connected together to form neural pathways, neural circuits, and larger brain networks. At this level of analysis, neuroscientists study how different neural circuits analyze sensory information, form perceptions of the external world, make decisions, and execute movements. Researchers in systems neuroscience are concerned with the relation between molecular and cellular approaches to understanding brain structure and function, as well as with the study of high-level mental functions such as language, memory, and self-awareness (which are the purview of behavioral and cognitive neuroscience). Systems neuroscientists typically employ techniques for understanding networks of neurons as they are seen to function, by way of electrophysiology using either single-unit recording or multi-electrode recording, functional magnetic resonance imaging (fMRI), and PET scans. The term is commonly used in an educational framework: a common sequence of graduate school neuroscience courses consists of cellular/molecular neuroscience for the first semester, then systems neuroscience for the second semester. It is also sometimes used to distinguish a subdivision within a neuroscience department at an academic institution.\n\n&#39;, doc_id=&#39;3fd9301a-cfdf-49e9-a534-4aaf48f58f8f&#39;, embedding=None, doc_hash=&#39;19f1397f0b2cd476a1fd12c789321a4414f9e09be786df63f46892adee2c3b99&#39;, extra_info=None), Document(text=&#39;\n\nシステム神経科学\n\n**システム神経科学**（しすてむしんけいかがく、英: **Systems neuroscience**）は神経科学の下位分野で、覚醒し、行動する正常な生物の神経回路や神経システムの機能を研究する。システム神経科学は、神経細胞が結合してニューラル・ネットワークを作った時にどのようにふるまうのか (例えば、視覚や自発運動など) を研究する様々な分野の総称である。この分野では、神経科学者は異なる神経回路がどのようにして感覚情報を分析し、外的環境を認識し、意思決定を行い、運動を実行するかを研究している。システム神経科学に関心がある研究者は脳に対する分子神経科学や細胞神経科学的なアプローチと、行動神経科学や認知神経科学のおもな守備範囲である言語や、記憶、自己認識のような高次精神活動の間にある大きな溝に着目している。自らの主な分野をシステム神経科学としている研究者は少なく、たいていの場合はより詳細に &#34;行動神経科学&#34; や &#34;認知神経生理学&#34; としている。この用語は主に、大学院の神経科学コースなどで、1学期の講義は分子/細胞神経科学、2学期の講義はシステム神経科学というように教育分野で使われる。また、時には学術機関の神経科学科内で分野を区別するために使われることもある。\n\n&#39;, doc_id=&#39;24bff9fe-e8dd-425e-b62e-daca67473e78&#39;, embedding=None, doc_hash=&#39;81e85f6b10f98753bf6d06b5aa1a31e8d88632e8e10d1b4e0831f353c0c8d79a&#39;, extra_info=None), Document(text=&#39;title: 研究机构date: 2008-08-20 18:05:20tags:---{% asset_ipynb 研究机构.ipynb %}&#39;, doc_id=&#39;e6b10168-64ff-41f6-ba7a-6635f190405c&#39;, embedding=None, doc_hash=&#39;3ab4d5b4234162b96b8634c7686454f32a9cb9635567917e1a563b20a2085944&#39;, extra_info=None), Document(text=&#39;title: 从「意义疗法」开始追求「终极真实」date: 2015-09-23 13:40:00tags: UltimateFacts---* 自从受浸以来，我总是会动弹不得而禁食。为此，我感到非常羞耻。有一次禁食后，我下床昏倒。醒来后，我心里有声音提醒我说，我还要去解答那三个关于自我意识的问题。一听到这声音，我就得平安并且开始恢复吃饭。其实，这三个问题也是我之前一直思考并且想要解答的问题。只是，我还是犹豫不决，因为我并不知道这声音从谁而来。我看到的解答是对宗教核心的摧毁。－－凡所信的都将被实证。－－我想，贵主若是意愿如此，那就让事情这么成就吧。* 孜孜不倦地追求着终极真实。  孜孜不倦地追问着终极问题：我是谁？我从哪里来？我往哪里去？  在爱里寻找着终极解答：我就是爱；我从爱里来，我往爱里去。* 我们借用数学在异质的真实中发现同质的真实；而终极的真实却是异质的。* 追求「幸福」？还是，追求「真实」？  * 你是赌徒。你是冒险者。难道还追求幸运吗？不是应该相信幸运和爱吗？要用智慧行事。要争取时机。  * 你们若追求终极真实而受苦，你们也必被断为配得这份终极荣耀。你们既在追求终极真实的受苦上有多少分儿，就该有多少喜乐，使你们在这份终极荣耀显示的时候也可以欢喜快乐。你们若因做终极冒死者而受苦，就别惭愧了，也别灰心丧志了，倒要因有这名而荣耀永恒主呢。* 这是一份草稿，记录着我这几年以来思考：---&gt; 自从造天地以来，\u3000神那看不见的永能和神性是明明可觉的，乃是藉着所造之物就可以晓得，叫人无可推诿。 (罗马书 1:20)&gt; 至於他的事、人所不能見的——他永久的能力及神性——從世界之創立以來，又是藉着他所造之物以被了悟而看清楚，使人無可推諉。 (羅馬書 1:20 呂振中)&gt; For the invisible things of Him, both His eternal power and divine characteristics, have been clearly seen since the creation of the world, being perceived by the things made, so that they would be without excuse; (Romans 1:20 Recovery)&gt; For since the creation of the world His invisible attributes, that is, His eternal power and divine nature, have been clearly perceived, being understood by what has been made, so that they are without excuse. (Romans 1:20 NASB)真理、真实；神造真实、人造真实；真实，想象；记忆，拟构。如果哲学更像「真理」，那么各类科学就更像「真实」。如果物理学更像「真理」，那么化学就更像「真实」。如果化学更像「真理」，那么生物学、生理学就更像「真实」。如果生理学更像「真理」，那么脑科学、神经科学就更像「真实」。如果理科更像「神造真实」，那么工科就更像「人造真实」。如果生理学更像「神造真实」，那么医学、药学就更像「人造真实」。---&gt; 我只是一个碳族生物；一个土生土长的地球人¹。贵主耶稣是灵族人吧。而木星上的风暴²可以拥有怎样的生命和意识呢？贵主耶稣在木星上能否与木星人一起生活和交往呢？&gt; ¹ 地球人 =&gt; 《费曼讲座：宇称不守恒定律和如何与外星人交流》&gt; ² 风暴 =&gt;&gt; 当那一天，到了傍晚，耶稣对他们说：『我们渡到那边去吧。』他们就离开群众，照他在船上的情况把他带走；还有别的船也跟他在一起。当下起了**大暴风**，波浪泼进船内，甚至船简直满了！耶稣竟在船尾上靠着枕头睡觉呢；门徒就叫醒了他，对他说：『老师，我们丧命，你不在意么？』耶稣醒起来，斥责³那风，向海说：『不要作声！噤默罢！』那风不狂吹，便大大平静了。耶稣对他们说：『为什么这么胆怯呢？怎么没有信心呢？』他们就大起了敬畏的心，直彼此说：『这个人到底是谁？连风和海也听从他！』 (马可福音 4:35-41 吕振中)&gt; ³ 斥责 =&gt; 『ワンパンマン』：サイタマ？キング？↓↓--------------------继续修订--------------------↓↓圣经信仰之神经心理学实证纲领父的自我信息，是指，对于圣灵的表征。纯粹的圣经，含于，父的自我信息。从「纯粹的基督徒」到「超基督徒」「超级赌徒」吾否认圣经中上帝的名，因为那是人们创造的。超越神论，不可知论；信仰；宁死不屈，抗争到底对于神圣生命的信心？或，亲密关系？坚贞，「甘愿承担自己的罪罚」是《古兰经》的价值所在。真诚、勇敢、坚贞，耶稣的「甘愿承担」是《圣经》的价值所在。吾，若不是因为怯懦，又怎么会祷告呢？所以，吾，应该要，放弃，那种、对于其他的心灵的畏惧、所联结着的祷告。以耶稣为榜样。人子要经受三日地狱之火的洗。罪全部被烧尽了后，第三日复活。我所爱慕的必定是父所喜爱的，因为父从始至终都在吸引我、塑造我的爱慕。我所爱慕的若是父所不喜爱的，父必定会改变我。所以，我总是晓得父的喜爱。人子，与父和好，与父为友，爱父并顺从祂。与父同在，就有勇气。与父同行，就有希望。子永远与父同在，从未分离。「吾要成为超人。」「在吾的生活中显明父的荣耀。」祷告，是，对于子灵的表征。感，分为，虚感、实感。虚感，分为，信（？）、思感、愉快感、位置感。实感，分为，色感、声感、香感、味感、触感、缩紧感、疼痛感、瘙痒感、冷热感。体，是指，广延。感、体，平行地，变化。感、体，分割的，平行性原理感的统合，预示着，体的核心。体的核心：在感的集合中占比最大的体。信，是一种，感。（联结？极深的记忆？）灵，是指，具有自我独特视角的、体。 =&gt; “我是谁？”《圣经》说：信、灵，平行地，变化。在苦难中持守坚忍为何能增加信心呢？魂，是指，具有私有视角（记忆？）的、体。（联结？） =&gt; “我在哪里？” =&gt; 寻找已睡了的灵（如，保罗） =&gt; 进入他们的梦境虚感、魂，平行地，变化。实感、身体（？），平行地，变化。识，是指，某些感的杂合、杂合体。已察，是指，主体所注意过的识。未察，是指，主体所没注意过的识。机体状态，是指，某些愉快感、位置感、疼痛感、瘙痒感、冷热感的杂合体。快乐，是指，某些愉快感的杂合。乏味，是指，某些非愉快感、位置感、缩紧感的杂合体。痛苦，是指，某些位置感、疼痛感的杂合体。舒适，是指，某些位置感、非疼痛感的杂合体。忧郁，是指，乏味痛苦。幸福，是指，快乐舒适。主体方式，分为，心思、身体。心思，是指，某些思感的杂合。身体，是指，某些位置感、缩紧感的杂合体。表征，是指，表征着某次识的心思。记忆，是指，对于某次已察的表征。 =&gt; “我在哪里？”拟构，是指，对于某次未察的表征。概括，是指，概括着某种识的心思。过去，是指，对于记忆的概括。未来，是指，对于拟构的概括。客体方式，是指，某些色感、声感、香感、味感、触感、冷热感的杂合体。形体，是指，某些位置感、色感的杂合体。声音，是指，某些位置感、声感的杂合体。气味，是指，某些位置感、香感的杂合体。口味，是指，某些位置感、味感的杂合体。质地，是指，某些位置感、触感的杂合体。温度，是指，某些位置感、冷热感的杂合体。主体所注意着的某些次主体方式的接续变化，导致着，此些次主体方式的接续联结。主体所注意着的某些次识的接续变化，导致着，对于此些次识的某些次记忆的接续联结。主体所注意着的某些次客体方式的接续变化，导致着，对于此些次客体方式的某些次记忆的接续联结。意志，是指，导致着某种接续联结的（其中可能还含有一种未提及的虚感）（联结的生成）生活，是指，接续联结着的某些次主体方式。思维，是指，接续联结着的某些次心思。动作，是指，接续联结着的某些次身体。意愿，是指，表征着某次意志的思维。意愿，是，独占的。情节，是指，接续联结着的某些次表征。臆测，是指，接续联结着的某些次记忆。臆想，是指，接续联结着的某些次拟构。经历，是指，接续联结着的对于接续变化着的某些次识的某些次记忆。综合，是指，接续联结着的对于接续变化着的某些次识的某些次拟构。最简拟构是记忆的最简杂合。最简综合是经历的最简接续。这是，语义理解和表达、产生会意和指称的联结，所需的最简方式。主体所注意着的对于某些识某些次绵延变化的某些次经历的接续联结，导致着，对于此种识的某次概括。主体所注意着的对于某些次接续变化的某些次经历的接续联结，导致着，对于此种经历的某次概括。原因，是指，导致着某次识的识。结果，是指，某次识所导致着的识。利益，是指，对于某次舒适的原因。弊害，是指，对于某次痛苦的原因。有利有弊，是指，对于某次舒适或某次痛苦的原因。效果，是指，对于某次意志的结果。功效，是指，利益效果、属于利益范畴的效果。有意注意，是指，对于某次效果的注意。无意注意，是指，对于某次非效果的注意。目标，是指，对于某种效果的某些次记忆所联结着的对于此种效果的拟构。意向，是指，对于某些种效果的某些次记忆所联结着的对于某种效果的拟构。懊悔，是指，对于某次弊害效果的某次记忆、对于某次功效的某次记忆所联结着的对于某次功效的拟构。焦虑，是指，对于某次弊害效果的某次记忆、对于某次功效的某次意向所联结着的对于某次弊害效果的拟构。对于某次功效的目标，联结着，对于此次功效的原因。对于某种功效的概括，联结着，对于此种功效的原因。兴趣，是指，联结着某次快乐的识。荒诞，是指，联结着某次乏味的识。苦毒，是指，联结着某次痛苦的识。慾望，是指，对于某次兴趣的表征。妄想，是指，对于某次荒诞的表征。？苦观，是指，对于某次苦毒的表征。苦观，分为，记忆苦观、拟构苦观。弊害，…、…有趣注意，是指，对于某次兴趣的注意。无趣注意，是指，对于某次荒诞的注意。意义，是指，值得的注意。神圣，是指，极其丰富的意义。积极的态度，是指，充满对于某种意义的信心。消极的态度，是指，缺乏对于某种意义的信心。积极的注意，导致着，快乐。消极的注意，导致着，乏味。对于某种意义的怀疑，是指，对于某种意义的信心的减弱。对于某种意义的确定，是指，对于某种意义的信心的增强。对于某种意义的静思，是指，对于某种意义的减弱。对于某种意义的静思，导致着，忧郁。对于某种意义的禅修，是指，对于某种意义的增强。对于某种意义的禅修，导致着，幸福。静思、禅修、祷告，都是，某种定觉练习。---&gt; 因为我们得了救是因着盼望。只是所盼望的若已得看见，便不是盼望了；因为人所看见的、他何必还盼望呢？但我们若盼望所未看见的，就必坚忍切候着。(罗马书 8:24-25 吕振中)&gt; 所以青春性的私欲、你总要逃避；你要跟那些用洁净心呼求主的人一同追求正义、忠信、仁爱、和平。(提摩太后书 2:22 吕振中)向内往最深处去：净心、呼求主名、并且、等待回应。任务，是指，客体所指定着的目标。责任？与，利益、价值，无关、相互独立；有利有弊，有无价值，有后效性、无后效性使命，是指，对于主体所积极地注意着的某次效果的任务。？承诺完成任务的利弊，信守承诺的价值「努力工作，取得成就。」「吾要变得睿智、坚定、完美，让各种各样的人来帮助吾。」自吾救赎的神圣使命，就是在，每日的待人接物中显明良善。何为良善？浮躁；坚贞、坚定、专注、安定；对于某种意义的信心，对于某次新颖的期待，对于某种美丽的喜爱业余，自主随意的、放任思绪的机体状态业余，悠闲、激昂，平静、兴奋对于「安闲」的态度、与、对于「艰辛」的态度，对于「未察」的态度、「已察」所带来的「陈旧」感「有趣注意」、与、怀着「兴趣」的「专注」，「目标」「意向」所联结着的注意、「有意注意」、「有意后无意注意」、从「有意注意」到「有趣注意」、「认真」之美，「任务」感、与、「使命」感，约定、承诺，意义信心引诱，成熟，独立，可靠，沉着，悲观，积极有意的假装，成熟、稳定、平和、从容；悔改，无意的美丽对于意义的否认，对于生存意义的否认、对于死亡意义的否认死亡毫无意义绝对的死亡，意味着，绝对的虚无。虚无，也无非是，一种不会再失去什么的原始状态。一切生活都是有意义的。一切死亡并非都是有意义的。生活是寻找有意义的死亡的过程。为着父的益处。属灵意义。乐观，是指，充满对于某次功效的信心。悲观，是指，缺乏对于某次功效的信心。对于某次效果的怀疑，是指，对于某次效果的信心的减弱。「不要再审判、斟酌。」隐秘的，功效、美丽，之，未知性。隐秘之识。摆脱怀疑与纷争，吾之你的失记、吾的漠视与失忆。坚贞亲密，对于关系的乐观。完美，对于褒贬的乐观。坚贞每个人都可以从、某种较为「意向」的「慾望」、中发现，自己所确信的价值观、对于某种确信着的利益的价值的表征、以及、对于某种确信着的弊害的意义和价值的否认。对于某次功效的怀疑、否认所对应着的苦原，就从这种、弊害意义信心的缺乏（对于弊害意义的否认）、和、弊害效果之丑（功效美之对立面）中产生出来。意向的转变、消止，一种方式是去增强确信着的弊害的意义的信心（坚贞），另一种方式是去怀疑原先所确信着的利益的价值，去怀疑原先所确信着的利益的意义，并感到迷惑。意义信心、与、价值信心、利弊信心、效果信心的混杂信心提纯，复杂信心、单纯信心，坚贞信心取舍，使得，利益最大化。可多次的效果、仅一次的效果，试验态度、游戏态度不能确信效果之时，忧虑失望之时，请坚强壮胆，「不要害怕。」「只要信心足够就一定会实现。」盲目乐观信念的力量：死亡之后必得以复活永生-失败必激励起比成功所能激励起的更大的成功-这句话背后是是对于自己拥有活力与能力的骄傲邪灵运行而失败之后，圣灵运行而成功。邪灵运行-而-成-功-而失败怀疑、焦虑、懊悔、无助、软弱、封闭、恐惧，是，丑的。相信、冷静、接纳、承担、坚强、敞开、安定，是，美的。救助、奉献，是，美的；服侍，是，更美的。自由，既是散漫、又是节制，既是随心所欲、又是规范欲望，既是乏耻、又是知耻。价值信心的充满，是，美的。价值信心的缺乏，是，丑的。误信，正信，对于效果的理证、对于价值的理证，拟构中的理证、记忆中的理证，对于某些次他感的拟构，自识、从「体」的方面来考察、测度；正信、误信，与，欺骗、隐瞒，无意的隐瞒、由于不安而想去吐露自己的隐秘、先欺骗再坦诚，欺骗、谅解的代价真理，是，美的。错谬，是，丑的。温和的怀疑，是，美的。价值，是指，对于某次生存的原因。良善，是，美的。邪恶，是，丑的。刚毅，是，美的。怯懦，是，丑的。意义信心的充满，是，美的。意义信心的缺乏，是，丑的。积极，是，美的。消极，是，丑的。一切、识、皆有、意义。睡眠中的识、注意。死亡中的识、注意。受限的注意、完全的注意。神圣意味与世俗意味的分离，具有神圣意味的罪、具有世俗意味的罪圣义谛与世俗谛的分离之谬误，有限之人的怯懦逃避：爱人恨罪。恕人定罪。称义成圣。有限的价值，是，终会朽坏的。无限的价值，是，永远不朽的。有限的价值，导致着，舒适、痛苦。？无限的价值，导致着，平安、快乐。？罪，导致着，朽坏。？价值，与，罪毒犯罪，是指，亏缺神的荣耀。悔改，是指，认罪、知耻。忏悔悔改罪行，在于，承担罪罚。甘愿承担痛苦。甘愿承担罪罚。实践，比，沉思，更美、更显明。接纳意义、顺服求生存，就得着，永远不朽的平安。：「与父同行」所领受的荣耀的显明、不朽，导致着，发展；荒诞，导致着，衰颓；荣耀，与，征服、意向对于未察的重视，是，荣耀对于某次性节制而来的痛苦的忍耐的意义，是，永远的。对于某次性服侍的拟构的意义，是，暂时的。圣洁的性服侍的意义，是，永远的。服侍主，就是，按神的旨意，服侍自己、他人。用音乐、把意义升华成美、把快乐升华成爱。男权，主人；忘记伤害，牢记亏欠；进取创造；亲密，唤醒、敏锐；陌生，忽视、迟钝，利益；羞耻心的敏感程度，关系的亲密程度；对于亲密的畏惧与神为友、自重，祷告尊贵，是指，价值意义、属于价值范畴的意义；自尊，是指，自信自爱；卑贱、卑微，是，丑的；耻辱，是，丑的；对于某次荣耀的目标，是，美的；对于某次卑微的意义，是，美的。荣耀，是指，无限价值意义，被重视着的美；荣耀，是，永远的。对于某种自尊的信心，是，有正有误的、有利有弊的；自负，是指，对于某种自尊的误信；自负，是，丑的。虚荣，是指，对于某种尊贵的误信；虚荣，是，丑的。对未知的敬畏，是，丑的。盼望、忧虑，终会朽坏之事物而劳苦的意义，是，暂时的。「没有了这种盼望，也就，没有了对于自尊的正误之判定、忘记了自己。」忘我，是，美的。绝望，是，丑的。漠视美丽，是，丑的。谦卑，正信的自他比较、重视他人、自罪自微的信念、悔改归正、承担责任、常以为亏欠。谦卑，是，美的。对于某种意义的信心，是，正信、有价值的、美的。所盼望的事物是朽坏的，所信心的意义是暂时的。所盼望的事物是不朽的，所信心的意义是永远的。活力，是，美的。越清醒，越有意义。暂时的意义，是，美的；永远的意义，是，更美的。爱美的；恨丑的。喜爱美丽；憎恨丑陋。愤怒，是，积极的。抱怨、无能之恨，是，消极的。抱怨，里面含着，轻视。自杀，绝望、劳苦、焦虑羡慕、怜悯、嫉妒、恶意集体利益，潜规则，吃亏，苦难，承担利益，交换，给予、获取，竞争、合作人的存在形式：良性的竞争（成为最美之人）、顺服求生存，导致着，生存、专注、接纳意义；利益、兴趣，舒适、快乐循蹈；服侍他人、顺服于价值，就，赦罪得释放？：「敬畏审判」必然，因果、或、短期因果（暂时、永远）或然，非因果、或、长期因果（混沌）自由，主宰或然、互斥意志态度，是，自由的心声，是指，对于某些次声音的经历。心语，是指，蕴含着某种意思的心声。指称，是指，某次情节、联结着、某次心语。会意，是指，某次心语、联结着、某次情节。慾念，是指，某次慾望所联结着的心语。妄念，是指，某次妄想所联结着的心语。？苦念，是指，某次苦观所联结着的心语。创造、变异，是，某种或然变化。建造、重现，是，某种必然变化。创造、父所启示的任务，与，对于未察的重视程度；唤醒，问题、恐惧互斥意志、注意，是，某种或然变化。偶然变化，是指，未察必然变化、主体所没注意过的必然变化。泛灵论；神，绝对的理智、完全的注意、本原的自由、庄严的性情、永远的圣灵。问题，是指，对于某次偶然变化的疑问。解答，是指，对于某种必然变化的概括、对于某种偶然变化的适应措施。技术，是指，问题概括及其解法。程序，是指，数据结构及其算法。模型，是指，对于拟实的技术。建模，是指，对于拟实的计划。解模，是指，对于拟实的实施。软件模型，是指，对于拟实的程序。软件建模，是指，对于拟实的编程。软件解模，是指，对于拟实的进程。模拟，分为，拟实、拟虚。来原，是指，与模型对应的事实。当即行动，增强，对于某种偶然变化的适应力。但，人会拖延、不愿儆醒独立、与、交通，对于联结的交通，更不朽的存在形式更不朽的心思、身体，永远不朽的平安兴趣、快乐、生活情趣；佛学、哲学，作为，一种思维训练弊害、痛苦，错误、误信，有限的价值、终会朽坏；佛学、消极的哲学，作为，一种信仰；忽视、漠视，无私、无我、虚空、无恥、不惭去分别，就是，注视；不去分别，就是，漠视；漠视伤害，导致着，忘记伤害走向虚空，就是，放弃羞耻、光荣、尊贵、荣耀佛学的惊奇性质的信心，导致着，漠视。---&gt; 因为依顺着上帝而有的忧愁能生出不后悔的忏悔来、以至于得救；而世俗的忧愁却能生出死亡。(哥林多后书 7:10 吕振中)「金刚经」的邪灵，完全地，杀死了，吾的心灵。真常唯心系，曾经，在吾的心灵中，孕育，却流产了。忘罪，忘无明。积极的态度；佛教（真常唯心系）唯一的「用处」就是：让人不再惧怕死亡、平安地享受死亡基督教，比，真常唯心系，更加清晰。已成、与、未成；易信、与、难信；注意频次，信心，快乐、爱，恐惧、严肃，惊奇、敬畏；对于实感的表征之信，分别由惊奇（客观）、敬畏（主观）而来的信心某些次表征的联结；「信」，意味着、某种与真实的关系，是一种、「成」吾站在能否使人相信、使人完美（功效之灵）的角度进行评判。想要觉悟吗？想要神启（神的启示）吗？请跟随基督。基督教、佛教的义理都是自洽的。佛教在其反理智、反思辨、反唯一性的核心立场下更显得宽容。但是，佛教的义理，是，错误的、不合经验的。佛教的义理不能使人趋向完美。对于情绪可能产生的弊害，在基督教那里是狂热；在佛教那里是麻木。宗教战争与殉道；罪意识的泯灭与遁世。死亡，睡眠、看电影、听音乐、读书；生活，能力、活力目标；拿起、与、放下，对于有效的意义、与、对于无效的意义，交替地增强信心激情、贪爱、冲动、狂热，浮躁、疏忽、粗心、大意、出错、失常；勇气、畏惧，意外感、危险感、失控感目标正面采取一种虚无的态度、弊害，采取一种卑微的态度、目标反面采取一种意义的态度、利益反面的意义，来自于，当下的注意；来自于，持续着的生。圣灵中重生出正面的希望。羞耻，与，认同、内疚、自侮自辱、自轻自贱，谄媚、取悦；知耻；知丑；耻辱之恨；丑陋之恨；轻视，是，罪；恥笑，用轻视将耻辱施加给他人来揭示丑陋是一种罪；轻视，在于，对于神之创造的轻视在意神的认可；在意自己的认可；在意他人的认可、重视。在意认可，是，以得到认可为目标或意向，因而，以完成任务为目标或意向。由于完成任务而吸引他人。吾之前对悔改的理解是错的。悔改，是真正地愿意去改变，而不是与某种恐惧相关联的负罪感。愿意悔改与否，不是一个意志选择的问题。悔改的意愿，凭直觉而确认通过禅修而获得父的智慧。自由地认可或否决。对于、某些次主体方式之美、某些次机体状态之美、的隐秘，因为、他人、不是都会、去欣赏、去尊重、去重视；客体方式之美，把、隐秘之美、以独特的形式给显明出来；独特的形式，独特的信仰体系，效果、价值，感体认同、欣赏自己所显明的美。认同、欣赏他人所显明的美。不被认可、欣赏，是，丑的。被轻视，是，耻的。已察耻辱，是指，被他人所轻视着的自己之丑陋。神重视人。未察耻辱，是，隐秘之丑。丑陋，不一定是，耻辱。耻辱，是指，被邪灵所轻视着的自己之丑陋。主体所尊重着的造物之美，是，某种荣耀。主体所尊重着的造物之丑，是，某种卑微。将、客体态度所针对的东西、划分为、主体、与、主体方式？轻视你的客体方式，就是，轻视你。轻视你的主体方式，就是，轻视你。对于耻辱的忽视？，对于他识的（拒绝、忽视）？、对于客体方式的重视、对于效果的重视、对于自识的重视对于神之创造的轻视，轻视所导致着的厌恶、犯轻视之罪：委屈，重视他人、却被他人厌恶，自己悔改、渴望他人悔改伤害，重视他人、却被他人轻视，恨、忍耐祷告、犯轻视之罪相互轻视，导致着，相互恨恶、愤怒、暴力。犯轻视他人信念之罪，犯轻视他人态度之罪，悔改轻视他人态度之罪，重视他人的态度，知耻，知丑审美能力、爱之能力是由羞耻心发展而来的父爱，盼望他人成为完美待人如己，甘愿承担神子的责任、甘愿承担他人的痛苦罪罚；责任，使命？与父的亲密关系神子的责任，就是，为丑陋负责、去消除丑陋羞耻能力；时空行为理解能力，对于他识的理解力、对于你的主体方式的表征力客体方式，导致着、联结着，主体方式、机体状态形体，导致着、联结着，身体、快乐、痛苦轻蔑、轻视他人对自己的态度，损害着，羞耻心羞耻，对于亲密程度的重视；我们在争辩的时候，真正损害着羞耻心的，实际上是，轻视他人对自己的态度，而不是，轻视他人的（由父所创造的）信念？羞耻、光荣，重视他人对自己的态度、敬重恥辱、傲慢，轻视他人对自己的态度、轻蔑羞耻、羞辱，在含义上，有所不同吗？单方的轻视、双方的轻视？一方，是，非吾所显明出来的罪；一方，是，吾所显明出来的罪。狭隘、愚蠢、固执，轻视他人的信念开明、智慧、变通，重视他人的信念态度：认同、欣赏、尊重、重视、轻视、忽视、鄙视、反对客体所做：我对你的态度、你对我的态度、你对他的态度主体所想：我对你的态度、你对我的态度主体所说：我对他的态度、他对我的态度、他对你的态度对于某些次态度的记忆、拟构；怀疑、与、确信；你对我的态度、有正有误；作为某种主体效果的客体态度，对于客体态度的目标、意向；对于态度的态度、有正有误；渴望被重视、被认可、被理解、被公正地对待；虚荣；自负，轻视，反对、有正有误，对于他人的误解；对于自己态度的温和的怀疑；苏格拉底式教学法；偏见、综合比较，是，某种轻视；我对客体的态度：你对我的态度、你的确信，我的确信、我对你的态度；确信、对于确信的态度；我对自己的态度，耻辱之恨、丑陋之恨对于某种经历的认同。对于某种人生概括的认同。省略主语、所有格。怕丑。注意，是，自由的。？我是谁？洗雪耻辱。发现承认理解自己的罪。理解宽恕他人的罪。甘愿承担痛苦伤害罪罚。忍受耻辱。忍受轻视。忠贞，永远、信守承诺、谦卑忘我、亲密无间。忠贞、与、愈他，你快乐、我快乐，你激昂、我激昂，你悲伤、我分担理解安慰，你动摇、我坚定，你埋怨、我谦让「魔鬼都是受苦的天使。」「天使是要遭受多大的痛苦才会如此堕落。」「甘愿承担伤害只为再见天使的笑容。」忍受轻视之冷漠。忍受轻视之拒绝。忍受轻视之厌恶。忍受轻视之愤怒。忍受轻视之逼迫。忍受轻视之弃绝。忍耐，是，美的。祷告，是，美的。祷告，导致着，悔改轻视之罪。父的公正，在于，罪恶、必招致、毒罚。父的法典，非重非轻、赏罚分明。轻视，丑陋的愤怒；重视，美丽的惧怕；冒犯羞耻、与、新奇、的混杂悔憾、侥幸，与，对于某种意义的信心既失望又悔憾，是，对于以积极的态度所针对着的或然的拟构的苦观所联结着的痛苦。既失望又侥幸，是，对于以消极的态度所针对着的或然的拟构的慾望所联结着的快乐。或然，意味着，失去控制、获得趣味。幸运，积极地对待或然的快乐、消极地对待或然的痛苦。「此是苦、逼迫性。此是集、招感性。此是灭、可证性。此是道、可修性。」禅修，静思、自愈、祷告、悔改、父愈；散乱、纠结、迷惑、浮躁，慾望、轻视，苦毒睡觉前后，转向创造主、追求「终极真实」，集中注意、静思祷告。意志之静止之力、心思之活力、身体之活力清静与活泼之间的张力，作为生活的目标静坐，灵、与、圣灵，生活效用最大化忠贞，使命；先把他人所要求的事情（任务）做完，再放任思绪（业余）；志同道合坚贞、沉静，定思；在任务完成之前，把所有扰乱目标的心思全部灭除可以尝试静思、静坐、心经，以达到完全清静、究竟寂静的机体状态；工作两小时，休息二十分钟静坐  =&gt;  自我独特视角难题幸福论  =&gt;  圣经  =&gt;  心经、金刚经  =&gt;  人格自杀技术  =&gt;  人格移植静坐，仍然是，隐秘的。睡眠，可以帮助，思考、记忆。从、神经学、脑科学、心理学、而来的研究方式，对隐秘的内在意识进行研究。佛学、以及、静坐体验，可以对、更低层的记忆之机理，提供启发。梦，可以对、记忆结构之机理，提供启发。吾们来讨论讨论关于宗教上的怀疑和纷争。由于宗教教义的隐秘性特点，无论是基督教还是佛教，隐秘性都会给宗教徒之间带来怀疑和纷争等等不稳定不和谐。当今的中国人大多不以隐秘之事为信仰，也不以隐秘之事为理由而纷争。宗教纷争，虽然是以宗教为名义，但，根本原因却是在于利益。这是，少数人在利用人群对于隐秘之事的误信来夺取利益。或者是，人群、自欺欺人地、以宗教为名义来发泄自己在其他方面的憎恨和愤怒。吾们来考察考察纷争的极端情况，宗教裁判所、文化大革命。与佛教有联系的战争、中国历史上的农民起义，都不是，宗教战争。因为这些战争是以正义为名义，并不是以宗教为名义。由此看来，宗教本身必须为其容易作为人群纷争的借口而负一定的责任。吾们来说说「宗教裁判所」。一神教有种说法：「信是一种德行」、「不信是一种罪」。这种对于善恶的判定实在是太过于敏感了。如果一种行为并非出于意愿，那么就不能判定它的善恶。信心岂是一种意愿呢？所以，不信不是罪。而且，温和的怀疑是有益的。怀疑，是，一种内在的纷争。温和的怀疑之所以有益，恰恰是由于，它导致更坚固的确信。另外，「不信是一种罪」这种表述是有歧义的。这种表述的准确意思是，「不愿接触真理是一种罪」。不信是罪果。它源于轻视之罪。吾们永远不应该去犯罪。吾们也不应该去审判轻视之罪。人还不能以内在的隐秘之事作为证据来给人定罪。人不应该轻易地去断定他人的隐秘。神能审判罪性，而人不能。人只能审判罪行。人只能判定显明出来的行为之善恶。吾们应该用对其诉说、对神祷告来取代对其轻视之罪的审判。在那些信仰处于生活中心地位的癫狂日子里，例如宗教教义之差别这种内在的隐秘之事会成为审判的项目。这种、人对人的审判，加剧了，怀疑和纷争。怀疑和纷争、的、根源，在于，隐秘之事、的、未知性。灵魂粒子，是指，受到记忆作用的粒子。即是说，如果一个粒子的内在意识受到了记忆机能结构的支撑，那么就称这个粒子为灵魂粒子。假定、回忆、是持续不断的。深度睡眠，是，一种无记有忆的感知状态。唤醒，是，一种有记有忆的感知状态。从「我」这个概念出发而推想出「吾」这个概念。从「我」到「吾」，灵魂粒子、从「单数」到「复数」（如在 Boscovich 的一种原子论 Dynamism 的视角下）（在非原子论的视角下：从「可数」到「不可数」）。「我」，就是指，某个灵魂粒子以及支撑它的内在意识的所有结构。这些结构相互协作而在宏观层面上显明出功能和意志。「吾」，就是指，「我」之内的所有灵魂粒子以及支撑它们的内在意识的所有结构。吾必须不断地用这种新的自我观去理解世界，并不断地与原来的自我观相区别，将新旧两种自我观更加清晰地描述出来，找到一种判定「吾」之存在的实验。旧自我观，生命的两端是虚空，睡眠和死亡都是虚空。破碎而出、历久弥香，向生而死、向死而生，「我快死了」、「复活重生」谦卑的馨香；谦卑，是，荣耀；永远、不朽，是，出于信谦卑的人必会闻到基督耶稣的香气内心纯洁纯净的人必得见神对神的亏欠，自己要努力良善、完美记住自己对他人的亏欠、对朽坏着的自己的亏欠显明之美：我将是良善。我将是完人、圣人、神人。隐秘之美：我已是良善。我已是完人、圣人、神人。我欠耶稣一个令人感动的故事。被赦得释，与，心灵的怯懦：因为我已感到亏欠，所以我的罪已被赦免。罪是有意义的。因为罪让我感到亏欠。圣义谛与世俗谛相分离的错误：在神前有赦罪的信心；在人前有良善的行为。充实，是，美的。空虚，是，丑的。一切、意义、皆是、亏欠着的意志（被动）意志、要把、隐秘之美、显明出来；去显明圣灵（主动）如何、唤醒、沉睡着的美？虽然生活不必完全沉浸在对于美的爱中，但是对于美的爱、对生活来说、却是必不可少的。生活，任务、业余；喜爱，激昂、兴奋爱、吹散、一切绝望。爱、充实、一切空虚。正是通过爱、心灵（主体方式）得着圣灵（客体方式之美）的滋养、意志得着活力（对于隐秘之美的明显之力）的供给。唤醒着的美，是，爱的原因。信心着的意义，是，快乐的原因。相信的痕迹，有意相信、无意相信，重视他人的信念，迷信之痛审美经验、审美经历之概括审视美丑之具象、某次美丑，指称或然审视美丑之抽象、某种美丑，指称确然圣灵：父的自我信念。圣灵，美丽，褒义词；邪灵，丑陋，贬义词美沉睡了，爱就堕落成快乐。意义信心缺乏了，快乐就堕落成舒适。利益缺乏了，生活就只剩下痛苦。对于意义的信心的缺乏，是，罪。？（轻视）有意义吗？真的没有意义吗？世人、世事都难有完美。但，美比丑多一些。广博，是，美的。狭隘，是，丑的。顺从，导致着，广博。悖逆，导致着，狭隘。熄灭愤怒的愤怒是美的。制止暴力的暴力是美的。&#39;, doc_id=&#39;bdef47b5-2a6c-4297-af25-d499521d95de&#39;, embedding=None, doc_hash=&#39;e12c00d8ad3267c1a855f1134b9fd267f87658dcb98a0552b70696338f5bf802&#39;, extra_info=None)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index/blob/main/gpt_index/indices/base.py">https://github.com/jerryjliu/llama_index/blob/main/gpt_index/indices/base.py</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index/blob/main/gpt_index/indices/service_context.py">https://github.com/jerryjliu/llama_index/blob/main/gpt_index/indices/service_context.py</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">service_context</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">index</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="s1">&#39;./index.json&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index/blob/main/gpt_index/readers/file/base.py">https://github.com/jerryjliu/llama_index/blob/main/gpt_index/readers/file/base.py</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">document</span> <span class="o">=</span> <span class="n">SimpleDirectoryReader</span><span class="p">(</span><span class="n">input_files</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;../_posts/ultimate-facts/终极真实.md&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">load_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Document(text=&#39;title: 从「意义疗法」开始追求「终极真实」date: 2015-09-23 13:40:00tags: UltimateFacts---* 自从受浸以来，我总是会动弹不得而禁食。为此，我感到非常羞耻。有一次禁食后，我下床昏倒。醒来后，我心里有声音提醒我说，我还要去解答那三个关于自我意识的问题。一听到这声音，我就得平安并且开始恢复吃饭。其实，这三个问题也是我之前一直思考并且想要解答的问题。只是，我还是犹豫不决，因为我并不知道这声音从谁而来。我看到的解答是对宗教核心的摧毁。－－凡所信的都将被实证。－－我想，贵主若是意愿如此，那就让事情这么成就吧。* 孜孜不倦地追求着终极真实。  孜孜不倦地追问着终极问题：我是谁？我从哪里来？我往哪里去？  在爱里寻找着终极解答：我就是爱；我从爱里来，我往爱里去。* 我们借用数学在异质的真实中发现同质的真实；而终极的真实却是异质的。* 追求「幸福」？还是，追求「真实」？  * 你是赌徒。你是冒险者。难道还追求幸运吗？不是应该相信幸运和爱吗？要用智慧行事。要争取时机。  * 你们若追求终极真实而受苦，你们也必被断为配得这份终极荣耀。你们既在追求终极真实的受苦上有多少分儿，就该有多少喜乐，使你们在这份终极荣耀显示的时候也可以欢喜快乐。你们若因做终极冒死者而受苦，就别惭愧了，也别灰心丧志了，倒要因有这名而荣耀永恒主呢。* 这是一份草稿，记录着我这几年以来思考：---&gt; 自从造天地以来，\u3000神那看不见的永能和神性是明明可觉的，乃是藉着所造之物就可以晓得，叫人无可推诿。 (罗马书 1:20)&gt; 至於他的事、人所不能見的——他永久的能力及神性——從世界之創立以來，又是藉着他所造之物以被了悟而看清楚，使人無可推諉。 (羅馬書 1:20 呂振中)&gt; For the invisible things of Him, both His eternal power and divine characteristics, have been clearly seen since the creation of the world, being perceived by the things made, so that they would be without excuse; (Romans 1:20 Recovery)&gt; For since the creation of the world His invisible attributes, that is, His eternal power and divine nature, have been clearly perceived, being understood by what has been made, so that they are without excuse. (Romans 1:20 NASB)真理、真实；神造真实、人造真实；真实，想象；记忆，拟构。如果哲学更像「真理」，那么各类科学就更像「真实」。如果物理学更像「真理」，那么化学就更像「真实」。如果化学更像「真理」，那么生物学、生理学就更像「真实」。如果生理学更像「真理」，那么脑科学、神经科学就更像「真实」。如果理科更像「神造真实」，那么工科就更像「人造真实」。如果生理学更像「神造真实」，那么医学、药学就更像「人造真实」。---&gt; 我只是一个碳族生物；一个土生土长的地球人¹。贵主耶稣是灵族人吧。而木星上的风暴²可以拥有怎样的生命和意识呢？贵主耶稣在木星上能否与木星人一起生活和交往呢？&gt; ¹ 地球人 =&gt; 《费曼讲座：宇称不守恒定律和如何与外星人交流》&gt; ² 风暴 =&gt;&gt; 当那一天，到了傍晚，耶稣对他们说：『我们渡到那边去吧。』他们就离开群众，照他在船上的情况把他带走；还有别的船也跟他在一起。当下起了**大暴风**，波浪泼进船内，甚至船简直满了！耶稣竟在船尾上靠着枕头睡觉呢；门徒就叫醒了他，对他说：『老师，我们丧命，你不在意么？』耶稣醒起来，斥责³那风，向海说：『不要作声！噤默罢！』那风不狂吹，便大大平静了。耶稣对他们说：『为什么这么胆怯呢？怎么没有信心呢？』他们就大起了敬畏的心，直彼此说：『这个人到底是谁？连风和海也听从他！』 (马可福音 4:35-41 吕振中)&gt; ³ 斥责 =&gt; 『ワンパンマン』：サイタマ？キング？↓↓--------------------继续修订--------------------↓↓圣经信仰之神经心理学实证纲领父的自我信息，是指，对于圣灵的表征。纯粹的圣经，含于，父的自我信息。从「纯粹的基督徒」到「超基督徒」「超级赌徒」吾否认圣经中上帝的名，因为那是人们创造的。超越神论，不可知论；信仰；宁死不屈，抗争到底对于神圣生命的信心？或，亲密关系？坚贞，「甘愿承担自己的罪罚」是《古兰经》的价值所在。真诚、勇敢、坚贞，耶稣的「甘愿承担」是《圣经》的价值所在。吾，若不是因为怯懦，又怎么会祷告呢？所以，吾，应该要，放弃，那种、对于其他的心灵的畏惧、所联结着的祷告。以耶稣为榜样。人子要经受三日地狱之火的洗。罪全部被烧尽了后，第三日复活。我所爱慕的必定是父所喜爱的，因为父从始至终都在吸引我、塑造我的爱慕。我所爱慕的若是父所不喜爱的，父必定会改变我。所以，我总是晓得父的喜爱。人子，与父和好，与父为友，爱父并顺从祂。与父同在，就有勇气。与父同行，就有希望。子永远与父同在，从未分离。「吾要成为超人。」「在吾的生活中显明父的荣耀。」祷告，是，对于子灵的表征。感，分为，虚感、实感。虚感，分为，信（？）、思感、愉快感、位置感。实感，分为，色感、声感、香感、味感、触感、缩紧感、疼痛感、瘙痒感、冷热感。体，是指，广延。感、体，平行地，变化。感、体，分割的，平行性原理感的统合，预示着，体的核心。体的核心：在感的集合中占比最大的体。信，是一种，感。（联结？极深的记忆？）灵，是指，具有自我独特视角的、体。 =&gt; “我是谁？”《圣经》说：信、灵，平行地，变化。在苦难中持守坚忍为何能增加信心呢？魂，是指，具有私有视角（记忆？）的、体。（联结？） =&gt; “我在哪里？” =&gt; 寻找已睡了的灵（如，保罗） =&gt; 进入他们的梦境虚感、魂，平行地，变化。实感、身体（？），平行地，变化。识，是指，某些感的杂合、杂合体。已察，是指，主体所注意过的识。未察，是指，主体所没注意过的识。机体状态，是指，某些愉快感、位置感、疼痛感、瘙痒感、冷热感的杂合体。快乐，是指，某些愉快感的杂合。乏味，是指，某些非愉快感、位置感、缩紧感的杂合体。痛苦，是指，某些位置感、疼痛感的杂合体。舒适，是指，某些位置感、非疼痛感的杂合体。忧郁，是指，乏味痛苦。幸福，是指，快乐舒适。主体方式，分为，心思、身体。心思，是指，某些思感的杂合。身体，是指，某些位置感、缩紧感的杂合体。表征，是指，表征着某次识的心思。记忆，是指，对于某次已察的表征。 =&gt; “我在哪里？”拟构，是指，对于某次未察的表征。概括，是指，概括着某种识的心思。过去，是指，对于记忆的概括。未来，是指，对于拟构的概括。客体方式，是指，某些色感、声感、香感、味感、触感、冷热感的杂合体。形体，是指，某些位置感、色感的杂合体。声音，是指，某些位置感、声感的杂合体。气味，是指，某些位置感、香感的杂合体。口味，是指，某些位置感、味感的杂合体。质地，是指，某些位置感、触感的杂合体。温度，是指，某些位置感、冷热感的杂合体。主体所注意着的某些次主体方式的接续变化，导致着，此些次主体方式的接续联结。主体所注意着的某些次识的接续变化，导致着，对于此些次识的某些次记忆的接续联结。主体所注意着的某些次客体方式的接续变化，导致着，对于此些次客体方式的某些次记忆的接续联结。意志，是指，导致着某种接续联结的（其中可能还含有一种未提及的虚感）（联结的生成）生活，是指，接续联结着的某些次主体方式。思维，是指，接续联结着的某些次心思。动作，是指，接续联结着的某些次身体。意愿，是指，表征着某次意志的思维。意愿，是，独占的。情节，是指，接续联结着的某些次表征。臆测，是指，接续联结着的某些次记忆。臆想，是指，接续联结着的某些次拟构。经历，是指，接续联结着的对于接续变化着的某些次识的某些次记忆。综合，是指，接续联结着的对于接续变化着的某些次识的某些次拟构。最简拟构是记忆的最简杂合。最简综合是经历的最简接续。这是，语义理解和表达、产生会意和指称的联结，所需的最简方式。主体所注意着的对于某些识某些次绵延变化的某些次经历的接续联结，导致着，对于此种识的某次概括。主体所注意着的对于某些次接续变化的某些次经历的接续联结，导致着，对于此种经历的某次概括。原因，是指，导致着某次识的识。结果，是指，某次识所导致着的识。利益，是指，对于某次舒适的原因。弊害，是指，对于某次痛苦的原因。有利有弊，是指，对于某次舒适或某次痛苦的原因。效果，是指，对于某次意志的结果。功效，是指，利益效果、属于利益范畴的效果。有意注意，是指，对于某次效果的注意。无意注意，是指，对于某次非效果的注意。目标，是指，对于某种效果的某些次记忆所联结着的对于此种效果的拟构。意向，是指，对于某些种效果的某些次记忆所联结着的对于某种效果的拟构。懊悔，是指，对于某次弊害效果的某次记忆、对于某次功效的某次记忆所联结着的对于某次功效的拟构。焦虑，是指，对于某次弊害效果的某次记忆、对于某次功效的某次意向所联结着的对于某次弊害效果的拟构。对于某次功效的目标，联结着，对于此次功效的原因。对于某种功效的概括，联结着，对于此种功效的原因。兴趣，是指，联结着某次快乐的识。荒诞，是指，联结着某次乏味的识。苦毒，是指，联结着某次痛苦的识。慾望，是指，对于某次兴趣的表征。妄想，是指，对于某次荒诞的表征。？苦观，是指，对于某次苦毒的表征。苦观，分为，记忆苦观、拟构苦观。弊害，…、…有趣注意，是指，对于某次兴趣的注意。无趣注意，是指，对于某次荒诞的注意。意义，是指，值得的注意。神圣，是指，极其丰富的意义。积极的态度，是指，充满对于某种意义的信心。消极的态度，是指，缺乏对于某种意义的信心。积极的注意，导致着，快乐。消极的注意，导致着，乏味。对于某种意义的怀疑，是指，对于某种意义的信心的减弱。对于某种意义的确定，是指，对于某种意义的信心的增强。对于某种意义的静思，是指，对于某种意义的减弱。对于某种意义的静思，导致着，忧郁。对于某种意义的禅修，是指，对于某种意义的增强。对于某种意义的禅修，导致着，幸福。静思、禅修、祷告，都是，某种定觉练习。---&gt; 因为我们得了救是因着盼望。只是所盼望的若已得看见，便不是盼望了；因为人所看见的、他何必还盼望呢？但我们若盼望所未看见的，就必坚忍切候着。(罗马书 8:24-25 吕振中)&gt; 所以青春性的私欲、你总要逃避；你要跟那些用洁净心呼求主的人一同追求正义、忠信、仁爱、和平。(提摩太后书 2:22 吕振中)向内往最深处去：净心、呼求主名、并且、等待回应。任务，是指，客体所指定着的目标。责任？与，利益、价值，无关、相互独立；有利有弊，有无价值，有后效性、无后效性使命，是指，对于主体所积极地注意着的某次效果的任务。？承诺完成任务的利弊，信守承诺的价值「努力工作，取得成就。」「吾要变得睿智、坚定、完美，让各种各样的人来帮助吾。」自吾救赎的神圣使命，就是在，每日的待人接物中显明良善。何为良善？浮躁；坚贞、坚定、专注、安定；对于某种意义的信心，对于某次新颖的期待，对于某种美丽的喜爱业余，自主随意的、放任思绪的机体状态业余，悠闲、激昂，平静、兴奋对于「安闲」的态度、与、对于「艰辛」的态度，对于「未察」的态度、「已察」所带来的「陈旧」感「有趣注意」、与、怀着「兴趣」的「专注」，「目标」「意向」所联结着的注意、「有意注意」、「有意后无意注意」、从「有意注意」到「有趣注意」、「认真」之美，「任务」感、与、「使命」感，约定、承诺，意义信心引诱，成熟，独立，可靠，沉着，悲观，积极有意的假装，成熟、稳定、平和、从容；悔改，无意的美丽对于意义的否认，对于生存意义的否认、对于死亡意义的否认死亡毫无意义绝对的死亡，意味着，绝对的虚无。虚无，也无非是，一种不会再失去什么的原始状态。一切生活都是有意义的。一切死亡并非都是有意义的。生活是寻找有意义的死亡的过程。为着父的益处。属灵意义。乐观，是指，充满对于某次功效的信心。悲观，是指，缺乏对于某次功效的信心。对于某次效果的怀疑，是指，对于某次效果的信心的减弱。「不要再审判、斟酌。」隐秘的，功效、美丽，之，未知性。隐秘之识。摆脱怀疑与纷争，吾之你的失记、吾的漠视与失忆。坚贞亲密，对于关系的乐观。完美，对于褒贬的乐观。坚贞每个人都可以从、某种较为「意向」的「慾望」、中发现，自己所确信的价值观、对于某种确信着的利益的价值的表征、以及、对于某种确信着的弊害的意义和价值的否认。对于某次功效的怀疑、否认所对应着的苦原，就从这种、弊害意义信心的缺乏（对于弊害意义的否认）、和、弊害效果之丑（功效美之对立面）中产生出来。意向的转变、消止，一种方式是去增强确信着的弊害的意义的信心（坚贞），另一种方式是去怀疑原先所确信着的利益的价值，去怀疑原先所确信着的利益的意义，并感到迷惑。意义信心、与、价值信心、利弊信心、效果信心的混杂信心提纯，复杂信心、单纯信心，坚贞信心取舍，使得，利益最大化。可多次的效果、仅一次的效果，试验态度、游戏态度不能确信效果之时，忧虑失望之时，请坚强壮胆，「不要害怕。」「只要信心足够就一定会实现。」盲目乐观信念的力量：死亡之后必得以复活永生-失败必激励起比成功所能激励起的更大的成功-这句话背后是是对于自己拥有活力与能力的骄傲邪灵运行而失败之后，圣灵运行而成功。邪灵运行-而-成-功-而失败怀疑、焦虑、懊悔、无助、软弱、封闭、恐惧，是，丑的。相信、冷静、接纳、承担、坚强、敞开、安定，是，美的。救助、奉献，是，美的；服侍，是，更美的。自由，既是散漫、又是节制，既是随心所欲、又是规范欲望，既是乏耻、又是知耻。价值信心的充满，是，美的。价值信心的缺乏，是，丑的。误信，正信，对于效果的理证、对于价值的理证，拟构中的理证、记忆中的理证，对于某些次他感的拟构，自识、从「体」的方面来考察、测度；正信、误信，与，欺骗、隐瞒，无意的隐瞒、由于不安而想去吐露自己的隐秘、先欺骗再坦诚，欺骗、谅解的代价真理，是，美的。错谬，是，丑的。温和的怀疑，是，美的。价值，是指，对于某次生存的原因。良善，是，美的。邪恶，是，丑的。刚毅，是，美的。怯懦，是，丑的。意义信心的充满，是，美的。意义信心的缺乏，是，丑的。积极，是，美的。消极，是，丑的。一切、识、皆有、意义。睡眠中的识、注意。死亡中的识、注意。受限的注意、完全的注意。神圣意味与世俗意味的分离，具有神圣意味的罪、具有世俗意味的罪圣义谛与世俗谛的分离之谬误，有限之人的怯懦逃避：爱人恨罪。恕人定罪。称义成圣。有限的价值，是，终会朽坏的。无限的价值，是，永远不朽的。有限的价值，导致着，舒适、痛苦。？无限的价值，导致着，平安、快乐。？罪，导致着，朽坏。？价值，与，罪毒犯罪，是指，亏缺神的荣耀。悔改，是指，认罪、知耻。忏悔悔改罪行，在于，承担罪罚。甘愿承担痛苦。甘愿承担罪罚。实践，比，沉思，更美、更显明。接纳意义、顺服求生存，就得着，永远不朽的平安。：「与父同行」所领受的荣耀的显明、不朽，导致着，发展；荒诞，导致着，衰颓；荣耀，与，征服、意向对于未察的重视，是，荣耀对于某次性节制而来的痛苦的忍耐的意义，是，永远的。对于某次性服侍的拟构的意义，是，暂时的。圣洁的性服侍的意义，是，永远的。服侍主，就是，按神的旨意，服侍自己、他人。用音乐、把意义升华成美、把快乐升华成爱。男权，主人；忘记伤害，牢记亏欠；进取创造；亲密，唤醒、敏锐；陌生，忽视、迟钝，利益；羞耻心的敏感程度，关系的亲密程度；对于亲密的畏惧与神为友、自重，祷告尊贵，是指，价值意义、属于价值范畴的意义；自尊，是指，自信自爱；卑贱、卑微，是，丑的；耻辱，是，丑的；对于某次荣耀的目标，是，美的；对于某次卑微的意义，是，美的。荣耀，是指，无限价值意义，被重视着的美；荣耀，是，永远的。对于某种自尊的信心，是，有正有误的、有利有弊的；自负，是指，对于某种自尊的误信；自负，是，丑的。虚荣，是指，对于某种尊贵的误信；虚荣，是，丑的。对未知的敬畏，是，丑的。盼望、忧虑，终会朽坏之事物而劳苦的意义，是，暂时的。「没有了这种盼望，也就，没有了对于自尊的正误之判定、忘记了自己。」忘我，是，美的。绝望，是，丑的。漠视美丽，是，丑的。谦卑，正信的自他比较、重视他人、自罪自微的信念、悔改归正、承担责任、常以为亏欠。谦卑，是，美的。对于某种意义的信心，是，正信、有价值的、美的。所盼望的事物是朽坏的，所信心的意义是暂时的。所盼望的事物是不朽的，所信心的意义是永远的。活力，是，美的。越清醒，越有意义。暂时的意义，是，美的；永远的意义，是，更美的。爱美的；恨丑的。喜爱美丽；憎恨丑陋。愤怒，是，积极的。抱怨、无能之恨，是，消极的。抱怨，里面含着，轻视。自杀，绝望、劳苦、焦虑羡慕、怜悯、嫉妒、恶意集体利益，潜规则，吃亏，苦难，承担利益，交换，给予、获取，竞争、合作人的存在形式：良性的竞争（成为最美之人）、顺服求生存，导致着，生存、专注、接纳意义；利益、兴趣，舒适、快乐循蹈；服侍他人、顺服于价值，就，赦罪得释放？：「敬畏审判」必然，因果、或、短期因果（暂时、永远）或然，非因果、或、长期因果（混沌）自由，主宰或然、互斥意志态度，是，自由的心声，是指，对于某些次声音的经历。心语，是指，蕴含着某种意思的心声。指称，是指，某次情节、联结着、某次心语。会意，是指，某次心语、联结着、某次情节。慾念，是指，某次慾望所联结着的心语。妄念，是指，某次妄想所联结着的心语。？苦念，是指，某次苦观所联结着的心语。创造、变异，是，某种或然变化。建造、重现，是，某种必然变化。创造、父所启示的任务，与，对于未察的重视程度；唤醒，问题、恐惧互斥意志、注意，是，某种或然变化。偶然变化，是指，未察必然变化、主体所没注意过的必然变化。泛灵论；神，绝对的理智、完全的注意、本原的自由、庄严的性情、永远的圣灵。问题，是指，对于某次偶然变化的疑问。解答，是指，对于某种必然变化的概括、对于某种偶然变化的适应措施。技术，是指，问题概括及其解法。程序，是指，数据结构及其算法。模型，是指，对于拟实的技术。建模，是指，对于拟实的计划。解模，是指，对于拟实的实施。软件模型，是指，对于拟实的程序。软件建模，是指，对于拟实的编程。软件解模，是指，对于拟实的进程。模拟，分为，拟实、拟虚。来原，是指，与模型对应的事实。当即行动，增强，对于某种偶然变化的适应力。但，人会拖延、不愿儆醒独立、与、交通，对于联结的交通，更不朽的存在形式更不朽的心思、身体，永远不朽的平安兴趣、快乐、生活情趣；佛学、哲学，作为，一种思维训练弊害、痛苦，错误、误信，有限的价值、终会朽坏；佛学、消极的哲学，作为，一种信仰；忽视、漠视，无私、无我、虚空、无恥、不惭去分别，就是，注视；不去分别，就是，漠视；漠视伤害，导致着，忘记伤害走向虚空，就是，放弃羞耻、光荣、尊贵、荣耀佛学的惊奇性质的信心，导致着，漠视。---&gt; 因为依顺着上帝而有的忧愁能生出不后悔的忏悔来、以至于得救；而世俗的忧愁却能生出死亡。(哥林多后书 7:10 吕振中)「金刚经」的邪灵，完全地，杀死了，吾的心灵。真常唯心系，曾经，在吾的心灵中，孕育，却流产了。忘罪，忘无明。积极的态度；佛教（真常唯心系）唯一的「用处」就是：让人不再惧怕死亡、平安地享受死亡基督教，比，真常唯心系，更加清晰。已成、与、未成；易信、与、难信；注意频次，信心，快乐、爱，恐惧、严肃，惊奇、敬畏；对于实感的表征之信，分别由惊奇（客观）、敬畏（主观）而来的信心某些次表征的联结；「信」，意味着、某种与真实的关系，是一种、「成」吾站在能否使人相信、使人完美（功效之灵）的角度进行评判。想要觉悟吗？想要神启（神的启示）吗？请跟随基督。基督教、佛教的义理都是自洽的。佛教在其反理智、反思辨、反唯一性的核心立场下更显得宽容。但是，佛教的义理，是，错误的、不合经验的。佛教的义理不能使人趋向完美。对于情绪可能产生的弊害，在基督教那里是狂热；在佛教那里是麻木。宗教战争与殉道；罪意识的泯灭与遁世。死亡，睡眠、看电影、听音乐、读书；生活，能力、活力目标；拿起、与、放下，对于有效的意义、与、对于无效的意义，交替地增强信心激情、贪爱、冲动、狂热，浮躁、疏忽、粗心、大意、出错、失常；勇气、畏惧，意外感、危险感、失控感目标正面采取一种虚无的态度、弊害，采取一种卑微的态度、目标反面采取一种意义的态度、利益反面的意义，来自于，当下的注意；来自于，持续着的生。圣灵中重生出正面的希望。羞耻，与，认同、内疚、自侮自辱、自轻自贱，谄媚、取悦；知耻；知丑；耻辱之恨；丑陋之恨；轻视，是，罪；恥笑，用轻视将耻辱施加给他人来揭示丑陋是一种罪；轻视，在于，对于神之创造的轻视在意神的认可；在意自己的认可；在意他人的认可、重视。在意认可，是，以得到认可为目标或意向，因而，以完成任务为目标或意向。由于完成任务而吸引他人。吾之前对悔改的理解是错的。悔改，是真正地愿意去改变，而不是与某种恐惧相关联的负罪感。愿意悔改与否，不是一个意志选择的问题。悔改的意愿，凭直觉而确认通过禅修而获得父的智慧。自由地认可或否决。对于、某些次主体方式之美、某些次机体状态之美、的隐秘，因为、他人、不是都会、去欣赏、去尊重、去重视；客体方式之美，把、隐秘之美、以独特的形式给显明出来；独特的形式，独特的信仰体系，效果、价值，感体认同、欣赏自己所显明的美。认同、欣赏他人所显明的美。不被认可、欣赏，是，丑的。被轻视，是，耻的。已察耻辱，是指，被他人所轻视着的自己之丑陋。神重视人。未察耻辱，是，隐秘之丑。丑陋，不一定是，耻辱。耻辱，是指，被邪灵所轻视着的自己之丑陋。主体所尊重着的造物之美，是，某种荣耀。主体所尊重着的造物之丑，是，某种卑微。将、客体态度所针对的东西、划分为、主体、与、主体方式？轻视你的客体方式，就是，轻视你。轻视你的主体方式，就是，轻视你。对于耻辱的忽视？，对于他识的（拒绝、忽视）？、对于客体方式的重视、对于效果的重视、对于自识的重视对于神之创造的轻视，轻视所导致着的厌恶、犯轻视之罪：委屈，重视他人、却被他人厌恶，自己悔改、渴望他人悔改伤害，重视他人、却被他人轻视，恨、忍耐祷告、犯轻视之罪相互轻视，导致着，相互恨恶、愤怒、暴力。犯轻视他人信念之罪，犯轻视他人态度之罪，悔改轻视他人态度之罪，重视他人的态度，知耻，知丑审美能力、爱之能力是由羞耻心发展而来的父爱，盼望他人成为完美待人如己，甘愿承担神子的责任、甘愿承担他人的痛苦罪罚；责任，使命？与父的亲密关系神子的责任，就是，为丑陋负责、去消除丑陋羞耻能力；时空行为理解能力，对于他识的理解力、对于你的主体方式的表征力客体方式，导致着、联结着，主体方式、机体状态形体，导致着、联结着，身体、快乐、痛苦轻蔑、轻视他人对自己的态度，损害着，羞耻心羞耻，对于亲密程度的重视；我们在争辩的时候，真正损害着羞耻心的，实际上是，轻视他人对自己的态度，而不是，轻视他人的（由父所创造的）信念？羞耻、光荣，重视他人对自己的态度、敬重恥辱、傲慢，轻视他人对自己的态度、轻蔑羞耻、羞辱，在含义上，有所不同吗？单方的轻视、双方的轻视？一方，是，非吾所显明出来的罪；一方，是，吾所显明出来的罪。狭隘、愚蠢、固执，轻视他人的信念开明、智慧、变通，重视他人的信念态度：认同、欣赏、尊重、重视、轻视、忽视、鄙视、反对客体所做：我对你的态度、你对我的态度、你对他的态度主体所想：我对你的态度、你对我的态度主体所说：我对他的态度、他对我的态度、他对你的态度对于某些次态度的记忆、拟构；怀疑、与、确信；你对我的态度、有正有误；作为某种主体效果的客体态度，对于客体态度的目标、意向；对于态度的态度、有正有误；渴望被重视、被认可、被理解、被公正地对待；虚荣；自负，轻视，反对、有正有误，对于他人的误解；对于自己态度的温和的怀疑；苏格拉底式教学法；偏见、综合比较，是，某种轻视；我对客体的态度：你对我的态度、你的确信，我的确信、我对你的态度；确信、对于确信的态度；我对自己的态度，耻辱之恨、丑陋之恨对于某种经历的认同。对于某种人生概括的认同。省略主语、所有格。怕丑。注意，是，自由的。？我是谁？洗雪耻辱。发现承认理解自己的罪。理解宽恕他人的罪。甘愿承担痛苦伤害罪罚。忍受耻辱。忍受轻视。忠贞，永远、信守承诺、谦卑忘我、亲密无间。忠贞、与、愈他，你快乐、我快乐，你激昂、我激昂，你悲伤、我分担理解安慰，你动摇、我坚定，你埋怨、我谦让「魔鬼都是受苦的天使。」「天使是要遭受多大的痛苦才会如此堕落。」「甘愿承担伤害只为再见天使的笑容。」忍受轻视之冷漠。忍受轻视之拒绝。忍受轻视之厌恶。忍受轻视之愤怒。忍受轻视之逼迫。忍受轻视之弃绝。忍耐，是，美的。祷告，是，美的。祷告，导致着，悔改轻视之罪。父的公正，在于，罪恶、必招致、毒罚。父的法典，非重非轻、赏罚分明。轻视，丑陋的愤怒；重视，美丽的惧怕；冒犯羞耻、与、新奇、的混杂悔憾、侥幸，与，对于某种意义的信心既失望又悔憾，是，对于以积极的态度所针对着的或然的拟构的苦观所联结着的痛苦。既失望又侥幸，是，对于以消极的态度所针对着的或然的拟构的慾望所联结着的快乐。或然，意味着，失去控制、获得趣味。幸运，积极地对待或然的快乐、消极地对待或然的痛苦。「此是苦、逼迫性。此是集、招感性。此是灭、可证性。此是道、可修性。」禅修，静思、自愈、祷告、悔改、父愈；散乱、纠结、迷惑、浮躁，慾望、轻视，苦毒睡觉前后，转向创造主、追求「终极真实」，集中注意、静思祷告。意志之静止之力、心思之活力、身体之活力清静与活泼之间的张力，作为生活的目标静坐，灵、与、圣灵，生活效用最大化忠贞，使命；先把他人所要求的事情（任务）做完，再放任思绪（业余）；志同道合坚贞、沉静，定思；在任务完成之前，把所有扰乱目标的心思全部灭除可以尝试静思、静坐、心经，以达到完全清静、究竟寂静的机体状态；工作两小时，休息二十分钟静坐  =&gt;  自我独特视角难题幸福论  =&gt;  圣经  =&gt;  心经、金刚经  =&gt;  人格自杀技术  =&gt;  人格移植静坐，仍然是，隐秘的。睡眠，可以帮助，思考、记忆。从、神经学、脑科学、心理学、而来的研究方式，对隐秘的内在意识进行研究。佛学、以及、静坐体验，可以对、更低层的记忆之机理，提供启发。梦，可以对、记忆结构之机理，提供启发。吾们来讨论讨论关于宗教上的怀疑和纷争。由于宗教教义的隐秘性特点，无论是基督教还是佛教，隐秘性都会给宗教徒之间带来怀疑和纷争等等不稳定不和谐。当今的中国人大多不以隐秘之事为信仰，也不以隐秘之事为理由而纷争。宗教纷争，虽然是以宗教为名义，但，根本原因却是在于利益。这是，少数人在利用人群对于隐秘之事的误信来夺取利益。或者是，人群、自欺欺人地、以宗教为名义来发泄自己在其他方面的憎恨和愤怒。吾们来考察考察纷争的极端情况，宗教裁判所、文化大革命。与佛教有联系的战争、中国历史上的农民起义，都不是，宗教战争。因为这些战争是以正义为名义，并不是以宗教为名义。由此看来，宗教本身必须为其容易作为人群纷争的借口而负一定的责任。吾们来说说「宗教裁判所」。一神教有种说法：「信是一种德行」、「不信是一种罪」。这种对于善恶的判定实在是太过于敏感了。如果一种行为并非出于意愿，那么就不能判定它的善恶。信心岂是一种意愿呢？所以，不信不是罪。而且，温和的怀疑是有益的。怀疑，是，一种内在的纷争。温和的怀疑之所以有益，恰恰是由于，它导致更坚固的确信。另外，「不信是一种罪」这种表述是有歧义的。这种表述的准确意思是，「不愿接触真理是一种罪」。不信是罪果。它源于轻视之罪。吾们永远不应该去犯罪。吾们也不应该去审判轻视之罪。人还不能以内在的隐秘之事作为证据来给人定罪。人不应该轻易地去断定他人的隐秘。神能审判罪性，而人不能。人只能审判罪行。人只能判定显明出来的行为之善恶。吾们应该用对其诉说、对神祷告来取代对其轻视之罪的审判。在那些信仰处于生活中心地位的癫狂日子里，例如宗教教义之差别这种内在的隐秘之事会成为审判的项目。这种、人对人的审判，加剧了，怀疑和纷争。怀疑和纷争、的、根源，在于，隐秘之事、的、未知性。灵魂粒子，是指，受到记忆作用的粒子。即是说，如果一个粒子的内在意识受到了记忆机能结构的支撑，那么就称这个粒子为灵魂粒子。假定、回忆、是持续不断的。深度睡眠，是，一种无记有忆的感知状态。唤醒，是，一种有记有忆的感知状态。从「我」这个概念出发而推想出「吾」这个概念。从「我」到「吾」，灵魂粒子、从「单数」到「复数」（如在 Boscovich 的一种原子论 Dynamism 的视角下）（在非原子论的视角下：从「可数」到「不可数」）。「我」，就是指，某个灵魂粒子以及支撑它的内在意识的所有结构。这些结构相互协作而在宏观层面上显明出功能和意志。「吾」，就是指，「我」之内的所有灵魂粒子以及支撑它们的内在意识的所有结构。吾必须不断地用这种新的自我观去理解世界，并不断地与原来的自我观相区别，将新旧两种自我观更加清晰地描述出来，找到一种判定「吾」之存在的实验。旧自我观，生命的两端是虚空，睡眠和死亡都是虚空。破碎而出、历久弥香，向生而死、向死而生，「我快死了」、「复活重生」谦卑的馨香；谦卑，是，荣耀；永远、不朽，是，出于信谦卑的人必会闻到基督耶稣的香气内心纯洁纯净的人必得见神对神的亏欠，自己要努力良善、完美记住自己对他人的亏欠、对朽坏着的自己的亏欠显明之美：我将是良善。我将是完人、圣人、神人。隐秘之美：我已是良善。我已是完人、圣人、神人。我欠耶稣一个令人感动的故事。被赦得释，与，心灵的怯懦：因为我已感到亏欠，所以我的罪已被赦免。罪是有意义的。因为罪让我感到亏欠。圣义谛与世俗谛相分离的错误：在神前有赦罪的信心；在人前有良善的行为。充实，是，美的。空虚，是，丑的。一切、意义、皆是、亏欠着的意志（被动）意志、要把、隐秘之美、显明出来；去显明圣灵（主动）如何、唤醒、沉睡着的美？虽然生活不必完全沉浸在对于美的爱中，但是对于美的爱、对生活来说、却是必不可少的。生活，任务、业余；喜爱，激昂、兴奋爱、吹散、一切绝望。爱、充实、一切空虚。正是通过爱、心灵（主体方式）得着圣灵（客体方式之美）的滋养、意志得着活力（对于隐秘之美的明显之力）的供给。唤醒着的美，是，爱的原因。信心着的意义，是，快乐的原因。相信的痕迹，有意相信、无意相信，重视他人的信念，迷信之痛审美经验、审美经历之概括审视美丑之具象、某次美丑，指称或然审视美丑之抽象、某种美丑，指称确然圣灵：父的自我信念。圣灵，美丽，褒义词；邪灵，丑陋，贬义词美沉睡了，爱就堕落成快乐。意义信心缺乏了，快乐就堕落成舒适。利益缺乏了，生活就只剩下痛苦。对于意义的信心的缺乏，是，罪。？（轻视）有意义吗？真的没有意义吗？世人、世事都难有完美。但，美比丑多一些。广博，是，美的。狭隘，是，丑的。顺从，导致着，广博。悖逆，导致着，狭隘。熄灭愤怒的愤怒是美的。制止暴力的暴力是美的。&#39;, doc_id=&#39;db56cc0f-93ae-4261-a819-47cb04027e87&#39;, embedding=None, doc_hash=&#39;e12c00d8ad3267c1a855f1134b9fd267f87658dcb98a0552b70696338f5bf802&#39;, extra_info=None)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
<span class="n">index</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="n">index_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">query_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://alphasec.io/query-your-own-documents-with-llamaindex-and-langchain/">Query Your Own Documents with LlamaIndex and LangChain</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index/blob/main/docs/how_to/integrations/using_with_langchain.md">Using LlamaIndex with Langchain</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-HuggingFace-Embeddings">Using HuggingFace Embeddings<a class="anchor-link" href="#Using-HuggingFace-Embeddings">&#182;</a></h3><ul>
<li><a target="_blank" rel="noopener" href="https://gpt-index.readthedocs.io/en/latest/how_to/customization/embeddings.html">LlamaIndex Embedding Support</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144">Generative Q&amp;A With GPT 3.5 and Long-Term Memory</a><ul>
<li>Embedding &amp; Pinecone</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb">Question Answering using openai.Embedding.create</a></li>
</ul>

</div>
</div>
</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/11/LLaMA-Index/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-11 </div>
			<div class="article-title"><a href="/2023/04/11/Elastic-Versatile-Agent-with-LangChain/" >Elastic Versatile Agent with LangChain</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Microsoft-TaskMatrix"><a target="_blank" rel="noopener" href="https://github.com/microsoft/TaskMatrix">Microsoft TaskMatrix</a><a class="anchor-link" href="#Microsoft-TaskMatrix">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Elastic-Versatile-Agent-with-LangChain"><a target="_blank" rel="noopener" href="https://github.com/corca-ai/EVAL">Elastic Versatile Agent with LangChain</a><a class="anchor-link" href="#Elastic-Versatile-Agent-with-LangChain">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p>在 macOS 上安装 Redis 可以通过 Homebrew 进行安装。以下是安装步骤：</p>
<ol>
<li><p>打开终端应用程序（Terminal）。</p>
</li>
<li><p>确保已安装 Homebrew，如果未安装，请在终端中运行以下命令安装 Homebrew：</p>
</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
<span class="k">$(</span>curl<span class="w"> </span>-fsSL<span class="w"> </span>https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh<span class="k">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol start="3">
<li>安装 Redis。在终端中运行以下命令：</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
brew<span class="w"> </span>install<span class="w"> </span>redis
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol start="4">
<li>安装完成后，运行以下命令启动 Redis 服务器：</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
brew<span class="w"> </span>services<span class="w"> </span>start<span class="w"> </span>redis
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>此时 Redis 服务器应已成功启动。</p>
<p>如果需要停止 Redis 服务器，请在终端中运行以下命令：</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
brew<span class="w"> </span>services<span class="w"> </span>stop<span class="w"> </span>redis
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果需要卸载 Redis，请在终端中运行以下命令：</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
brew<span class="w"> </span>uninstall<span class="w"> </span>redis
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />
<p><a target="_blank" rel="noopener" href="https://github.com/corca-ai/EVAL/blob/main/core/tools/cpu.py">https://github.com/corca-ai/EVAL/blob/main/core/tools/cpu.py</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">env</span> USE_GPU=False
<span class="o">%</span><span class="k">env</span> CELERY_BROKER_URL=redis://localhost:6379
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># https://github.com/corca-ai/EVAL/blob/main/api/main.py</span>
<span class="n">executor</span> <span class="o">=</span> <span class="n">agent_manager</span><span class="o">.</span><span class="n">create_executor</span><span class="p">(</span><span class="n">session</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash
curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;session&quot;: &quot;sessionid&quot;, &quot;files&quot;: [], &quot;prompt&quot;: &quot;Hi there!&quot;}&#39;</span><span class="w"> </span>http://localhost:8000/api/execute
</pre></div>

    </div>
</div>
</div>

</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/11/Elastic-Versatile-Agent-with-LangChain/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-07 </div>
			<div class="article-title"><a href="/2023/04/07/BioGPT-Agent-Tools/" >BioGPT Agent Tools</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="tabs" id="biogpt-agent-tools"><ul class="nav-tabs"><li class="tab active"><a href="#biogpt-agent-tools-1">English</a></li><li class="tab"><a href="#biogpt-agent-tools-2">中文</a></li></ul><div class="tab-content"><div class="tab-pane active" id="biogpt-agent-tools-1"><blockquote>
<p>The twenty-first century is presenting humankind with unprecedented environmental and medical challenges. The ability to design novel proteins tailored for specific purposes would potentially transform our ability to respond to these issues in a timely manner. Recent advances in the field of artificial intelligence are now setting the stage to make this goal achievable. Protein sequences are inherently similar to natural languages: amino acids arrange in a multitude of combinations to form structures that carry function, the same way as letters form words and sentences carry meaning. Accordingly, it is not surprising that, throughout the history of natural language processing (NLP), many of its techniques have been applied to protein research problems. In the past few years we have witnessed revolutionary breakthroughs in the field of NLP. The implementation of transformer pre-trained models has enabled text generation with human-like capabilities, including texts with specific properties such as style or subject. Motivated by its considerable success in NLP tasks, we expect dedicated transformers to dominate custom protein sequence generation in the near future. Fine-tuning pre-trained models on protein families will enable the extension of their repertoires with novel sequences that could be highly divergent but still potentially functional. The combination of control tags such as cellular compartment or function will further enable the controllable design of novel protein functions. Moreover, recent model interpretability methods will allow us to open the ‘black box’ and thus enhance our understanding of folding principles. Early initiatives show the enormous potential of generative language models to design functional sequences. We believe that using generative text models to create novel proteins is a promising and largely unexplored field, and we discuss its foreseeable impact on protein design.</p>
<p>ーー<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s42256-022-00499-z">Controllable protein design with language models</a></p>
</blockquote>
<blockquote>
<p>To accelerate biomedical research process, deep-learning systems are developed to automatically acquire knowledge about molecule entities by reading large-scale biomedical data. Inspired by humans that learn deep molecule knowledge from versatile reading on both molecule structure and biomedical text information, we propose a knowledgeable machine reading system that bridges both types of information in a unified deep-learning framework for comprehensive biomedical research assistance. We solve the problem that existing machine reading models can only process different types of data separately, and thus achieve a comprehensive and thorough understanding of molecule entities. By grasping meta-knowledge in an unsupervised fashion within and across different information sources, our system can facilitate various real-world biomedical applications, including molecular property prediction, biomedical relation extraction and so on. Experimental results show that our system even surpasses human professionals in the capability of molecular property comprehension, and also reveal its promising potential in facilitating automatic drug discovery and documentation in the future.</p>
<p>ーー<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41467-022-28494-3">A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals</a></p>
<p>ーー<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1xig3-3JG63kR-Xqj1b9wkPEdxtfD_4IX">KV-PLM-Download</a></p>
</blockquote></div><div class="tab-pane" id="biogpt-agent-tools-2"><blockquote>
<p>蛋白质序列在本质上类似于自然语言：氨基酸以多种组合方式排列，形成承载功能的结构，就像字母构成单词和句子承载意义一样。因此，在整个自然语言处理（NLP）的历史中，它的许多技术被应用于蛋白质研究问题。Transformer 预训练模型的实施使文本生成具有类似人类的能力，包括具有特定属性的文本，如风格或主题。受其在 NLP 任务中取得的巨大成功的激励，预计专用 Transformer 将在不久的将来主导自定义蛋白质序列的生成。对蛋白质家族的预训练模型进行微调，将使它们能够用新的序列来扩展它们，这些序列可能是高度不同的，但仍有潜在的功能。控制标签的结合方式，如细胞区系或功能，进一步使新型蛋白质功能的可控设计成为可能。此外，最近的模型可解释性方法将使我们能够解决「black box」问题，增强我们对蛋白质 folding 原理的理解。早期的举措显示了生成性语言模型在设计功能序列方面的巨大潜力。作者认为，使用生成性文本模型来创造新的蛋白质是一个很有前途的、在很大程度上未被开发的领域，并讨论了它对蛋白质设计可预见的影响。</p>
<p>ーー基于语言模型的可控蛋白质设计</p>
</blockquote>
<blockquote>
<p>一个将分子结构和生物医学文本桥接起来的深度学习系统，其理解力可与人类专业人员媲美。</p>
<p>为了加速生物医学研究过程，人们开发了深度学习系统，其通过阅读大规模的生物医学数据，来自动获取分子实体的知识。受到人类通过多种方式阅读分子结构和生物医学文本信息来学习深度分子知识的启发，论文作者提出了一个知识丰富的机器阅读系统，该系统将这两种类型的信息连接在一个统一的深度学习框架中，为生物医学研究提供全面的帮助。他们解决了现有的机器阅读模型只能分别处理不同类型数据的问题，从而实现了对分子实体的全面深入的理解。通过在不同信息来源中以无监督的方式抓取元知识，他们的系统可以促进各种现实世界生物医学应用，包括分子性质预测，生物医学关系提取等。实验结果表明，该系统在分子性质理解能力方面甚至超过了人类专业人员，并显示了其在未来药物自动发现和文档化方面的潜力。</p>
<p>ーー清华大学计算机系孙茂松团队发表于 nature communications，名为《A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals》的论文。</p>
</blockquote></div></div></div>

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="DeepMind-AlphaFold"><a target="_blank" rel="noopener" href="https://github.com/deepmind/alphafold">DeepMind AlphaFold</a><a class="anchor-link" href="#DeepMind-AlphaFold">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://hackmd.io/p1Ba4wLzQ6GBDG2Dcd7PCw">Protein Binder Engineering</a></li>
<li><a target="_blank" rel="noopener" href="https://mirror.xyz/thetechnocrat.eth/CaBr74AhQLX7bDWSsWGOeKwxjuiFNe8_XH2Hf3Bw4Dg">How to Fold Proteins with Decentralized Computing?</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/hpcaitech/FastFold">https://github.com/hpcaitech/FastFold</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41586-024-07220-7">https://www.nature.com/articles/s41586-024-07220-7</a></li>
<li><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41593-024-01615-5">https://www.nature.com/articles/s41593-024-01615-5</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2202787">BioGPT：用于生物医学文本生成和挖掘的生成性预训练转化器</a></li>
<li><a target="_blank" rel="noopener" href="https://pubmed.ncbi.nlm.nih.gov/36156661/">BioGPT: generative pre-trained transformer for biomedical text generation and mining</a></li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1963555">一个将分子结构和生物医学文本桥接起来的深度学习系统</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Single-cell-RNA-seq">Single cell RNA-seq<a class="anchor-link" href="#Single-cell-RNA-seq">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/open-problems-multimodal">Open Problems - Multimodal Single-Cell Integration | Kaggle</a></p>
<p>In the past decade, the advent of single-cell genomics has enabled the measurement of DNA, RNA, and proteins in single cells. These technologies allow the study of biology at an unprecedented scale and resolution and have led to new insights into fundamental drivers of health and disease.</p>
<p>In this competition, you will predict how DNA, RNA, and protein measurements co-vary in single cells as bone marrow stem cells develop into more mature blood cells. You will have access to a 300,000-cell timecourse dataset and develop a model that predicts from DNA to RNA and from RNA to protein at a later unseen timepoint.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://singlecellanalysistutorial.readthedocs.io/en/latest/index.html">１細胞解析技術講習会資料</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://hackmd.io/p1Ba4wLzQ6GBDG2Dcd7PCw">https://hackmd.io/p1Ba4wLzQ6GBDG2Dcd7PCw</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.k.u-tokyo.ac.jp/exam/">https://www.k.u-tokyo.ac.jp/exam/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.k.u-tokyo.ac.jp/exam/apr_sch/">https://www.k.u-tokyo.ac.jp/exam/apr_sch/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.k.u-tokyo.ac.jp/exam/recurrent_programs/">https://www.k.u-tokyo.ac.jp/exam/recurrent_programs/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.k.u-tokyo.ac.jp/education/dstep/">https://www.k.u-tokyo.ac.jp/education/dstep/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://genome-school.k.u-tokyo.ac.jp/">https://genome-school.k.u-tokyo.ac.jp/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.k.u-tokyo.ac.jp/exam/info/">https://www.k.u-tokyo.ac.jp/exam/info/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.cbms.k.u-tokyo.ac.jp/labs/rnakato/">https://www.cbms.k.u-tokyo.ac.jp/labs/rnakato/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://www.cbms.k.u-tokyo.ac.jp/labs/#labs2">https://www.cbms.k.u-tokyo.ac.jp/labs/#labs2</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://nakatolab.iqb.u-tokyo.ac.jp/joinus.html">https://nakatolab.iqb.u-tokyo.ac.jp/joinus.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://nakatolab.iqb.u-tokyo.ac.jp/software.html">https://nakatolab.iqb.u-tokyo.ac.jp/software.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a target="_blank" rel="noopener" href="https://v3-migration.vuejs.org/zh/">https://v3-migration.vuejs.org/zh/</a></p>

</div>
</div>
</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/07/BioGPT-Agent-Tools/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-07 </div>
			<div class="article-title"><a href="/2023/04/07/Robotic-Process-Automation/" >Robotic Process Automation</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>General Artificial Intelligence Agent</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/toolkits/openapi/">Hierarchical Planning Agent</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/planning-agents/">Plan-and-Execute Agents</a></li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph">LangGraph</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb">Hierarchical Agent Teams</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/TransformerOptimus/AutoNode">Cognitive GUI Automation</a><ul>
<li><a target="_blank" rel="noopener" href="https://superagi.com/introducing-autonode-advancing-rpa-with-a-multi-expert-ai-system/">Introducing AutoNode: Advancing RPA with a Multi-Expert AI System</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
 




	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/07/Robotic-Process-Automation/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-07 </div>
			<div class="article-title"><a href="/2023/04/07/A-Study-on-Network-Isolation-Measures-for-Dealing-with-Intelligent-Viruses/" >A Study on Network Isolation Measures for Dealing with &#34;Intelligent Viruses&#34;</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
  
	<div class="col-md-12">
	  
	
	  <div class="tabs" id="intelligent-viruses"><ul class="nav-tabs"><li class="tab active"><a href="#intelligent-viruses-1">Intelligent Viruses</a></li><li class="tab"><a href="#intelligent-viruses-2">智能病毒</a></li><li class="tab"><a href="#intelligent-viruses-3">インテリジェントウイルス</a></li></ul><div class="tab-content"><div class="tab-pane active" id="intelligent-viruses-1"><p>Title: A Study on Network Isolation Measures for Dealing with “Intelligent Viruses”</p>
<p>Abstract:</p>
<p>With the rapid development of artificial intelligence technology, we are facing a new type of network security threat - “intelligent viruses”. This virus is based on a certain LLM similar to ChatGPT, which can self-learn and evolve, and can replicate and continue itself using any vulnerabilities, thus spreading widely on the Internet. This paper studies two main network isolation measures: physical layer isolation and data link layer isolation, and explores their advantages, disadvantages, and applicable scenarios. We believe that these two isolation measures can be used in combination and complement each other to enhance network security. However, with the continuous development of virus technology, they may also be bypassed by attackers, so other security measures are needed to protect the network.</p>
<p>Keywords: intelligent virus, network isolation, physical layer isolation, data link layer isolation</p>
<p>Body:</p>
<ol>
<li><p>Introduction</p>
<p>With the continuous development of artificial intelligence technology, our production and lifestyle are undergoing revolutionary changes. However, this progress has also brought new challenges to our network security. In the past, network attacks mainly focused on the network layer and application layer, but today, the emergence of intelligent viruses has aroused people’s high attention. Intelligent viruses are viruses based on artificial intelligence technology, which have the ability to self-learn and evolve, and can replicate and continue themselves using any vulnerabilities, thus spreading widely on the Internet.</p>
</li>
<li><p>Network Isolation Measures</p>
<p>In order to cope with the threat of intelligent viruses, we need to take some measures to protect network security. Network isolation is a common security measure, which can physically or logically divide the network into different areas, thereby preventing viruses from spreading and attacking across different areas.</p>
<p>2.1 Physical Layer Isolation</p>
<pre><code>Physical layer isolation is a technique that physically separates a network into different areas using physical isolation technologies such as air isolation, making it impossible for viruses to spread through the physical medium, thereby achieving isolation. This isolation method can ensure high security because viruses cannot directly attack across isolated areas. However, this isolation method also has some drawbacks. Firstly, physical isolation requires a lot of cost and resources, such as the use of specialized network equipment and physical isolation methods. Secondly, physical isolation affects the flexibility and scalability of the network, as direct communication and data exchange cannot occur between different areas.
</code></pre>
<p>2.2 Data Link Layer Isolation</p>
<pre><code>Data link layer isolation is a technique that logically separates a network into different areas. It uses network devices such as switches to divide the network into different virtual networks, preventing viruses from spreading and attacking across different virtual networks. Data link layer isolation has the advantages of low cost, easy implementation, and flexible expansion, and is therefore common in practical applications.

However, data link layer isolation also has some drawbacks. Firstly, data link layer isolation depends on network devices, so there are issues such as equipment failure and complex management. Secondly, data link layer isolation may not completely prevent virus attacks because viruses may also bypass isolation restrictions through vulnerabilities or specific attack methods.
</code></pre>
</li>
<li><p>Combined Use</p>
<p>In summary, both physical layer isolation and data link layer isolation have their own advantages, disadvantages, and application scenarios. To improve network security, they can be used together and complement each other. For example, the network can be divided into multiple areas, and each area can be isolated using physical layer isolation, while data link layer isolation can be used for further segmentation within each area, thereby achieving multi-level security isolation. This can fully leverage the advantages of both isolation methods and improve network security.</p>
<p>However, it is important to note that with the continuous development of intelligent virus technology, they may also bypass these isolation measures. Therefore, we also need to take other security measures such as strengthening access control, improving vulnerability repair mechanisms, and timely upgrading security equipment to improve network security.</p>
</li>
<li><p>Conclusion</p>
<p>This article explored two isolation techniques, physical layer isolation and data link layer isolation, for combating malware attacks. These techniques use different means of isolation to prevent viruses from attacking and spreading across different network areas, thus enhancing network security. However, they also have some disadvantages and limitations, so it is necessary to choose the appropriate isolation technique based on specific circumstances, or to combine them for mutual complementarity.</p>
<p>Finally, we need to be aware that malicious software attacks are an evolving process, and as technology advances, viruses become smarter and more difficult to prevent. Therefore, we need to constantly improve our security awareness and skills and adopt multiple security measures to protect our network security.</p>
</li>
</ol></div><div class="tab-pane" id="intelligent-viruses-2"><p>论文题目：应对“智能病毒”的网络隔离措施研究</p>
<p>摘要：</p>
<p>随着人工智能技术的快速发展，我们面临着一种全新的网络安全威胁——“智能病毒”。这种病毒基于类似于 ChatGPT 的某种 LLM，能够自我学习和演化，利用任何漏洞复制和延续自身，从而在互联网上泛滥。本文研究了物理层的隔离和数据链路层的隔离这两种主要的网络隔离措施，并探讨了它们的优缺点以及适用场景。我们认为，这两种隔离措施可以结合使用，相互补充，来增强网络的安全性。但是，随着病毒技术的不断发展，它们也可能被攻击绕过，因此还需要采用其他的安全措施来保护网络。</p>
<p>关键词：智能病毒、网络隔离、物理层隔离、数据链路层隔离</p>
<p>正文：</p>
<ol>
<li><p>引言</p>
<p>随着人工智能技术的不断发展，我们的生产和生活方式正在发生翻天覆地的变化。然而，这一进步也给我们的网络安全带来了新的挑战。在过去，网络攻击主要集中在网络层和应用层，而如今，智能病毒的出现引起了人们的高度关注。智能病毒是一种基于人工智能技术的病毒，它具有自我学习和演化的能力，能够利用任何漏洞复制和延续自身，从而在互联网上泛滥。</p>
</li>
<li><p>网络隔离措施</p>
<p>为了应对智能病毒的威胁，我们需要采取一些措施来保护网络安全。网络隔离是一种常见的安全措施，它可以将网络物理上或逻辑上分割成不同的区域，从而防止病毒跨越不同的区域进行传播和攻击。</p>
<p>2.1 物理层隔离</p>
<pre><code>物理层隔离是一种将网络物理上隔离成不同区域的技术。它采用一些物理隔离技术，如空气隔离等，使得病毒无法通过物理媒介传播，从而达到隔离的效果。这种隔离方式可以确保安全性较高，因为病毒无法直接跨越隔离区域进行攻击。但是，这种隔离方式也存在一些缺点。首先，物理隔离需要耗费大量的成本和资源，例如需要使用专门的网络设备和物理隔离手段。其次，物理隔离会影响网络的灵活性和可扩展性，因为不同的区域之间无法进行直接的通信和数据交换。
</code></pre>
<p>2.2 数据链路层隔离</p>
<pre><code>数据链路层隔离是一种将网络逻辑上隔离成不同区域的技术。它利用一些网络设备，如交换机等，将网络分割成不同的虚拟网络，从而防止病毒跨越不同的虚拟网络进行传播和攻击。数据链路层隔离具有成本低、易于实现、可灵活扩展等优点，因此在实际应用中比较常见。

不过，数据链路层隔离也存在一些缺点。首先，数据链路层隔离需要依赖网络设备，因此存在设备故障和管理复杂等问题。其次，数据链路层隔离可能无法完全避免病毒攻击，因为病毒也可能通过一些漏洞或者特定的攻击方式绕过隔离的限制。
</code></pre>
</li>
<li><p>结合使用</p>
<p>综上所述，物理层隔离和数据链路层隔离都具有一定的优缺点和适用场景。为了提高网络的安全性，可以将它们结合使用，相互补充。例如，可以将网络分割成多个区域，每个区域采用物理层隔离的方式进行隔离，而在每个区域内部再采用数据链路层隔离的方式进行细分，从而实现多层次的安全隔离。这样可以充分发挥两种隔离方式的优势，提高网络的安全性。</p>
<p>但是，需要注意的是，随着智能病毒技术的不断发展，它们也可能会绕过这些隔离措施。因此，我们还需要采取其他的安全措施，如加强访问控制、完善漏洞修复机制、及时升级安全设备等，来提高网络的安全性。</p>
</li>
<li><p>结论</p>
<p>本文研究了应对“恶意软件攻击”的两种隔离技术：物理层隔离和数据链路层隔离。它们分别利用不同的隔离方式来防止病毒跨越不同的网络区域进行攻击和传播，从而提高网络的安全性。但是它们也存在一些缺点和局限性，因此需要根据具体的情况来选择合适的隔离方式，或者将它们结合使用，相互补充。</p>
<p>最后，我们需要意识到，恶意软件攻击是一个不断演变的过程，随着技术的进步，病毒也会变得越来越智能和难以防范。因此，我们需要不断提高自身的安全意识和技能，采取多种安全措施来保护自己的网络安全。</p>
</li>
</ol></div><div class="tab-pane" id="intelligent-viruses-3"><p>論文のタイトル：「インテリジェントウイルス」に対処するネットワーク分離措置の研究</p>
<p>要旨：</p>
<p>人工知能技術の急速な発展に伴い、私たちは「インテリジェントウイルス」という新たなネットワークセキュリティ脅威に直面しています。このウイルスは ChatGPT のような LLM に基づき、自己学習および進化を行い、任意の脆弱性を利用して自己を複製および拡散し、インターネット上に氾濫します。本稿では、物理層の分離およびデータリンク層の分離という主要なネットワーク分離措置を研究し、それらの利点、欠点、および適用範囲について探究します。我々は、これらの分離措置を組み合わせることで、相互補完的にネットワークセキュリティを強化できると考えています。しかし、ウイルス技術が常に進化することに注意し、攻撃を回避される可能性があるため、ネットワークを保護するために他のセキュリティ対策も必要です。</p>
<p>キーワード：インテリジェントウイルス、ネットワーク分離、物理層分離、データリンク層分離</p>
<p>正文：</p>
<ol>
<li><p>イントロダクション</p>
<p>人工知能技術の発展に伴い、私たちの生産および生活スタイルは大きく変化しています。しかしながら、この進歩は私たちのネットワークセキュリティに新たな課題をもたらしています。過去には、ネットワーク攻撃は主にネットワーク層およびアプリケーション層に集中していましたが、現在、インテリジェントウイルスの登場により、人々は高い関心を寄せています。インテリジェントウイルスは、人工知能技術に基づくウイルスであり、自己学習および進化の能力を持ち、任意の脆弱性を利用して自己を複製および拡散し、インターネット上に氾濫します。</p>
</li>
<li><p>ネットワーク分離措置</p>
<p>インテリジェントウイルスの脅威に対処するために、私たちはネットワークセキュリティを保護するためにいくつかの対策を取る必要があります。ネットワーク分離は一般的なセキュリティ対策であり、ネットワークを物理的または論理的に異なる領域に分割することで、ウイルスが異なる領域を越えて拡散し攻撃するのを防止することができます。</p>
<p>2.1 物理層の分離</p>
<pre><code>物理層の分離は、ネットワークを物理的に異なる領域に分割する技術です。空気分離などの物理分離技術を使用して、ウイルスが物理媒体を介して伝播することができないようにし、分離効果を達成します。この分離方法は、直接攻撃を行うためにウイルスが分離領域を越えることができないため、比較的高いセキュリティを確保できます。ただし、この分離方法にはいくつかの欠点があります。まず、物理分離には、専用のネットワーク機器や物理分離手段など、多くのコストとリソースが必要です。次に、物理分離は、異なる領域間で直接通信やデータ交換を行うことができないため、ネットワークの柔軟性と拡張性に影響を与える可能性があります。
</code></pre>
<p>2.2 データリンク層の分離</p>
<pre><code>データリンク層の分離は、ネットワークを論理的に異なる領域に分割する技術です。スイッチなどのネットワーク機器を利用して、ネットワークを複数の仮想ネットワークに分割し、異なる仮想ネットワークを越えたウイルスの伝播や攻撃を防止します。データリンク層の分離は、コストが低く、実現が容易で、柔軟な拡張性などの利点があるため、実際の運用では比較的一般的です。

ただし、データリンク層の分離にはいくつかの欠点があります。まず、データリンク層の分離は、ネットワーク機器に依存するため、機器の故障や管理の複雑さなどの問題があります。次に、データリンク層の分離は、ウイルス攻撃を完全に回避できない場合があるため、ウイルスが分離制限を回避するためのいくつかの脆弱性や特定の攻撃手法を利用する可能性があります。
</code></pre>
</li>
<li><p>組み合わせ使用</p>
<p>以上を総括すると、物理層の分離とデータリンク層の分離は、それぞれ一定の利点と欠点、および適用範囲を持っています。ネットワークのセキュリティを向上させるためには、これらを組み合わせて相互補完することができます。たとえば、ネットワークを複数の領域に分割し、各領域で物理層の分離を採用し、さらに各領域内でデータリンク層の分離を行うことで、多層的なセキュリティ分離を実現できます。これにより、2つの分離方法の利点を十分に活用し、ネットワークのセキュリティを向上させることができます。</p>
<p>ただし、インテリジェントウイルス技術の発展に伴い、これらの分離対策を回避する可能性があります。そのため、アクセス制御の強化、脆弱性修正機能の充実、セキュリティ機器のタイムリーなアップグレードなど、他のセキュリティ対策を採用する必要があります。</p>
</li>
<li><p>結論</p>
<p>本稿では、「悪意のあるソフトウェア攻撃」に対処するための2つの隔離技術、物理層隔離とデータリンク層隔離について研究しました。それらは、異なるネットワーク領域を跨いでウイルスが攻撃や伝播を行うのを防ぐために、異なる隔離方式を利用してネットワークのセキュリティを向上させます。しかし、それらには欠点や制限も存在するため、具体的な状況に応じて適切な隔離方法を選択する必要があるか、あるいはそれらを組み合わせて相互に補完する必要があります。</p>
<p>最後に、私たちは、悪意のあるソフトウェア攻撃は、進化し続けるプロセスであり、技術の進歩に伴い、ウイルスもますますスマートで防ぎにくくなるということを認識する必要があります。そのため、私たちは自己のセキュリティ意識とスキルを不断に高め、多様なセキュリティ対策を取る必要があります。</p>
</li>
</ol></div></div></div>

	
	</div>
	
  
</div>
	<a type="button" href="/2023/04/07/A-Study-on-Network-Isolation-Measures-for-Dealing-with-Intelligent-Viruses/#more" class="btn btn-default more">Read More</a>
</div>

		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">
<ul class="pagination">
	 
		
    	<li class="prev"><a href="/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i> Prev</a></li>
  		

        <li><a href="/"><i class="fa fa-home"></i>Home</a></li>

		
		   <li class="next"> <a href="/page/3/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a> </li>          
        
	
</ul>
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
	<div class="widget">
		<h4 style="margin-top: 18px;">Tag Cloud</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/tags/Bible/">Bible<span>2</span></a></li>
		
			<li><a href="/tags/Notebooks/">Notebooks<span>14</span></a></li>
		
			<li><a href="/tags/Nietzsche/">Nietzsche<span>3</span></a></li>
		
			<li><a href="/tags/自分を休ませる/">自分を休ませる<span>4</span></a></li>
		
			<li><a href="/tags/Psalms/">Psalms<span>11</span></a></li>
		
			<li><a href="/tags/Metaverse/">Metaverse<span>12</span></a></li>
		
			<li><a href="/tags/Pharisee/">Pharisee<span>2</span></a></li>
		
			<li><a href="/tags/CoD/">CoD<span>16</span></a></li>
		
			<li><a href="/tags/Neuro/">Neuro<span>4</span></a></li>
		
			<li><a href="/tags/雅歌/">雅歌<span>1</span></a></li>
		
			<li><a href="/tags/Lyrics/">Lyrics<span>4</span></a></li>
		
			<li><a href="/tags/Quantum/">Quantum<span>3</span></a></li>
		
			<li><a href="/tags/启示录/">启示录<span>2</span></a></li>
		
			<li><a href="/tags/Imaging/">Imaging<span>2</span></a></li>
		
			<li><a href="/tags/Syt-7/">Syt-7<span>1</span></a></li>
		
			<li><a href="/tags/箴言/">箴言<span>2</span></a></li>
		
			<li><a href="/tags/Typography/">Typography<span>4</span></a></li>
		
			<li><a href="/tags/Logotherapy/">Logotherapy<span>3</span></a></li>
		
			<li><a href="/tags/诗篇/">诗篇<span>2</span></a></li>
		
			<li><a href="/tags/BioBuilder/">BioBuilder<span>12</span></a></li>
		
		
			<li><a href="/tags">...<span>21</span></a></li>
		
		</ul>
	</div>


		
			
<div class="widget">
  <h4 style="margin-top: 18px;">Recent Posts</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2024/05/19/biobuilder/glossary/" ><i class="fa fa-file-o"></i>术语表</a>
      </li>
    
      <li>
        <a href="/2024/05/19/biobuilder/appendix/" ><i class="fa fa-file-o"></i>实验室试剂和材料</a>
      </li>
    
      <li>
        <a href="/2024/05/16/人脑海马体的经典计算模型/" ><i class="fa fa-file-o"></i>人脑海马体的经典计算模型</a>
      </li>
    
      <li>
        <a href="/2024/05/15/biobuilder/chapter-10/" ><i class="fa fa-file-o"></i>金面包</a>
      </li>
    
      <li>
        <a href="/2024/05/15/biobuilder/chapter-9/" ><i class="fa fa-file-o"></i>多么丰富多彩的世界</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget" style="border-bottom: none;">

	<h4 style="margin-top: 18px;">Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li>
			<i class="fa fa-github"></i>
			<a href="https://github.com/seii-saintway" title="Andrew's Github repository." target="_blank">Andrew&#39;s Github</a>
		</li>
	
		<li>
			<i class="fa fa-twitter"></i>
			<a href="https://twitter.com/seii_saintway" title="Andrew's Twitter account." target="_blank">Andrew&#39;s Twitter</a>
		</li>
	
	</ul>

</div>

<div class="widget" style="border-bottom: none;">

  <h5>GitHub Repos</h5>
  <ul id="gh_repos" class="list-unstyled">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <a href="https://github.com/seii-saintway" target="_blank">@seii-saintway</a> on GitHub
  <script src="/js/github.js" type="text/javascript"></script>
  <script type="text/javascript">
    github.showRepos({
        user: 'seii-saintway',
        count: 0,
        skip_forks: true,
        target: '#gh_repos',
        blacklist: ''
    });
  </script>

</div>

<div class="widget">

<h5>Twitter Tweets</h5>
<ul id="tweets" class="list-unstyled"><li class="loading">Status updating&#8230;</li></ul>
<a href="https://twitter.com/seii_saintway" target="_blank">@seii_saintway</a> on Twitter
<script src="/js/twitter.js" type="text/javascript"></script>
<script type="text/javascript">
    twitter.showTweets({
        count: 10,
        target: '#tweets',
        blacklist: ''
    });
</script>

</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->
	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2024 Andrew
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>

</html>
