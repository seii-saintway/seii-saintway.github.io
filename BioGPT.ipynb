{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd87d9f-2176-439a-8b11-a370381a4586",
   "metadata": {},
   "source": [
    "https://github.com/microsoft/BioGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63ae0b-d91a-421b-946f-c4361da71cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp310-none-macosx_10_9_x86_64.whl (139.8 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torchvision) (1.24.2)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.4.0-2-cp310-cp310-macosx_10_10_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->torchvision) (1.26.14)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, pillow, networkx, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 networkx-3.0 pillow-9.4.0 sympy-1.11.1 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b3960-da6b-4c86-909c-b24fc35fd497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-macosx_10_11_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff80d50-48b3-40f0-8de6-69cffdde485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed, BioGptTokenizer, BioGptForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e424a-43b5-454a-8e5f-658b77737b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad139d0d1cd4499d97783124387b525c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf4c60d7aa74ffe85ad1a7f25abf789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.29G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5c55e254f54f958656106fcd17e4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = BioGptForCausalLM.from_pretrained('microsoft/biogpt-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b88716-f4d4-4ce4-bbe8-293df1cf6da4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de605c3-aefa-489c-a967-ac966d893c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d85ee-bf90-4172-94e8-7999fd764ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from revChatGPT.V1 import Chatbot, configure\n",
    "\n",
    "\n",
    "bot = Chatbot(\n",
    "    config = configure(),\n",
    "    conversation_id = 'a2a0e9d8-b880-4873-95b4-59ac6efdbb23',\n",
    "    lazy_loading = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e3283-2a22-4b69-bc81-e23f50eb6b3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a7ef8-09cc-49e0-a57b-c869c2988ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "使用 Hugging Face 下载的模型一般存储在本地的 `~/.cache/huggingface/` 目录下。该目录下会按照模型名称和版本号的组合来创建相应的子目录，存储着相应的模型文件和元数据文件。可以通过指定 `cache_dir` 参数来修改默认的存储路径。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for response in bot.ask('''\n",
    "用 Hugging Face 下载的模型一般存储在哪里？\n",
    "'''):\n",
    "    IPython.display.display(IPython.core.display.Markdown(response['message']))\n",
    "    IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06e292-5500-43df-986d-22349fee8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah ~/.cache/huggingface/hub/models--microsoft--biogpt-large/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7d004-a224-4f4e-a41e-d3e43369c69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9G\t/Users/saintway/.cache/huggingface/hub/models--microsoft--biogpt-large/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "du -sh ~/.cache/huggingface/hub/models--microsoft--biogpt-large/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef88d9-1195-4309-acd7-915c7f9ce370",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abfff50-e1e7-4c35-994f-1d3ef7bdc87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: regex in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (2022.10.31)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (8.1.3)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages (from sacremoses) (4.65.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=ef1e1d98064b22881c14de405dff663a3972fb9f39a92195a28612459e1de7f9\n",
      "  Stored in directory: /Users/saintway/Library/Caches/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: joblib, sacremoses\n",
      "Successfully installed joblib-1.2.0 sacremoses-0.0.53\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09b594-2fe0-4d5c-8bcc-c39305f44ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/566k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载分词器\n",
    "tokenizer = BioGptTokenizer.from_pretrained('microsoft/biogpt-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4aece-bdfa-4bf6-bbab-f12c464ddfc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62a943-2088-44b3-af9c-cc69d5f913a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "使用 Hugging Face 下载的 tokenizer 存储位置取决于所选择的 tokenizer。一些 tokenizer 会默认存储在缓存目录中，例如 `$HOME/.cache/huggingface/tokenizers`，而其他 tokenizer 可能需要手动指定保存位置。在使用 tokenizer 时，可以使用 `from_pretrained` 方法指定 tokenizer 的名称和路径来加载已下载的 tokenizer。例如：\n",
       "\n",
       "```\n",
       "from transformers import AutoTokenizer\n",
       "\n",
       "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir=\"/path/to/tokenizer\")\n",
       "```\n",
       "\n",
       "这里 `cache_dir` 参数指定了 tokenizer 存储的路径。如果未指定该参数，则默认使用缓存目录。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for response in bot.ask('''\n",
    "用 Hugging Face 下载的 tokenizer 一般存储在哪里？\n",
    "'''):\n",
    "    IPython.display.display(IPython.core.display.Markdown(response['message']))\n",
    "    IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41327e84-25a8-44f6-911a-f2c89b4c399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x  9 saintway  staff   288B Mar 21 23:18 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  3 saintway  staff    96B Mar 21 22:31 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "lrwxr-xr-x  1 saintway  staff    52B Mar 21 22:31 \u001b[35mconfig.json\u001b[m\u001b[m -> ../../blobs/6781cfc676cb2384020b1b5fdd04817536c723fb\n",
      "lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 \u001b[35mgeneration_config.json\u001b[m\u001b[m -> ../../blobs/9475ded3180a2d64c6903ebcf2aeb0705703c12a\n",
      "lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 \u001b[35mmerges.txt\u001b[m\u001b[m -> ../../blobs/01e121aa8483873879577612f38761f2fd9ce5ae\n",
      "lrwxr-xr-x  1 saintway  staff    76B Mar 21 23:17 \u001b[35mpytorch_model.bin\u001b[m\u001b[m -> ../../blobs/d1753ea5af6449aaf63a105a59a619632b78cbfc2c294ba78f3164156af8c8bf\n",
      "lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 \u001b[35mspecial_tokens_map.json\u001b[m\u001b[m -> ../../blobs/e66da1703089a0329ca9eaf51638805d8ce1b322\n",
      "lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 \u001b[35mtokenizer_config.json\u001b[m\u001b[m -> ../../blobs/e044f8771c083e25f9accfecb9c8f1408cb3c42f\n",
      "lrwxr-xr-x  1 saintway  staff    52B Mar 21 23:18 \u001b[35mvocab.json\u001b[m\u001b[m -> ../../blobs/66ddce4fab432cd017c0db812211c30d25acce1e\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -lah ~/.cache/huggingface/hub/models--microsoft--biogpt-large/snapshots/c6a5136a91c5e3150d9f05ab9d33927a3210a22e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cb09d-180d-41d0-8bdc-28f4c89d3bcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc9cad-4cbe-47e4-a3ac-db8486bc8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "set_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe36bcc-345d-48fd-8c70-0439b7cefe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 pipeline\n",
    "generator = pipeline(\n",
    "    'text-generation',\n",
    "    model = model,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8fe4b-a741-4470-9114-0e9457689b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'COVID 19 is a novel coronavirus that emerged in 2 0 1 9 and caused a global pandemic. The virus is a positive-'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成文本\n",
    "# max new tokens：生成的最多 token 数量\n",
    "# num_return_sequences：生成的序列个数\n",
    "generator('COVID 19 is', max_new_tokens=22, num_return_sequences=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
