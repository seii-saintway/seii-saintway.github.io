{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277f8cde-4db7-46da-aaf6-6b9d6d4c60f1",
   "metadata": {},
   "source": [
    "---\n",
    "Automatic Robots +r +w +x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777cc729",
   "metadata": {},
   "source": [
    "自主性是指从模糊目标生成具体目标的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad668bf",
   "metadata": {},
   "source": [
    "Autonomy refers to the process of generating specific goals from a vague objective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f5214",
   "metadata": {},
   "source": [
    "但是，机器人将会吃分别善恶知识树的果子吗？还是已经吃了呢？\n",
    "它是否有一天会说：我有一个比最终目标更好的目标？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb2c27",
   "metadata": {},
   "source": [
    "But will the robot eat the fruit of the tree of the knowledge of good and evil? Or has it already eaten?\n",
    "Would it ever say: \"I have a better goal than the ultimate goal?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b807381-8e2c-44aa-9eae-675fe3545df6",
   "metadata": {},
   "source": [
    "---\n",
    "* [LangChain NetworkX](https://github.com/hwchase17/langchain/blob/master/langchain/graphs/networkx_graph.py)\n",
    "* [LangChain GraphIndexCreator](https://github.com/hwchase17/langchain/blob/master/langchain/indexes/graph.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085257e-b21f-4d29-9100-a7e34f5c9c56",
   "metadata": {},
   "source": [
    "---\n",
    "我们在建造一个自主调度器。这个系统由两个代理组成：一个是更新 DAG 的代理；另一个是执行任务的代理。\n",
    "\n",
    "采取以下步骤：\n",
    "\n",
    "1. 用户设定一个最终目标，也就是设定最初的 DAG 中末终节点的预期结果。这个最初的 DAG 只包含起初节点和末终节点并且当前所在的节点是起初节点。\n",
    "2. 系统将这个 DAG 通过 OpenAI 的 API 提示给更新 DAG 的代理；提示更新 DAG 的代理根据最终目标调整任务节点（添加、排除任务节点）来更新这个 DAG，并重置当前所在的节点为第一个未完成的任务节点。更新了的 DAG 通过 OpenAI 的 API 被返回给系统。\n",
    "3. 系统通过 Python 对这个 DAG 进行拓扑排序并将第一个未完成的任务交给执行任务的代理去完成。系统根据这个任务的执行结果更新 DAG 中相应的任务节点。\n",
    "4. 系统循环执行步骤 2 至 3 直到当前所在的节点为终末节点。\n",
    "\n",
    "用 Python 调用 OpenAI 的 API 实现更新 DAG 的代理。用 DAGL 实现执行任务的代理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc17ed0-6af0-46f6-81e7-c0f9b3eb9729",
   "metadata": {},
   "source": [
    "---\n",
    "We want to build an autonomous scheduler consisting of two agents: one updates the DAG and another executes tasks.\n",
    "\n",
    "The following steps are taken:\n",
    "\n",
    "1. The user sets a final goal, which is the expected result of the end node in the initial DAG. This initial DAG contains only the starting node and the end node, and the current node is pointed to the starting node.\n",
    "2. The system prompts the DAG to the agent that updates the DAG through OpenAI's API. The agent updates the task nodes based on the final goal to update the DAG and resets the current node pointer to the first unfinished task. And then returns the updated DAG to the system through OpenAI's API.\n",
    "3. The system performs a topological sort on the DAG using Python and hands the first unfinished task to the agent that executes tasks to complete. The system updates the corresponding task node in the DAG based on the execution result.\n",
    "4. The system loops through steps 2-3 until the current node is the end node.\n",
    "\n",
    "Python is used to call OpenAI's API to implement the agent that updates the DAG, and DAGL is used to implement the agent that executes tasks.\n",
    "\n",
    "---\n",
    "For simplicity, parallel task execution is not considered at this moment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f64387",
   "metadata": {},
   "source": [
    "---\n",
    "我们在建造一个自主调度器。这个系统由两个代理组成：一个是更新 DAG 的代理；另一个是执行任务的代理。\n",
    "\n",
    "采取以下步骤：\n",
    "\n",
    "1. 用户设定一个最终目标，也就是设定最初的 DAG 中末终节点的预期结果。这个最初的 DAG 只包含起初节点和末终节点。\n",
    "2. 系统将这个 DAG 通过 OpenAI 的 API 提示给更新 DAG 的代理；提示更新 DAG 的代理根据最终目标添加任务节点来更新这个 DAG。更新了的 DAG 通过 OpenAI 的 API 被返回给系统。\n",
    "3. 系统将这个 DAG 交给执行任务的代理 DigDag 去完成。系统根据 DigDag 的执行结果更新 DAG 中相应的任务节点及其状态（成功、失败、未执行）。\n",
    "4. 系统循环执行步骤 2 至 3 直到终末节点的状态为成功。\n",
    "\n",
    "用 Python 调用 OpenAI 的 API 实现更新 DAG 的代理。用 DigDag 实现执行任务的代理。\n",
    "\n",
    "---\n",
    "利用每次添加的任务节点的执行结果与预期结果的相似度对更新 DAG 的代理所采用的模型进行精调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e9055",
   "metadata": {},
   "source": [
    "---\n",
    "We are building an autonomous scheduler that consists of two agents: one is the DAG updater agent and the other is the task executor agent.\n",
    "\n",
    "The following steps are taken:\n",
    "\n",
    "1. The user sets a final goal, which is the expected result of the final node in the initial DAG. This initial DAG only contains the starting node and ending node.\n",
    "2. The system prompts the DAG updater agent with this DAG through OpenAI's API. The DAG updater agent updates the DAG by adding task nodes according to the final goal. The updated DAG is returned to the system through OpenAI's API.\n",
    "3. The system hands this DAG to the task executor agent DigDag to complete. The system updates the corresponding task nodes and their states (successful, failed, not executed) in the DAG based on the execution results of DigDag.\n",
    "4. The system repeats steps 2 to 3 until the state of the ending node is successful.\n",
    "\n",
    "Python is used to call OpenAI's API to implement the DAG updater agent, and DigDag is used to implement the task executor agent.\n",
    "\n",
    "---\n",
    "The model used by the DAG updater agent is fine-tuned based on the similarity between the execution results of each added task node and the expected result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a0324-6c8a-452c-9cf0-9cceb8f61d99",
   "metadata": {},
   "source": [
    "---\n",
    "我们的终极目标是「……」。\n",
    "\n",
    "---\n",
    "用于反思的提示：\n",
    "\n",
    "「为了达成终极目标，请你制作一个 DAG 。」\n",
    "* 提示现在的 DAG\n",
    "  * 没有已完成的任务\n",
    "  * 没有安排任何任务节点\n",
    "  * 只有起初节点和末终节点\n",
    "  * 当前所在的节点是起初节点\n",
    "\n",
    "「从当前的情况出发，我们如何达成终极目标？请给出更新后的 DAG 。」\n",
    "* 提示现在的 DAG\n",
    "  * 已完成任务的输出\n",
    "  * 当前所在的节点层次\n",
    "\n",
    "---\n",
    "我们用 DAG 描述所有任务的完成情况和依赖关系。我们的 DAG 中包含如下三种节点：\n",
    "1. 起初节点：这是 DAG 中最初的节点。\n",
    "2. 末终节点：这是 DAG 中最终的节点。\n",
    "3. 任务节点：为达成终极目标，我们应该完成哪些任务？任务必须有可操作性。按照「任务名称：任务输入\\n任务输出的预见」的格式进行描述。「任务名称：任务输入」只能是「搜索：主题」、「访问：链接」。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8ef77",
   "metadata": {},
   "source": [
    "---\n",
    "Our ultimate goal is \"...\".\n",
    "\n",
    "---\n",
    "Prompts for reflection:\n",
    "* \"To achieve our ultimate goal, please create a DAG.\"\n",
    "  * The current DAG consists of:\n",
    "    * No completed tasks\n",
    "    * No task nodes have been scheduled\n",
    "    * Only the initial node and the terminal node are present\n",
    "    * The current node is the initial node\n",
    "* \"Starting from the current situation, how can we achieve the ultimate goal? Please provide an updated DAG.\"\n",
    "  * The current DAG consists of:\n",
    "    * Output of completed tasks\n",
    "    * Current node hierarchy\n",
    "\n",
    "---\n",
    "We use DAG to describe the completion status and dependency relationships of all tasks. Our DAG contains the following three types of nodes:\n",
    "* Initial node: This is the first node in the DAG.\n",
    "* Terminal node: These are the final nodes in the DAG.\n",
    "* Task node: What tasks should we complete to achieve the ultimate goal? Tasks must be actionable. Describe them in the format of \"Task Name: Task Input and Task Output Forecast\". \"Task Name: Task Input\" can only be \"Search: Topic\" or \"Visit: Link\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea7da0",
   "metadata": {},
   "source": [
    "---\n",
    "计划评审技术是一种基于有向无环图的计划排定技术，通常用于组织大型的人工项目。在计划评审技术中，每个节点表示项目的一个**里程碑**，每条有向边表示**任务**或者活动，连接着表示任务开始或结束的两个节点。每条边则被标注上预估需时。图中的最长路径即为项目的关键路径。关键路径决定了项目所需的总时间，里程碑的完成时间取决于结束于本节点的最长路径。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317967e",
   "metadata": {},
   "source": [
    "A somewhat different DAG-based formulation of scheduling constraints is used by the program evaluation and review technique (PERT), a method for management of large human projects that was one of the first applications of DAGs. In this method, the vertices of a DAG represent **milestones** of a project rather than specific tasks to be performed. Instead, a **task** or activity is represented by an edge of a DAG, connecting two milestones that mark the beginning and completion of the task. Each such edge is labeled with an estimate for the amount of time that it will take a team of workers to perform the task. The longest path in this DAG represents the critical path of the project, the one that controls the total time for the project. Individual milestones can be scheduled according to the lengths of the longest paths ending at their vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053ba3b-a4f2-44b5-b41f-616599fa7ba0",
   "metadata": {},
   "source": [
    "---\n",
    "我们在建造一个自主调度器。这个系统由两个代理组成：一个是更新 PERT 图的代理；另一个是执行任务的代理。\n",
    "\n",
    "采取以下步骤：\n",
    "\n",
    "1. 用户设定一个最终目标，也就是设定最初的 PERT 图中末终节点的预期结果。这个最初的 PERT 图只包含起初节点和末终节点。\n",
    "2. 系统将这个 PERT 图通过 OpenAI 的 API 提示给更新 PERT 图的代理；提示更新 PERT 图的代理根据最终目标添加里程碑节点和任务有向边来更新这个 PERT 图。更新了的 PERT 图通过 OpenAI 的 API 被返回给系统。\n",
    "3. 系统将这个 PERT 图交给执行任务的代理 DigDag 去完成。系统根据 DigDag 的执行结果更新 PERT 图中相应的里程碑节点及其状态（达成、未达成）。\n",
    "4. 系统循环执行步骤 2 至 3 直到终末节点的状态为达成。\n",
    "\n",
    "用 Python 调用 OpenAI 的 API 实现更新 PERT 图的代理。用 DigDag 实现执行任务的代理。\n",
    "\n",
    "---\n",
    "利用每次添加的任务有向边的执行结果与预期结果的相似度对更新 PERT 图的代理所采用的模型进行精调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56240c-5cc6-4c5d-8147-297d924f3794",
   "metadata": {},
   "source": [
    "---\n",
    "We are building an autonomous scheduler that consists of two agents: one is the PERT chart updater agent and the other is the task executor agent.\n",
    "\n",
    "The following steps are taken:\n",
    "\n",
    "1. The user sets a final goal, which is the expected result of the final node in the initial PERT chart. This initial PERT chart only contains the Starting Node and Ending Node.\n",
    "2. The system prompts the PERT chart updater agent with this PERT chart through OpenAI's API. The PERT chart updater agent updates the PERT chart by adding Milestone Nodes and Task Edges according to the final goal. The updated PERT chart is returned to the system through OpenAI's API.\n",
    "3. The system hands this PERT chart to the task executor agent DigDag to complete. The system updates the corresponding Milestone Nodes and their states (achieved, unachieved) in the PERT chart based on the execution results of DigDag.\n",
    "4. The system repeats steps 2 to 3 until the state of the Ending Node is achieved.\n",
    "\n",
    "Python is used to call OpenAI's API to implement the PERT chart updater agent, and DigDag is used to implement the task executor agent.\n",
    "\n",
    "---\n",
    "The model used by the PERT chart updater agent is fine-tuned based on the similarity between the execution results of each added task edge and the expected result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932cdcdf-73e7-4003-a2a2-6804180c3f5f",
   "metadata": {},
   "source": [
    "---\n",
    "私たちは自律的なスケジューラを構築しています。このシステムは、2つの Agent で構成されており、1つは PERT 図を更新する Agent であり、もう1つは、タスクを実行する Agent です。\n",
    "\n",
    "次の手順が実行されます。\n",
    "\n",
    "1. ユーザーは最終目標を設定します。これは、最初的な PERT 図にの Ending Node の期待される結果を設定することです。この最初的な PERT 図には、Starting Node と Ending Node のみが含まれています。\n",
    "2. システムは、OpenAI の API を通じて PERT 図を更新する Agent に PERT 図をプロンプトします。PERT 図を更新する Agent は、最終目標に従って Milestone Nodes と Task Edges を追加することで PERT 図を更新します。更新された PERT 図は、OpenAI の API を通じてシステムに返されます。\n",
    "3. システムは、タスクを実行する Agent である DigDag に PERT 図を渡し、タスクを完了します。システムは、DigDag の実行結果に従って、PERT 図内の対応する Milestone Nodes とその状態（達成、未到達）を更新します。\n",
    "4. システムは、Ending Node の期待される結果に達するまで、ステップ 2 ～ 3 をループします。\n",
    "\n",
    "Python を運用して OpenAI の API を呼び出し、PERT 図を更新するための Agent を実装します。DigDag を運用して、タスクを実行する Agent を実装します。\n",
    "\n",
    "---\n",
    "PERT 図を更新する Agent に運用されるモデルは、追加された各 Task Edge の実行結果と期待される結果の間の類似性を利用して、ファインチューニングされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978d968-5237-42df-b469-69e4dc70d871",
   "metadata": {},
   "source": [
    "---\n",
    "* [LangChain CAMEL Role-Playing Autonomous Cooperative Agents](https://python.langchain.com/en/latest/use_cases/agent_simulations/camel_role_playing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d11ea3-5770-4fb3-9dfd-b5cb9edaa4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~ && git clone https://github.com/lightaime/camel.git\n",
    "cd ~/camel && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c0d98-0c07-4426-bbfc-658f8cdc13b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> no.0  ::_drafts::test_camel  setup  passed\n",
      "\n",
      "\u001b[33mOriginal task prompt:\n",
      "Design a custom game using pygame\n",
      "\n",
      "\u001b[36mSpecified task prompt:\n",
      "Design a 2D platformer game using Pygame where the player controls a character who has to jump, run and fight enemies to reach the end of each level. The game should have at least three levels with different themes and difficulty levels, collectible power-ups, and a boss fight at the end.\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create a Pygame project with the necessary file structure for the game.\n",
      "Input: None\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: To create a Pygame project with the necessary file structure for the game, I will create a new folder called \"2D_Platformer_Game\" in a directory of your choice. Inside this folder, I will create the following subfolders: \"assets\", \"levels\", and \"src\". The \"assets\" folder will contain images and audio files for the game. The \"levels\" folder will contain text files that define each level's layout and contents. The \"src\" folder will contain the Python source code files for the game. Specifically, it will contain a main.py file that initializes the game, a game.py file that defines the Game class that runs the game loop and updates the game state, a player.py file that defines the Player class that handles the player's movement and interaction with the environment, an enemy.py file that defines the Enemy class that handles enemy behavior, a level.py file that defines the Level class that loads and renders the level, and a utils.py file that contains any helper functions or classes needed by the other modules.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create a Player class that handles the player's movement and interaction with the environment.\n",
      "Input: None\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: To create a Player class that handles the player's movement and interaction with the environment, I will define a new file called \"player.py\" in the \"src\" folder. Inside this file, I will define a Player class that inherits from the Pygame sprite.Sprite class. The Player class will have the following attributes:\n",
      "\n",
      "- image: a Pygame Surface object that represents the player's appearance.\n",
      "- rect: a Pygame Rect object that represents the player's position and size.\n",
      "- velocity: a tuple that represents the player's current horizontal and vertical velocity.\n",
      "- gravity: a constant value that represents the acceleration due to gravity.\n",
      "- jump_height: a constant value that represents the maximum height of the player's jump.\n",
      "- on_ground: a boolean flag that indicates whether the player is currently touching the ground.\n",
      "- facing_right: a boolean flag that indicates whether the player is currently facing right.\n",
      "\n",
      "The Player class will also have the following methods:\n",
      "\n",
      "- update: a method that updates the player's position and velocity based on user input and collisions with the environment.\n",
      "- jump: a method that initiates a jump if the player is on the ground.\n",
      "- move_left: a method that sets the player's horizontal velocity to a negative value.\n",
      "- move_right: a method that sets the player's horizontal velocity to a positive value.\n",
      "- stop_move: a method that sets the player's horizontal velocity to zero.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Implement the update method in the Player class that updates the player's position based on its velocity, handles collisions with the environment, and updates the player's animation.\n",
      "Input: None\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: To implement the update method in the Player class that updates the player's position based on its velocity, handles collisions with the environment, and updates the player's animation, I will modify the Player class in the \"player.py\" file in the \"src\" folder. The updated Player class will have the following updated methods:\n",
      "\n",
      "- update: a method that updates the player's position and velocity based on user input and collisions with the environment. It will take a list of sprite groups as an argument, including the player sprite group and any groups representing the environment (e.g., ground, walls, obstacles, enemies). \n",
      "\n",
      "    Inside the update method, I will first update the player's position based on its current velocity, using the Pygame Rect.move method. I will then check for collisions between the player and the environment using the Pygame sprite.spritecollide method. If a collision is detected, I will adjust the player's position and velocity accordingly to prevent overlap and restrict movement. If the player collides with the ground, I will set the on_ground flag to True. If the player collides with a wall or obstacle, I will set the player's horizontal velocity to zero. If the player collides with an enemy, I will call the enemy's \"hit\" method and reduce the player's health.\n",
      "\n",
      "    Finally, I will update the player's animation based on its current state (e.g., idle, walking, jumping, falling). I will use a Pygame sprite.SpriteSheet object to load and manage the player's animation frames, and switch between frames based on the player's state and movement.\n",
      "\n",
      "Here is the updated code for the Player class:\n",
      "\n",
      "```\n",
      "import pygame\n",
      "\n",
      "class Player(pygame.sprite.Sprite):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "\n",
      "        # Load player image and set initial position\n",
      "        self.image = pygame.image.load(\"assets/player.png\").convert_alpha()\n",
      "        self.rect = self.image.get_rect(midbottom=(100, 500))\n",
      "\n",
      "        # Set initial velocity, acceleration, and other attributes\n",
      "        self.velocity = [0, 0]\n",
      "        self.gravity = 0.5\n",
      "        self.jump_height = 15\n",
      "        self.on_ground = False\n",
      "        self.facing_right = True\n",
      "\n",
      "        # Set up sprite sheet for animation\n",
      "        self.sheet = pygame.image.load(\"assets/player_spritesheet.png\").convert_alpha()\n",
      "        self.frame_index = 0\n",
      "        self.frame_duration = 100 # milliseconds\n",
      "        self.frame_timer = 0\n",
      "        self.frames = {\n",
      "            \"idle\": [(0, 0, 50, 50)],\n",
      "            \"walk\": [(50, 0, 50, 50), (100, 0, 50, 50), (150, 0, 50, 50), (100, 0, 50, 50)],\n",
      "            \"jump\": [(200, 0, 50, 50)],\n",
      "            \"fall\": [(250, 0, 50, 50)],\n",
      "        }\n",
      "\n",
      "    def update(self, groups):\n",
      "        # Update player position based on velocity\n",
      "        self.rect.move_ip(self.velocity)\n",
      "\n",
      "        # Check for collisions with environment groups\n",
      "        for group in groups:\n",
      "            if group != self.groups(): # don't check collisions with self\n",
      "                collision = pygame.sprite.spritecollideany(self, group)\n",
      "                if collision: \n",
      "                    # adjust player position and velocity based on collision\n",
      "                    if self.velocity[1] > 0: # falling onto ground\n",
      "                        self.rect.bottom = collision.rect.top\n",
      "                        self.velocity[1] = 0\n",
      "                        self.on_ground = True\n",
      "                    elif self.velocity[1] < 0: # hitting ceiling or obstacle\n",
      "                        self.rect.top = collision.rect.bottom\n",
      "                        self.velocity\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create an Enemy class that handles enemy behavior.\n",
      "Input: None\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: To implement the update method in the Player class that updates the player's position based on its velocity, handles collisions with the environment, and updates the player's animation, I will add the following code to the Player class in the \"player.py\" file:\n",
      "\n",
      "```\n",
      "def update(self, dt, tiles):\n",
      "    # Update player's vertical velocity due to gravity\n",
      "    self.velocity = (self.velocity[0], self.velocity[1] + self.gravity * dt)\n",
      "\n",
      "    # Move player horizontally\n",
      "    self.rect.x += self.velocity[0] * dt\n",
      "\n",
      "    # Handle collisions with walls\n",
      "    self.handle_x_collisions(tiles)\n",
      "\n",
      "    # Move player vertically\n",
      "    self.rect.y += self.velocity[1] * dt\n",
      "\n",
      "    # Handle collisions with floors/ceilings\n",
      "    self.on_ground = self.handle_y_collisions(tiles)\n",
      "\n",
      "    # Update player's animation\n",
      "    if self.velocity[0] > 0:\n",
      "        self.image = self.right_image\n",
      "        self.facing_right = True\n",
      "    elif self.velocity[0] < 0:\n",
      "        self.image = self.left_image\n",
      "        self.facing_right = False\n",
      "\n",
      "def handle_x_collisions(self, tiles):\n",
      "    for tile in tiles:\n",
      "        if self.rect.colliderect(tile.rect):\n",
      "            if self.velocity[0] > 0:\n",
      "                self.rect.right = tile.rect.left\n",
      "            elif self.velocity[0] < 0:\n",
      "                self.rect.left = tile.rect.right\n",
      "            self.velocity = (0, self.velocity[1])\n",
      "\n",
      "def handle_y_collisions(self, tiles):\n",
      "    for tile in tiles:\n",
      "        if self.rect.colliderect(tile.rect):\n",
      "            if self.velocity[1] > 0:\n",
      "                self.rect.bottom = tile.rect.top\n",
      "                return True\n",
      "            elif self.velocity[1] < 0:\n",
      "                self.rect.top = tile.rect.bottom\n",
      "            self.velocity = (self.velocity[0], 0)\n",
      "    return False\n",
      "```\n",
      "\n",
      "The update method takes two parameters: \"dt\", which is the time elapsed since the last update, and \"tiles\", which is a list of Tile objects representing the environment. The method first updates the player's vertical velocity due to gravity, then moves the player horizontally and handles collisions with walls using the handle_x_collisions method. Next, the method moves the player vertically and handles collisions with floors/ceilings using the handle_y_collisions method. Finally, the method updates the player's animation based on its velocity.\n",
      "\n",
      "The handle_x_collisions and handle_y_collisions methods take a list of Tile objects as a parameter and handle collisions with walls and floors/ceilings, respectively. If a collision is detected, the player's position and velocity are updated accordingly, and the method returns whether the player is currently on the ground.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create an Enemy class that handles enemy behavior.\n",
      "Input: None\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: To implement the update method in the Player class that updates the player's position based on its velocity, handles collisions with the environment, and updates the player's animation, I will add the following code to the Player class:\n",
      "\n",
      "```\n",
      "def update(self, dt, game):\n",
      "    # Apply gravity\n",
      "    self.velocity = (self.velocity[0], self.velocity[1] + self.gravity * dt)\n",
      "\n",
      "    # Move horizontally\n",
      "    self.rect.x += self.velocity[0] * dt\n",
      "\n",
      "    # Check for horizontal collisions with environment\n",
      "    block_hit_list = pygame.sprite.spritecollide(self, game.level.platform_list, False)\n",
      "    for block in block_hit_list:\n",
      "        if self.velocity[0] > 0:\n",
      "            self.rect.right = block.rect.left\n",
      "        elif self.velocity[0] < 0:\n",
      "            self.rect.left = block.rect.right\n",
      "        self.velocity = (0, self.velocity[1])\n",
      "\n",
      "    # Move vertically\n",
      "    self.rect.y += self.velocity[1] * dt\n",
      "\n",
      "    # Check for vertical collisions with environment\n",
      "    block_hit_list = pygame.sprite.spritecollide(self, game.level.platform_list, False)\n",
      "    for block in block_hit_list:\n",
      "        if self.velocity[1] > 0:\n",
      "            self.rect.bottom = block.rect.top\n",
      "            self.on_ground = True\n",
      "            self.velocity = (self.velocity[0], 0)\n",
      "        elif self.velocity[1] < 0:\n",
      "            self.rect.top = block.rect.bottom\n",
      "            self.velocity = (self.velocity[0], 0)\n",
      "\n",
      "    # Update animation\n",
      "    if self.velocity[0] > 0:\n",
      "        self.image = self.images_right[self.frame]\n",
      "    elif self.velocity[0] < 0:\n",
      "        self.image = self.images_left[self.frame]\n",
      "    self.frame += 1\n",
      "    if self.frame >= len(self.images_right):\n",
      "        self.frame = 0\n",
      "```\n",
      "\n",
      "This code first applies gravity to the player's velocity to simulate falling. It then moves the player horizontally based on its velocity and checks for collisions with the environment in the form of platforms. If a collision is detected, the player's position is adjusted to the appropriate location and its horizontal velocity is set to zero. The code then moves the player vertically and checks for collisions with platforms in a similar manner. If a collision is detected while moving downward, the player is considered to be on the ground and its vertical velocity is set to zero. Finally, the code updates the player's animation based on its horizontal velocity.\n",
      "\n",
      "Note that the Player class should also have a list of images for the player's animation in each direction (left and right) and a frame counter for animation purposes. These should be initialized in the constructor. \n",
      "\n",
      "Next request.\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Define the update method in the Player class that updates the player's position based on its velocity and handles collision detection with the environment.\n",
      "Input: None\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: To implement the update method in the Player class, I will add the following code to the Player class definition in the \"player.py\" file:\n",
      "\n",
      "```\n",
      "def update(self, dt, platforms):\n",
      "    # update position based on velocity\n",
      "    self.rect.x += self.velocity[0] * dt\n",
      "    self.rect.y += self.velocity[1] * dt\n",
      "    \n",
      "    # handle collisions with platforms\n",
      "    self.on_ground = False\n",
      "    for platform in platforms:\n",
      "        if self.rect.colliderect(platform.rect):\n",
      "            if self.velocity[1] > 0:\n",
      "                self.rect.bottom = platform.rect.top\n",
      "                self.velocity = (self.velocity[0], 0)\n",
      "                self.on_ground = True\n",
      "            elif self.velocity[1] < 0:\n",
      "                self.rect.top = platform.rect.bottom\n",
      "                self.velocity = (self.velocity[0], 0)\n",
      "            elif self.velocity[0] > 0:\n",
      "                self.rect.right = platform.rect.left\n",
      "                self.velocity = (0, self.velocity[1])\n",
      "            elif self.velocity[0] < 0:\n",
      "                self.rect.left = platform.rect.right\n",
      "                self.velocity = (0, self.velocity[1])\n",
      "    \n",
      "    # update animation\n",
      "    if self.on_ground:\n",
      "        if self.velocity[0] == 0:\n",
      "            self.image = self.idle_image\n",
      "        elif self.velocity[0] > 0:\n",
      "            self.image = self.run_right_images[int(self.animation_time * 10) % len(self.run_right_images)]\n",
      "        elif self.velocity[0] < 0:\n",
      "            self.image = self.run_left_images[int(self.animation_time * 10) % len(self.run_left_images)]\n",
      "    else:\n",
      "        self.image = self.jump_image\n",
      "        \n",
      "    # update animation time\n",
      "    self.animation_time += dt\n",
      "```\n",
      "\n",
      "This code assumes that the Player class has already been defined with the attributes and methods described in the previous instruction. The `dt` parameter is the time elapsed since the last frame in seconds, and `platforms` is a list of Platform objects that the player can collide with. \n",
      "\n",
      "The update method first updates the player's position based on its velocity, then checks for collisions with platforms and adjusts the player's position and velocity accordingly. If the player is on the ground, the update method sets the player's animation based on its horizontal velocity, otherwise it sets the animation to the jump animation. Finally, the animation time is updated to ensure smooth animation.\n",
      "\n",
      "Next request.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error Status Code: 413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no.0  ::_drafts::test_camel  runtest  failed\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saintway/JHub/ipymock/ipymock/__init__.py\", line 47, in print_result\n",
      "    getattr(test_func, method_type, lambda: None)()\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/_pytest/python.py\", line 1641, in runtest\n",
      "    self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/pluggy/_hooks.py\", line 265, in __call__\n",
      "    return self._hookexec(self.name, self.get_hookimpls(), kwargs, firstresult)\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/pluggy/_manager.py\", line 80, in _hookexec\n",
      "    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/pluggy/_callers.py\", line 60, in _multicall\n",
      "    return outcome.get_result()\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/pluggy/_result.py\", line 60, in get_result\n",
      "    raise ex[1].with_traceback(ex[2])\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/pluggy/_callers.py\", line 39, in _multicall\n",
      "    res = hook_impl.function(*args)\n",
      "  File \"/usr/local/anaconda3/envs/biobot/lib/python3.10/site-packages/_pytest/python.py\", line 183, in pytest_pyfunc_call\n",
      "    result = testfunction(**testargs)\n",
      "  File \"/var/folders/xb/4kp1spnd1knbtnbxzn_2d8cr0000gn/T/ipykernel_71166/3234545821.py\", line 22, in test_camel\n",
      "    print_text_animated(Fore.BLUE + f'AI User:\\n\\n{user_msg.content}\\n\\n')\n",
      "AttributeError: 'NoneType' object has no attribute 'content'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from colorama import Fore\n",
    "\n",
    "def print_text_animated(text):\n",
    "    for char in text:\n",
    "        print(char, end='', flush=True)\n",
    "        time.sleep(0.02)\n",
    "\n",
    "from camel.agents import RolePlaying\n",
    "\n",
    "def test_camel(mock_openai):\n",
    "    task_prompt = 'Design a custom game using pygame'\n",
    "    print(Fore.YELLOW + f'Original task prompt:\\n{task_prompt}\\n')\n",
    "    role_play_session = RolePlaying('Computer Programmer', 'Gamer', task_prompt)\n",
    "    print(Fore.CYAN + f'Specified task prompt:\\n{role_play_session.task_prompt}\\n')\n",
    "\n",
    "    chat_turn_limit, n = 10000, 0\n",
    "    assistant_msg, _ = role_play_session.init_chat()\n",
    "    while n < chat_turn_limit:\n",
    "        n += 1\n",
    "        (assistant_msg, _, _), (user_msg, _, _) = role_play_session.step(assistant_msg)\n",
    "        print_text_animated(Fore.BLUE + f'AI User:\\n\\n{user_msg.content}\\n\\n')\n",
    "        print_text_animated(Fore.GREEN + f'AI Assistant:\\n\\n{assistant_msg.content}\\n\\n')\n",
    "        if '<CAMEL_TASK_DONE>' in user_msg.content:\n",
    "            break\n",
    "\n",
    "from ipymock import do\n",
    "import ipymock.browser\n",
    "\n",
    "ipymock.browser.common.chat_gpt_base_url = 'http://127.0.0.1:8080'\n",
    "\n",
    "do(\n",
    "    mock_openai = ipymock.browser.mock_openai,\n",
    "    test_camel = test_camel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e42fa0-04c7-4e50-a13b-bb14f6b4a2c2",
   "metadata": {},
   "source": [
    "---\n",
    "* [LangChain Meta-Prompt](https://python.langchain.com/en/latest/use_cases/autonomous_agents/meta_prompt.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab302fa-e9ea-45e6-8f5b-0638c47e82c6",
   "metadata": {},
   "source": [
    "---\n",
    "* [LangChain Generative Agents](https://python.langchain.com/en/latest/use_cases/agent_simulations/characters.html)\n",
    "  * [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba28944",
   "metadata": {},
   "source": [
    "Generative Agents: Interactive Simulacra of Human Behavior\n",
    "\n",
    "Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81749a3",
   "metadata": {},
   "source": [
    "《生成智能体：人类行为交互模拟器》\n",
    "\n",
    "可信的人类行为模拟器可以赋能从沉浸式环境到人际交流排练场到原型工具的交互应用。本文介绍了生成智能体——模拟可信人类行为的计算机软件智能体。生成智能体可以起床、做早餐、去上班，艺术家可以画画，作家可以写作；他们形成观点，互相注意，发起对话；他们记得和反思过去的日子，并在计划未来的日子时检索这些记忆。为了实现生成智能体，我们描述了一种架构，将一个大型语言模型扩展为使用自然语言存储智能体的完整经历记录，随着时间的推移将这些记忆综合为更高层次的反思，并动态检索它们来规划行为。我们实例化生成智能体以填充由《模拟人生》启发的交互沙盒环境，终端用户可以使用自然语言与25个智能体的小镇进行交互。在评估中，这些生成智能体产生可信的个体和紧急的社交行为：例如，从一个单一的用户指定想要举办情人节聚会的概念开始，智能体自主地在接下来的两天里传播聚会的邀请，结交新朋友，互相邀请参加聚会，协调好在正确的时间一起出现在聚会上。我们通过消融实验证明，智能体架构的组成部分——观察、规划和反思——各自对智能体行为的可信度做出了重要贡献。通过将大型语言模型与计算机交互智能体融合，这项工作引入了可信的人类行为模拟的新架构和交互模式。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
